<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>numpy_reshape_ravel_flatten_resize</title>
      <link href="/2018/08/29/numpy-reshape-ravel-flatten-resize/"/>
      <url>/2018/08/29/numpy-reshape-ravel-flatten-resize/</url>
      <content type="html"><![CDATA[<h3 id="numpy-中的reshape，flatten，ravel-数据平展，多维数组变成一维数组"><a href="#numpy-中的reshape，flatten，ravel-数据平展，多维数组变成一维数组" class="headerlink" title="numpy 中的reshape，flatten，ravel 数据平展，多维数组变成一维数组"></a>numpy 中的reshape，flatten，ravel 数据平展，多维数组变成一维数组</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="使用array对象"><a href="#使用array对象" class="headerlink" title="使用array对象"></a>使用array对象</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">arr1=np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">print(arr1)</span><br><span class="line">print(type(arr1))</span><br></pre></td></tr></table></figure><pre><code>[[ 0  1  2  3] [ 4  5  6  7] [ 8  9 10 11]]&lt;class &apos;numpy.ndarray&apos;&gt;</code></pre><ul><li>flatten 展平</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a=arr1.flatten() </span><br><span class="line"><span class="comment"># 默认参数order=C，按照行进行展平；order=F，按照列进行展平，交叉展平；</span></span><br><span class="line"><span class="comment">#A 或K参数用的不多，顾不变多记，到时候找到会用即可</span></span><br><span class="line">a[<span class="number">2</span>]=<span class="number">1000</span></span><br><span class="line">print(arr1)  <span class="comment"># arr1 并没有改变,flatten 返回的是copy</span></span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>[[ 0  1  2  3] [ 4  5  6  7] [ 8  9 10 11]]array([   0,    1, 1000,    3,    4,    5,    6,    7,    8,    9,   10,         11])</code></pre><a id="more"></a><ul><li>reshape 变换</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr1=np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b=arr1.reshape(<span class="number">-1</span>)  <span class="comment">#  b=arr1.reshape((-1)) 等同的效果意义 ,  </span></span><br><span class="line">b[<span class="number">2</span>]=<span class="number">1000</span></span><br><span class="line">print(arr1)<span class="comment"># 返回的是视图view</span></span><br></pre></td></tr></table></figure><pre><code>[[   0    1 1000    3] [   4    5    6    7] [   8    9   10   11]]</code></pre><ul><li>ravel 变换</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr1=np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">c=arr1.ravel()</span><br><span class="line">c</span><br></pre></td></tr></table></figure><pre><code>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c[<span class="number">2</span>]=<span class="number">10001</span></span><br><span class="line">arr1  <span class="comment"># 返回的是视图view</span></span><br></pre></td></tr></table></figure><pre><code>array([[    0,     1, 10001,     3],       [    4,     5,     6,     7],       [    8,     9,    10,    11]])</code></pre><ul><li>resize</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr1=np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">arr1.resize((<span class="number">4</span>,<span class="number">3</span>))  <span class="comment">#  无返回值，即会对原始多维数组直接进行修改，也就是不能赋值</span></span><br><span class="line">arr1</span><br></pre></td></tr></table></figure><pre><code>array([[ 0,  1,  2],       [ 3,  4,  5],       [ 6,  7,  8],       [ 9, 10, 11]])</code></pre><h4 id="对matrix对象进行操作"><a href="#对matrix对象进行操作" class="headerlink" title="对matrix对象进行操作"></a>对matrix对象进行操作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用matrix对象的时候，返回的仍是matrix，得不到想要的结果,不过该matrix仍然可以使用numpy中的一些方法对其操作，比如sum，min,max等等</span></span><br><span class="line">d=np.matrix(np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">d</span><br></pre></td></tr></table></figure><pre><code>matrix([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d.flatten()<span class="comment">#</span></span><br></pre></td></tr></table></figure><pre><code>matrix([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])</code></pre>]]></content>
      
      <categories>
          
          <category> numpy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> numpy </tag>
            
            <tag> data_processing </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DataFrame_line_column_sum</title>
      <link href="/2018/08/27/dataframeme-line-column-sum/"/>
      <url>/2018/08/27/dataframeme-line-column-sum/</url>
      <content type="html"><![CDATA[<h4 id="pandas-DataFrame对行和列求和及添加新行和列"><a href="#pandas-DataFrame对行和列求和及添加新行和列" class="headerlink" title="pandas.DataFrame对行和列求和及添加新行和列"></a>pandas.DataFrame对行和列求和及添加新行和列</h4><ul><li>导入模块：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><ul><li><p>生成DataFrame数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(np.random.randn(<span class="number">4</span>, <span class="number">5</span>), columns=[<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>, <span class="string">'E'</span>])</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line">          A         B         C         D         E</span><br><span class="line"><span class="number">0</span>  <span class="number">0.673092</span>  <span class="number">0.230338</span> <span class="number">-0.171681</span>  <span class="number">0.312303</span> <span class="number">-0.184813</span></span><br><span class="line"><span class="number">1</span> <span class="number">-0.504482</span> <span class="number">-0.344286</span> <span class="number">-0.050845</span> <span class="number">-0.811277</span> <span class="number">-0.298181</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.542788</span>  <span class="number">0.207708</span>  <span class="number">0.651379</span> <span class="number">-0.656214</span>  <span class="number">0.507595</span></span><br><span class="line"><span class="number">3</span> <span class="number">-0.249410</span>  <span class="number">0.131549</span> <span class="number">-2.198480</span> <span class="number">-0.437407</span>  <span class="number">1.628228</span></span><br></pre></td></tr></table></figure></li><li><p>计算各列数据总和并作为新列添加到末尾</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'Col_sum'</span>] = df.apply(<span class="keyword">lambda</span> x: x.sum(), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ul><p>计算各行数据总和并作为新行添加到末尾<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.loc[<span class="string">'Row_sum'</span>] = df.apply(<span class="keyword">lambda</span> x: x.sum())</span><br></pre></td></tr></table></figure></p><p>最终数据结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">                A         B         C         D         E   Col_sum</span><br><span class="line"><span class="number">0</span>        <span class="number">0.673092</span>  <span class="number">0.230338</span> <span class="number">-0.171681</span>  <span class="number">0.312303</span> <span class="number">-0.184813</span>  <span class="number">0.859238</span></span><br><span class="line"><span class="number">1</span>       <span class="number">-0.504482</span> <span class="number">-0.344286</span> <span class="number">-0.050845</span> <span class="number">-0.811277</span> <span class="number">-0.298181</span> <span class="number">-2.009071</span></span><br><span class="line"><span class="number">2</span>        <span class="number">0.542788</span>  <span class="number">0.207708</span>  <span class="number">0.651379</span> <span class="number">-0.656214</span>  <span class="number">0.507595</span>  <span class="number">1.253256</span></span><br><span class="line"><span class="number">3</span>       <span class="number">-0.249410</span>  <span class="number">0.131549</span> <span class="number">-2.198480</span> <span class="number">-0.437407</span>  <span class="number">1.628228</span> <span class="number">-1.125520</span></span><br><span class="line">Row_sum  <span class="number">0.461987</span>  <span class="number">0.225310</span> <span class="number">-1.769627</span> <span class="number">-1.592595</span>  <span class="number">1.652828</span> <span class="number">-1.022097</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>sohu_news_classification</title>
      <link href="/2018/08/24/sohu-news-classification/"/>
      <url>/2018/08/24/sohu-news-classification/</url>
      <content type="html"><![CDATA[<h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><ul><li>数据是从搜狐新闻开放的新闻xml数据，经过一系列的处理之后，生成的一个excel文件</li><li>该xml文件的处理有单独的处理过程，就是用pandas处理，该过程在此省略</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><ul><li>读取新闻文本文件，查看文本的长度</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=pd.read_excel(<span class="string">'sohu_data.xlsx'</span>)</span><br><span class="line">df[<span class="string">'length'</span>]=df[<span class="string">'content'</span>].apply(<span class="keyword">lambda</span> x: len(x)).values</span><br></pre></td></tr></table></figure><ul><li>去掉长度小于50的文本</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_data = df[df[<span class="string">'length'</span>]&gt;=<span class="number">50</span>][[<span class="string">'content'</span>,<span class="string">'category'</span>]]</span><br></pre></td></tr></table></figure><ul><li>查看新闻类型的分布，共9类</li></ul><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_data[<span class="string">'category'</span>].value_counts()</span><br><span class="line"><span class="comment"># 可以看到这里面存在类别不平衡，最大的差距有7倍。</span></span><br></pre></td></tr></table></figure><pre><code>health      30929news        27613auto        22841stock       18152it          13875yule        13785women        4667book         4411business     1769Name: category, dtype: int64</code></pre><ul><li>使用sklearn中的处理模块的labelEncoder方法对类标进行处理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">class_le=LabelEncoder()</span><br><span class="line">class_le.fit(np.unique(df[<span class="string">'category'</span>].values)</span><br><span class="line">print(list(class_le.classes_))</span><br><span class="line">y=class_le.transform(df[<span class="string">'category'</span>].values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看前20个新闻样本的类别</span></span><br><span class="line">y[:<span class="number">20</span>]</span><br></pre></td></tr></table></figure><pre><code>[&apos;auto&apos;, &apos;book&apos;, &apos;business&apos;, &apos;health&apos;, &apos;it&apos;, &apos;news&apos;, &apos;stock&apos;, &apos;women&apos;, &apos;yule&apos;]array([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], dtype=int64)</code></pre><ul><li>导入jieba，进行分词</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chinese_word_cut</span><span class="params">(mytext)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(jieba.cut(mytext))</span><br><span class="line">X=pd.DataFrame()</span><br><span class="line">X[<span class="string">'cut_content'</span>]=df[<span class="string">"content"</span>].apply(chinese_word_cut)</span><br><span class="line">X[<span class="string">'cut_content'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>Building prefix dict from the default dictionary ...Loading model from cache C:\Users\HUANG_~1\AppData\Local\Temp\jieba.cacheLoading model cost 0.966 seconds.Prefix dict has been built succesfully.1    产品名称 ：  规格 及 价格 ： ３ ０ ｍ ｌ ／ ３ ０ ０ 　 元  羽西 当归...2    常见问题  Ｑ ： 为什么 我 提交 不了 试用 申请 　 Ａ ： 试用 申请 必须 同时...3    产品名称 ： 肌醇 （ Ｐ ｕ ｒ ｅ 　 Ｓ ｋ ｉ ｎ ） 深层 卸妆 凝胶  规格 ...4    欧诗漫 的 试用装 终于 延期 而 至 ， 果然 不负 所望 ， 包装 很 精美 。 从 快...5    试用 申请 步骤  １ 注册 并 完善 个人资料 　 登入 搜狐 试用 频道 ， 填写 并...Name: cut_content, dtype: object</code></pre><ul><li>使用词袋模型进行文本处理，去除停用词，去除数字特征，使用朴素贝叶斯进行分类</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test= train_test_split(X,y,random_state=<span class="number">42</span>,test_size=<span class="number">0.25</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_custom_stopwords</span><span class="params">(stop_words_file)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(stop_words_file,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        custom_stopwords_list=[i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines()]</span><br><span class="line">    <span class="keyword">return</span> custom_stopwords_list</span><br><span class="line">stop_words_file = <span class="string">"stopwords.txt"</span></span><br><span class="line">stopwords = get_custom_stopwords(stop_words_file) <span class="comment"># 获取停用词</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span>  CountVectorizer</span><br><span class="line">vect = CountVectorizer(token_pattern=<span class="string">u'(?u)\\b[^\\d\\W]\\w+\\b'</span>,stop_words=frozenset(stopwords))</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">nb=MultinomialNB()</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line">pipe=make_pipeline(vect,nb)</span><br><span class="line">pipe.fit(X_train.cut_content, y_train)</span><br><span class="line">y_pred = pipe.predict(X_test.cut_content)</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  metrics</span><br><span class="line">print(metrics.accuracy_score(y_test,y_pred))</span><br><span class="line">metrics.confusion_matrix(y_test,y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.897216216938array([[6266,  163,    2,  249,    5,  345,   66,   74,   53],       [   5, 1118,    0,    0,    0,   31,    2,    5,   37],       [   8,    4,   15,    0,    0,  104,  329,    5,    3],       [   4,    1,    0, 8230,    0,   64,    6,    1,    0],       [  59,   29,    0,   10, 3672,   66,   29,   26,   45],       [  72,   71,    6,   26,    1, 5683,  756,   60,  193],       [  28,    0,   10,    0,    0,  381, 4275,    0,    2],       [   9,   90,    0,    5,    1,   74,    5,  890,  132],       [   2,   38,    1,    2,    0,   44,    1,   11, 3467]], dtype=int64)</code></pre><ul><li><p>可以看到朴素贝叶斯对该测试集的正确率达到了接近90%</p></li><li><p>对训练集进行评估，正确率91%</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = pipe.predict(X_train.cut_content)</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  metrics</span><br><span class="line">print(metrics.accuracy_score(y_train,y_pred))</span><br></pre></td></tr></table></figure><pre><code>0.913158362989</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br></pre></td></tr></table></figure><ul><li>随后我们使用逻辑回归模型进行拟合模型并对测试集进行预测，测试集准确率达到94%</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lr=LogisticRegression()  </span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line">pipe=make_pipeline(vect,lr)</span><br><span class="line">pipe.fit(X_train.cut_content, y_train)</span><br><span class="line">y_pred = pipe.predict(X_test.cut_content)</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  metrics</span><br><span class="line">print(metrics.accuracy_score(y_test,y_pred))</span><br><span class="line">metrics.confusion_matrix(y_test,y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.944644620599array([[7079,    3,    3,    5,   19,   62,   27,   10,   15],       [  43, 1131,    1,    0,    3,    3,    4,    6,    7],       [  16,    0,   36,    1,    1,  106,  296,    7,    5],       [   7,    0,    0, 8298,    0,    1,    0,    0,    0],       [  48,    1,    0,    0, 3870,    9,    2,    1,    5],       [  60,   12,   22,   14,    9, 6453,  218,   35,   45],       [  36,    1,  140,    0,    7,  415, 4090,    3,    4],       [  48,   28,    1,    1,   10,   54,    6, 1008,   50],       [  44,   12,    0,    1,   10,   38,    4,   29, 3428]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">tree=DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>,random_state=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line">bag=BaggingClassifier(base_estimator=tree,</span><br><span class="line">                     n_estimators=<span class="number">10</span>,</span><br><span class="line">                     max_samples=<span class="number">1.0</span>,</span><br><span class="line">                     max_features=<span class="number">1.0</span>,</span><br><span class="line">                     bootstrap=<span class="keyword">True</span>,</span><br><span class="line">                     bootstrap_features=<span class="keyword">False</span>,</span><br><span class="line">                     n_jobs=<span class="number">4</span>,random_state=<span class="number">1</span>)</span><br><span class="line">pipe=make_pipeline(vect,bag)</span><br><span class="line">pipe.fit(X_train.cut_content, y_train)</span><br><span class="line">y_pred = pipe.predict(X_test.cut_content)</span><br><span class="line">metrics.accuracy_score(y_test,y_pred)</span><br></pre></td></tr></table></figure><ul><li>使用bagging的方法将决策树进行ensemble，得到的准确率比逻辑回归低了1%<br>  0.9294045426642111</li><li>通过对混淆矩阵进行分析，我们返现对第三类，也就是business类的误分类较多，后续需要改进的模型<ul><li>可以使用td-idf进行文本特征处理</li><li>word2vector与深度学习的方式进行结合，测试文本分类效果</li></ul></li></ul>]]></content>
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>meituan_comment_LogisticRegression</title>
      <link href="/2018/08/16/meituan-comment-LogisticRegression/"/>
      <url>/2018/08/16/meituan-comment-LogisticRegression/</url>
      <content type="html"><![CDATA[<h3 id="美团店铺评价语言处理以及分类（LogisticRegression）"><a href="#美团店铺评价语言处理以及分类（LogisticRegression）" class="headerlink" title="美团店铺评价语言处理以及分类（LogisticRegression）"></a>美团店铺评价语言处理以及分类（LogisticRegression）</h3><ul><li>主要用到的包有jieba，sklearn，pandas</li><li>本篇博文主要先用的是词袋模型(bag of words),将文本以数值特征向量的形式来表示(每个文档构建一个特征向量，有很多的0，类似于前文说的category类的one-hot形式，得到的矩阵为稀疏矩阵)</li><li>比较朴素贝叶斯方法，逻辑回归两种分类算法</li><li>逻辑回归算法的参数细节以及参数调优</li></ul><a id="more"></a><h4 id="导入数据分析常用库"><a href="#导入数据分析常用库" class="headerlink" title="导入数据分析常用库"></a>导入数据分析常用库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><ul><li>读取文件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=pd.read_excel(<span class="string">"all_data_meituan.xlsx"</span>)[[<span class="string">"comment"</span>,<span class="string">"star"</span>]]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><h4 id="上一博客中数据预处理，忘记的可以打开此链接复习"><a href="#上一博客中数据预处理，忘记的可以打开此链接复习" class="headerlink" title="上一博客中数据预处理，忘记的可以打开此链接复习"></a><a href="https://point6013.github.io/2018/08/14/meituan-comment-nlp/" target="_blank" rel="noopener">上一博客中数据预处理，忘记的可以打开此链接复习</a></h4><ul><li>直接上处理好的特征，如下</li></ul><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu9c4y3h26j20u5057wem.jpg" alt=""></p><ul><li>朴素贝叶斯作为文本界的快速分类，这次将他作为对比的初始模型，将朴素贝叶斯与逻辑回归进行比较</li></ul><h4 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h4><ul><li>从sklearn 朴素贝叶斯中导入多维贝叶斯</li><li>朴素贝叶斯通常用来处理文本分类垃圾短信，速度飞快，效果一般都不会差很多</li><li>MultinomialNB类可以选择默认参数，如果模型预测能力不符合要求，可以适当调整</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">nb=MultinomialNB()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline <span class="comment"># 导入make_pipeline方法</span></span><br><span class="line">pipe=make_pipeline(vect,nb)</span><br><span class="line">pipe.steps <span class="comment">#  查看pipeline的步骤（与pipeline相似）</span></span><br></pre></td></tr></table></figure><pre><code>[(&apos;countvectorizer&apos;,  CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,          dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,          lowercase=True, max_df=1.0, max_features=None, min_df=1,          ngram_range=(1, 1), preprocessor=None,          stop_words=frozenset({&apos;&apos;, &apos;范围&apos;, &apos;但愿&apos;, &apos;vs&apos;, &apos;为&apos;, &apos;过去&apos;, &apos;集中&apos;, &apos;这般&apos;, &apos;孰知&apos;, &apos;认为&apos;, &apos;论&apos;, &apos;36&apos;, &apos;前后&apos;, &apos;每年&apos;, &apos;长期以来&apos;, &apos;our&apos;, &apos;要不&apos;, &apos;使用&apos;, &apos;好象&apos;, &apos;such&apos;, &apos;不但&apos;, &apos;一下&apos;, &apos;how&apos;, &apos;召开&apos;, &apos;6&apos;, &apos;全体&apos;, &apos;严格&apos;, &apos;除开&apos;, &apos;get&apos;, &apos;可好&apos;, &apos;毕竟&apos;, &apos;but&apos;, &apos;如前所述&apos;, &apos;满足&apos;, &apos;your&apos;, &apos;keeps&apos;, &apos;只&apos;, &apos;大抵&apos;, &apos;己&apos;, &apos;concerning&apos;, &quot;they&apos;re&quot;, &apos;再则&apos;, &apos;有意的&apos;...&apos;reasonably&apos;, &apos;绝对&apos;, &apos;咧&apos;, &apos;除此以外&apos;, &apos;50&apos;, &apos;得了&apos;, &apos;seeming&apos;, &apos;只是&apos;, &apos;背靠背&apos;, &apos;弗&apos;, &apos;need&apos;, &apos;其&apos;, &apos;第二&apos;, &apos;再者说&apos;}),          strip_accents=None, token_pattern=&apos;(?u)\\b[^\\d\\W]\\w+\\b&apos;,          tokenizer=None, vocabulary=None)), (&apos;multinomialnb&apos;, MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipe.fit(X_train.cut_comment, y_train)</span><br></pre></td></tr></table></figure><pre><code>Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=...e, vocabulary=None)), (&apos;multinomialnb&apos;, MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])</code></pre><h4 id="测试集预测结果"><a href="#测试集预测结果" class="headerlink" title="测试集预测结果"></a>测试集预测结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = pipe.predict(X_test.cut_comment) </span><br><span class="line"><span class="comment"># 对测试集进行预测（其中包括了转化以及预测）</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型对于测试集的准确率</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  metrics</span><br><span class="line">metrics.accuracy_score(y_test,y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.82929936305732488</code></pre><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><h4 id="模型构建-1"><a href="#模型构建-1" class="headerlink" title="模型构建"></a>模型构建</h4><ul><li>首先使用默认的逻辑回归参数进行预实验</li><li>默认参数为 solver = liblinear， max_iter=100，multi_class=’ovr’，penalty=’l2’</li><li>为了演示方便，我们没有把make_pipeline 改写为函数，而是单独的调用，使步骤更为清楚</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment"># lr=LogisticRegression(solver='saga',max_iter=10000)</span></span><br><span class="line">lr=LogisticRegression()  <span class="comment"># 实例化</span></span><br><span class="line">pipe_lr=make_pipeline(vect,lr) </span><br><span class="line">pipe_lr.steps</span><br></pre></td></tr></table></figure><pre><code>[(&apos;countvectorizer&apos;,  CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,          dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,          lowercase=True, max_df=1.0, max_features=None, min_df=1,          ngram_range=(1, 1), preprocessor=None,          stop_words=frozenset({&apos;&apos;, &apos;besides&apos;, &apos;中小&apos;, &apos;不管怎样&apos;, &apos;引起&apos;, &apos;它们的&apos;, &apos;take&apos;, &quot;c&apos;s&quot;, &apos;hopefully&apos;, &apos;no&apos;, &apos;就算&apos;, &apos;断然&apos;, &apos;直到&apos;, &apos;some&apos;, &apos;最后一班&apos;, &apos;许多&apos;, &apos;非独&apos;, &apos;嘻&apos;, &apos;：&apos;, &apos;时&apos;, &apos;两者&apos;, &apos;惟其&apos;, &apos;从优&apos;, &apos;so&apos;, &apos;specified&apos;, &apos;50&apos;, &apos;sometimes&apos;, &apos;明显&apos;, &apos;嗬&apos;, &apos;人家&apos;, &apos;截至&apos;, &apos;开始&apos;, &apos;动不动&apos;, &apos;大体&apos;, &apos;以及&apos;, &apos;使&apos;, &apos;own&apos;, &apos;whoever&apos;, &quot;wasn&apos;t&quot;, &apos;cha...&apos;我是&apos;, &apos;／&apos;, &apos;my&apos;, &apos;再则&apos;, &apos;正常&apos;, &apos;49&apos;, &apos;关于&apos;, &apos;愿意&apos;, &apos;其他&apos;, &apos;这么&apos;, &apos;粗&apos;, &apos;ｃ］&apos;, &apos;＄&apos;, &apos;29&apos;, &apos;要求&apos;, &apos;第十一&apos;, &apos;自后&apos;}),          strip_accents=None, token_pattern=&apos;(?u)\\b[^\\d\\W]\\w+\\b&apos;,          tokenizer=None, vocabulary=None)), (&apos;logisticregression&apos;,  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,            intercept_scaling=1, max_iter=100, multi_class=&apos;ovr&apos;, n_jobs=1,            penalty=&apos;l2&apos;, random_state=None, solver=&apos;liblinear&apos;, tol=0.0001,            verbose=0, warm_start=False))]</code></pre><ul><li>逻辑回归模型默认参数，对应同样的测试集0.82929936305732488，还是提高了5%，这是在默认的solver情况下，未调整正则化等其余参数</li></ul><h4 id="测试集预测结果-1"><a href="#测试集预测结果-1" class="headerlink" title="测试集预测结果"></a>测试集预测结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pipe_lr.fit(X_train.cut_comment, y_train)</span><br><span class="line">y_pred_lr = pipe_lr.predict(X_test.cut_comment)</span><br><span class="line">metrics.accuracy_score(y_test,y_pred_lr)</span><br></pre></td></tr></table></figure><pre><code>0.87261146496815289</code></pre><ul><li>现在我们将solver修改为saga，penalty默认是l2,重新进行模型拟合与预测</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr_solver = LogisticRegression(solver=<span class="string">'saga'</span>)</span><br><span class="line">pipe_lr1=make_pipeline(vect,lr_solver)</span><br><span class="line">pipe_lr1.steps</span><br></pre></td></tr></table></figure><pre><code>[(&apos;countvectorizer&apos;,  CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,          dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,          lowercase=True, max_df=1.0, max_features=None, min_df=1,          ngram_range=(1, 1), preprocessor=None,          stop_words=frozenset({&apos;&apos;, &apos;besides&apos;, &apos;中小&apos;, &apos;不管怎样&apos;, &apos;引起&apos;, &apos;它们的&apos;, &apos;take&apos;, &quot;c&apos;s&quot;, &apos;hopefully&apos;, &apos;no&apos;, &apos;就算&apos;, &apos;断然&apos;, &apos;直到&apos;, &apos;some&apos;, &apos;最后一班&apos;, &apos;许多&apos;, &apos;非独&apos;, &apos;嘻&apos;, &apos;：&apos;, &apos;时&apos;, &apos;两者&apos;, &apos;惟其&apos;, &apos;从优&apos;, &apos;so&apos;, &apos;specified&apos;, &apos;50&apos;, &apos;sometimes&apos;, &apos;明显&apos;, &apos;嗬&apos;, &apos;人家&apos;, &apos;截至&apos;, &apos;开始&apos;, &apos;动不动&apos;, &apos;大体&apos;, &apos;以及&apos;, &apos;使&apos;, &apos;own&apos;, &apos;whoever&apos;, &quot;wasn&apos;t&quot;, &apos;cha...&apos;我是&apos;, &apos;／&apos;, &apos;my&apos;, &apos;再则&apos;, &apos;正常&apos;, &apos;49&apos;, &apos;关于&apos;, &apos;愿意&apos;, &apos;其他&apos;, &apos;这么&apos;, &apos;粗&apos;, &apos;ｃ］&apos;, &apos;＄&apos;, &apos;29&apos;, &apos;要求&apos;, &apos;第十一&apos;, &apos;自后&apos;}),          strip_accents=None, token_pattern=&apos;(?u)\\b[^\\d\\W]\\w+\\b&apos;,          tokenizer=None, vocabulary=None)), (&apos;logisticregression&apos;,  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,            intercept_scaling=1, max_iter=100, multi_class=&apos;ovr&apos;, n_jobs=1,            penalty=&apos;l2&apos;, random_state=None, solver=&apos;saga&apos;, tol=0.0001,            verbose=0, warm_start=False))]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipe_lr1.fit(X_train.cut_comment, y_train)</span><br></pre></td></tr></table></figure><pre><code>C:\Anaconda3\envs\nlp\lib\site-packages\sklearn\linear_model\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge  &quot;the coef_ did not converge&quot;, ConvergenceWarning)Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=...penalty=&apos;l2&apos;, random_state=None, solver=&apos;saga&apos;, tol=0.0001,          verbose=0, warm_start=False))])</code></pre><ul><li>出现这个提示，说明solver参数在saga(随机平均梯度下降)情况下，系数没有收敛，随机平均梯度需要更大的迭代次数，需要调整最大迭代次数max_iter</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># C:\Anaconda3\envs\nlp\lib\site-packages\sklearn\linear_model\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge</span></span><br><span class="line"><span class="comment">#   "the coef_ did not converge", ConvergenceWarning)</span></span><br><span class="line"><span class="comment"># 出现这个提示，说明solver参数在saga(随机平均梯度下降)情况下，系数没有收敛，随机平均梯度需要更大的迭代次数，需要调整最大迭代次数max_iter</span></span><br><span class="line"><span class="comment"># 这里需要强调一点，这并不是说saga性能不好，saga针对大的数据集收敛速度比其他的优化算法更快。</span></span><br></pre></td></tr></table></figure><ul><li>重新设定了mat_iter之后，进行重新拟合，准确率达到 0.87388535031847137，准确率微弱提升</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lr_solver = LogisticRegression(solver=<span class="string">'saga'</span>,max_iter=<span class="number">10000</span>)</span><br><span class="line">pipe_lr1=make_pipeline(vect,lr_solver)</span><br><span class="line">pipe_lr1.steps</span><br><span class="line">pipe_lr1.fit(X_train.cut_comment, y_train)</span><br></pre></td></tr></table></figure><pre><code>Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=...penalty=&apos;l2&apos;, random_state=None, solver=&apos;saga&apos;, tol=0.0001,          verbose=0, warm_start=False))])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred_lr1 = pipe_lr1.predict(X_test.cut_comment)</span><br><span class="line">metrics.accuracy_score(y_test,y_pred_lr1)</span><br></pre></td></tr></table></figure><pre><code>0.87388535031847137</code></pre><h3 id="这里补充一些关于逻辑回归的参数"><a href="#这里补充一些关于逻辑回归的参数" class="headerlink" title="这里补充一些关于逻辑回归的参数"></a>这里补充一些关于逻辑回归的参数</h3><ul><li><p>solvers 优化模型</p><ul><li>相对与小规模数据liblinear的收敛速度更快，准确率与saga准确率相差无几</li><li>saga是sag的一种变体，同时支持两种正则化后面需进一步的调整正则化强度以及类别（l1,l2）</li><li>sklearn官网推荐一般情况下使用saga优化算法，同时支持l1,l2 正则化，而且对于大数据来说收敛速度更快。</li><li>sag，lbfgs，newton-cg支持l2正则化，对于多维数据收敛速度比较快(特征多)，不支持l1正则,(损失函数需要一阶或者二阶连续导数)</li><li>saga <strong>优化算法更适合在大规模数据集（数据量与特征量）都很大的情况，表现效果会非常好，saga优化算法支持l1正则化，可适用于多维的稀疏矩阵</strong></li><li>liblinear 使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数，同时支持(l1,l2),不支持真正的多分类（通过ovr实现的多分类）</li><li>lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。</li><li>newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。</li></ul></li><li><p>logitisct regression参数中的C是正则化系数λ的倒数(交叉验证参数Cs，list of floats 或者 int)</p></li><li><p>penalty 正则化选择参数（l1，l2)</p></li><li><p>multi_class 分类方式的选择参数（ovr，mvm）</p><ul><li>ovr 五种方式都支持，mvm 不支持liblinear</li></ul></li><li><p>class_weith 类型权重参数</p><ul><li>class_weight={0:0.9,1:0.1} 表示类型0的权重为90%，类型1的权重是10%，如果选择class_weith=’balanced’,那么就根据训练样本来计算权重，某类的样本越多，则权重越低，样本量越少，则权重越高。</li><li>误分类的代价很高，对于正常人与患病者进行分类，将患者划分为正常人的代价很大，我们宁愿将正常人分类为患者，这是还有进行人工干预，但是不愿意将患者漏检，这时我们可以将患者的权重适当提高</li><li>第二种情况是 样本高度失衡，比如患者和正常人的比例是1：700，如果不考虑权重，很容易得到一个预测准确率非常高的分类器，但是没有啥意义，这是可以选择balanced参数，分类器会自动根据患者比例进行调整权重。</li></ul></li><li><p>sample_weight 样本权重参数</p><ul><li>由于样本不平衡，导致样本不是总体样本的无偏估计，可能导致模型的检出率很低，调节样本权重有两种方式：</li><li>在class_weight 使用balance参数，第二种是在fit(X, y, sample_weight=None) 拟合模型的时候，调整sample_weight</li></ul></li><li><p>迭代次数 max_iter 默认值100，有的优化算法在默认的迭代次数时，损失函数未收敛，需要调整迭代次数</p></li></ul><h4 id="LogisticRegressionCV优化参数"><a href="#LogisticRegressionCV优化参数" class="headerlink" title="LogisticRegressionCV优化参数"></a>LogisticRegressionCV优化参数</h4><ul><li>LogisticRegressionCV 方法 默认是l2正则化,solver设定为saga</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">t1=time.time()</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegressionCV</span><br><span class="line">lrvc = LogisticRegressionCV(Cs=[<span class="number">0.0001</span>,<span class="number">0.005</span>,<span class="number">0.001</span>,<span class="number">0.05</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">10</span>],scoring=<span class="string">'accuracy'</span>,random_state=<span class="number">42</span>,solver=<span class="string">'saga'</span>,max_iter=<span class="number">10000</span>,penalty=<span class="string">'l2'</span>)</span><br><span class="line">pipe=make_pipeline(vect,lrvc)</span><br><span class="line">print(pipe.get_params)</span><br><span class="line">pipe.fit(X_train.cut_comment, y_train)</span><br><span class="line">y_pred=pipe.predict(X_test.cut_comment)</span><br><span class="line">print(metrics.accuracy_score(y_test,y_pred))</span><br><span class="line">t2=time.time()</span><br><span class="line">print(<span class="string">"time spent l2,saga"</span>,t2-t1)</span><br></pre></td></tr></table></figure><pre><code>&lt;bound method Pipeline.get_params of Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=... random_state=42, refit=True,           scoring=&apos;accuracy&apos;, solver=&apos;saga&apos;, tol=0.0001, verbose=0))])&gt;0.899363057325time spent l2,saga 5.017577648162842</code></pre><ul><li>LogisticRegressionCV 方法 solver设定为saga,l1正则化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">t1=time.time()</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegressionCV</span><br><span class="line">lrvc = LogisticRegressionCV(Cs=[<span class="number">0.0001</span>,<span class="number">0.005</span>,<span class="number">0.001</span>,<span class="number">0.05</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">10</span>],scoring=<span class="string">'accuracy'</span>,random_state=<span class="number">42</span>,solver=<span class="string">'saga'</span>,max_iter=<span class="number">10000</span>,penalty=<span class="string">'l1'</span>)</span><br><span class="line">pipe_cvl1=make_pipeline(vect,lrvc)</span><br><span class="line">print(pipe_cvl1.get_params)</span><br><span class="line">pipe_cvl1.fit(X_train.cut_comment, y_train)</span><br><span class="line">y_pred=pipe_cvl1.predict(X_test.cut_comment)</span><br><span class="line">print(metrics.accuracy_score(y_test,y_pred))</span><br><span class="line">t2=time.time()</span><br><span class="line">print(<span class="string">"time spent l1,saga"</span>,t2-t1)</span><br></pre></td></tr></table></figure><pre><code>&lt;bound method Pipeline.get_params of Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=... random_state=42, refit=True,           scoring=&apos;accuracy&apos;, solver=&apos;saga&apos;, tol=0.0001, verbose=0))])&gt;0.915923566879time spent l1,saga 64.17242479324341</code></pre><ul><li>l1正则化相比l2正则化，在saga优化器模式下，达到最佳参数所需要的时间增加</li></ul><ul><li>同时我们又验证了liblinear与saga在l1正则化的情况下，达到最佳参数需要的时间，差距接近120倍</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LogisticRegressionCV 方法 l1正则化，sovler liblinear，速度比saga快的多，很快就收敛了，准确率没有什么差别，只是不支持真正的多分类（为liblinear 打call）</span></span><br><span class="line">t3=time.time()</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegressionCV</span><br><span class="line">lrvc = LogisticRegressionCV(Cs=[<span class="number">0.0001</span>,<span class="number">0.005</span>,<span class="number">0.001</span>,<span class="number">0.05</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">10</span>],scoring=<span class="string">'accuracy'</span>,random_state=<span class="number">42</span>,solver=<span class="string">'liblinear'</span>,max_iter=<span class="number">10000</span>,penalty=<span class="string">'l1'</span>)</span><br><span class="line">pipe_cvl1=make_pipeline(vect,lrvc)</span><br><span class="line">print(pipe_cvl1.get_params)</span><br><span class="line">pipe_cvl1.fit(X_train.cut_comment, y_train)</span><br><span class="line">y_pred=pipe_cvl1.predict(X_test.cut_comment)</span><br><span class="line">print(<span class="string">"accuracy"</span>:metrics.accuracy_score(y_test,y_pred))</span><br><span class="line">t4=time.time()</span><br><span class="line">print(<span class="string">"time spent l1 liblinear "</span>,t4-t3)</span><br></pre></td></tr></table></figure><pre><code>&lt;bound method Pipeline.get_params of Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=...om_state=42, refit=True,           scoring=&apos;accuracy&apos;, solver=&apos;liblinear&apos;, tol=0.0001, verbose=0))])&gt;&quot;accuracy&quot;:0.912101910828time spent l1 liblinear  0.22439861297607422</code></pre>]]></content>
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logistic regression </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>meituan_comment_nlp</title>
      <link href="/2018/08/14/meituan-comment-nlp/"/>
      <url>/2018/08/14/meituan-comment-nlp/</url>
      <content type="html"><![CDATA[<h3 id="美团店铺评价语言处理以及分类（NLP）"><a href="#美团店铺评价语言处理以及分类（NLP）" class="headerlink" title="美团店铺评价语言处理以及分类（NLP）"></a>美团店铺评价语言处理以及分类（NLP）</h3><ul><li>上两篇博客中介绍了美团店铺的订单信息以及数据分析以及可视化</li><li>其中还有一部分评论文本信息并没有提及到，自然也就有了这篇</li><li>主要用到的包有jieba，sklearn，pandas</li><li>本篇博文主要先用的是词袋模型(bag of words),将文本以数值特征向量的形式来表示(每个文档构建一个特征向量，有很多的0，出现在特征向量中的值也叫做原始词频，tf(term frequency), 得到的矩阵为稀疏矩阵)</li></ul><h4 id="导入数据分析常用库"><a href="#导入数据分析常用库" class="headerlink" title="导入数据分析常用库"></a>导入数据分析常用库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><ul><li>读取文件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=pd.read_excel(<span class="string">"all_data_meituan.xlsx"</span>)[[<span class="string">"comment"</span>,<span class="string">"star"</span>]]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu9bm7nc6tj20qm0bijtc.jpg" alt=""></p><ul><li>查看DataFrame的大小</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.shape</span><br></pre></td></tr></table></figure><pre><code>(17400, 2)</code></pre><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'sentiment'</span>]=df[<span class="string">'star'</span>].apply(<span class="keyword">lambda</span> x:<span class="number">1</span> <span class="keyword">if</span> x&gt;<span class="number">30</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">df=df.drop_duplicates() <span class="comment">## 去掉重复的评论，剩余的文本1406条，我们将数据复制为原有数据的三倍</span></span><br><span class="line">df=df.dropna()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X=pd.concat([df[[<span class="string">'comment'</span>]],df[[<span class="string">'comment'</span>]],df[[<span class="string">'comment'</span>]]])</span><br><span class="line">y=pd.concat([df.sentiment,df.sentiment,df.sentiment])</span><br><span class="line">X.columns=[<span class="string">'comment'</span>]</span><br><span class="line">X.reset_index</span><br><span class="line">X.shape</span><br></pre></td></tr></table></figure><pre><code>(3138, 1)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba <span class="comment"># 导入分词库</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chinese_word_cut</span><span class="params">(mytext)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(jieba.cut(mytext))</span><br><span class="line">X[<span class="string">'cut_comment'</span>]=X[<span class="string">"comment"</span>].apply(chinese_word_cut)</span><br><span class="line">X[<span class="string">'cut_comment'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>Building prefix dict from the default dictionary ...DEBUG:jieba:Building prefix dict from the default dictionary ...Loading model from cache C:\Users\HUANG_~1\AppData\Local\Temp\jieba.cacheDEBUG:jieba:Loading model from cache C:\Users\HUANG_~1\AppData\Local\Temp\jieba.cacheLoading model cost 0.880 seconds.DEBUG:jieba:Loading model cost 0.880 seconds.Prefix dict has been built succesfully.DEBUG:jieba:Prefix dict has been built succesfully.0    还行 吧 ， 建议 不要 排队 那个 烤鸭 和 羊肉串 ， 因为 烤肉 时间 本来 就 不够...1    去过 好 几次 了   东西 还是 老 样子   没 增添 什么 新花样   环境 倒 是 ...2    一个 字 ： 好 ！ ！ ！   # 羊肉串 #   # 五花肉 #   # 牛舌 #   ...3    第一次 来 吃 ， 之前 看过 好多 推荐 说 这个 好吃 ， 真的 抱 了 好 大 希望 ...4    羊肉串 真的 不太 好吃 ， 那种 说 膻 不 膻 说 臭 不 臭 的 味 。 烤鸭 还 行...Name: cut_comment, dtype: object</code></pre><ul><li>导入sklearn中的数据分割模块，设定test数据集大小，shuffle默认Ture</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test= train_test_split(X,y,random_state=<span class="number">42</span>,test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure><ul><li>获取停用词 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_custom_stopwords</span><span class="params">(stop_words_file)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(stop_words_file,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        custom_stopwords_list=[i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines()]</span><br><span class="line">    <span class="keyword">return</span> custom_stopwords_list</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop_words_file = <span class="string">"stopwords.txt"</span></span><br><span class="line">stopwords = get_custom_stopwords(stop_words_file) <span class="comment"># 获取停用词</span></span><br></pre></td></tr></table></figure><ul><li>导入词袋模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span>  CountVectorizer</span><br><span class="line">vect=CountVectorizer()  <span class="comment"># 实例化</span></span><br><span class="line">vect <span class="comment"># 查看参数</span></span><br></pre></td></tr></table></figure><pre><code>CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None, stop_words=None,        strip_accents=None, token_pattern=&apos;(?u)\\b\\w\\w+\\b&apos;,        tokenizer=None, vocabulary=None)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dir(vect)  # 查看vect的属性</span></span><br></pre></td></tr></table></figure><ul><li>将分割后的文本进行fit_transform,系数矩阵大小为2353*1965</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vect.fit_transform(X_train[<span class="string">"cut_comment"</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;2353x1965 sparse matrix of type &apos;&lt;class &apos;numpy.int64&apos;&gt;&apos;    with 20491 stored elements in Compressed Sparse Row format&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vect.fit_transform(X_train[<span class="string">"cut_comment"</span>]).toarray().shape</span><br></pre></td></tr></table></figure><pre><code>(2353, 1965)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(vect.fit_transform(X_train[<span class="string">"cut_comment"</span>]).toarray(),columns=vect.get_feature_names()).iloc[:,<span class="number">0</span>:<span class="number">25</span>].head()</span><br><span class="line"><span class="comment"># print(vect.get_feature_names())</span></span><br><span class="line"><span class="comment">#  数据维数1956，不算很大（未使用停用词）</span></span><br><span class="line"><span class="comment"># 将其转化为DataFrame</span></span><br></pre></td></tr></table></figure><ul><li>发现其中有很多的数字以及无效特征，随后传入实例化参数的同时，加入正则匹配取出这些无意义特征，同时去除停用词<br><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu9c1rlvn1j20mo05c74b.jpg" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vect = CountVectorizer(token_pattern=<span class="string">u'(?u)\\b[^\\d\\W]\\w+\\b'</span>,stop_words=frozenset(stopwords)) <span class="comment"># 去除停用词，匹配以数字开头的非单词字符</span></span><br><span class="line">pd.DataFrame(vect.fit_transform(X_train[<span class="string">'cut_comment'</span>]).toarray(), columns=vect.get_feature_names()).head()</span><br><span class="line"><span class="comment"># 1691 columns,去掉以数字为特征值的列，减少了近三百列，由1965减小到1691 </span></span><br><span class="line"><span class="comment"># max_df = 0.8 # 在超过这一比例的文档中出现的关键词（过于平凡），去除掉（可以自行设定）</span></span><br><span class="line"><span class="comment"># min_df = 3 # 在低于这一数量的文档中出现的关键词（过于独特），去除掉。（可以自行设定）</span></span><br></pre></td></tr></table></figure><ul><li>取出数字特征之后</li></ul><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu9c4y3h26j20u5057wem.jpg" alt=""></p><h4 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h4><ul><li>从sklearn 朴素贝叶斯中导入多维贝叶斯</li><li>朴素贝叶斯通常用来处理文本分类垃圾短信，速度飞快，效果一般都不会差很多</li><li>MultinomialNB类可以选择默认参数，如果模型预测能力不符合要求，可以适当调整</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">nb=MultinomialNB()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline <span class="comment"># 导入make_pipeline方法</span></span><br><span class="line">pipe=make_pipeline(vect,nb)</span><br><span class="line">pipe.steps <span class="comment">#  查看pipeline的步骤（与pipeline相似）</span></span><br></pre></td></tr></table></figure><pre><code>[(&apos;countvectorizer&apos;,  CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,          dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,          lowercase=True, max_df=1.0, max_features=None, min_df=1,          ngram_range=(1, 1), preprocessor=None,          stop_words=frozenset({&apos;&apos;, &apos;范围&apos;, &apos;但愿&apos;, &apos;vs&apos;, &apos;为&apos;, &apos;过去&apos;, &apos;集中&apos;, &apos;这般&apos;, &apos;孰知&apos;, &apos;认为&apos;, &apos;论&apos;, &apos;36&apos;, &apos;前后&apos;, &apos;每年&apos;, &apos;长期以来&apos;, &apos;our&apos;, &apos;要不&apos;, &apos;使用&apos;, &apos;好象&apos;, &apos;such&apos;, &apos;不但&apos;, &apos;一下&apos;, &apos;how&apos;, &apos;召开&apos;, &apos;6&apos;, &apos;全体&apos;, &apos;严格&apos;, &apos;除开&apos;, &apos;get&apos;, &apos;可好&apos;, &apos;毕竟&apos;, &apos;but&apos;, &apos;如前所述&apos;, &apos;满足&apos;, &apos;your&apos;, &apos;keeps&apos;, &apos;只&apos;, &apos;大抵&apos;, &apos;己&apos;, &apos;concerning&apos;, &quot;they&apos;re&quot;, &apos;再则&apos;, &apos;有意的&apos;...&apos;reasonably&apos;, &apos;绝对&apos;, &apos;咧&apos;, &apos;除此以外&apos;, &apos;50&apos;, &apos;得了&apos;, &apos;seeming&apos;, &apos;只是&apos;, &apos;背靠背&apos;, &apos;弗&apos;, &apos;need&apos;, &apos;其&apos;, &apos;第二&apos;, &apos;再者说&apos;}),          strip_accents=None, token_pattern=&apos;(?u)\\b[^\\d\\W]\\w+\\b&apos;,          tokenizer=None, vocabulary=None)), (&apos;multinomialnb&apos;, MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipe.fit(X_train.cut_comment, y_train)</span><br></pre></td></tr></table></figure><pre><code>Pipeline(memory=None,     steps=[(&apos;countvectorizer&apos;, CountVectorizer(analyzer=&apos;word&apos;, binary=False, decode_error=&apos;strict&apos;,        dtype=&lt;class &apos;numpy.int64&apos;&gt;, encoding=&apos;utf-8&apos;, input=&apos;content&apos;,        lowercase=True, max_df=1.0, max_features=None, min_df=1,        ngram_range=(1, 1), preprocessor=None,        stop_words=...e, vocabulary=None)), (&apos;multinomialnb&apos;, MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])</code></pre><h4 id="测试集预测结果"><a href="#测试集预测结果" class="headerlink" title="测试集预测结果"></a>测试集预测结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = pipe.predict(X_test.cut_comment) </span><br><span class="line"><span class="comment"># 对测试集进行预测（其中包括了转化以及预测）</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型对于测试集的准确率</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  metrics</span><br><span class="line">metrics.accuracy_score(y_test,y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.82929936305732488</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型对于测试集的混淆矩阵</span></span><br><span class="line">metrics.confusion_matrix(y_test,y_pred)</span><br><span class="line"><span class="comment"># 测试集中的预测结果：真阳性474个，假阳性112个，假阴性22个，真阴性为177个</span></span><br></pre></td></tr></table></figure><pre><code>array([[177, 112],       [ 22, 474]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_confusion_matrix</span><span class="params">(conf,clas)</span>:</span></span><br><span class="line">    <span class="keyword">import</span>  matplotlib.pyplot <span class="keyword">as</span>  plt</span><br><span class="line">    fig,ax=plt.subplots(figsize=(<span class="number">2.5</span>,<span class="number">2.5</span>))</span><br><span class="line">    ax.matshow(conf,cmap=plt.cm.Blues,alpha=<span class="number">0.3</span>)</span><br><span class="line">    tick_marks = np.arange(len(clas))</span><br><span class="line">    plt.xticks(tick_marks,clas, rotation=<span class="number">45</span>)</span><br><span class="line">    plt.yticks(tick_marks, clas)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(conf.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(conf.shape[<span class="number">1</span>]):</span><br><span class="line">            ax.text(x=i,y=j,s=conf[i,j],</span><br><span class="line">                   va=<span class="string">'center'</span>,</span><br><span class="line">                   ha=<span class="string">'center'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"predict_label"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"true label"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conf=metrics.confusion_matrix(y_test,y_pred)</span><br><span class="line">class_names=np.array([<span class="string">'0'</span>,<span class="string">'1'</span>])</span><br><span class="line">get_confusion_matrix(np.array(conf),clas=class_names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu9l64amzrj208807vq2x.jpg" alt=""></p><h4 id="对整个数据集进行预测分类"><a href="#对整个数据集进行预测分类" class="headerlink" title="对整个数据集进行预测分类"></a>对整个数据集进行预测分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred_all = pipe.predict(X[<span class="string">'cut_comment'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metrics.accuracy_score(y,y_pred_all)</span><br><span class="line"><span class="comment"># 对于整个样本集的预测正确率，整个数据集的准确率高于测试集，说明有些过拟合</span></span><br></pre></td></tr></table></figure><pre><code>0.85659655831739967</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metrics.confusion_matrix(y,y_pred_all)</span><br><span class="line"><span class="comment">#  真个数据集的混淆矩阵</span></span><br></pre></td></tr></table></figure><pre><code>array([[ 801,  369],       [  81, 1887]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.value_counts()</span><br><span class="line"><span class="comment"># 初始样本中 正类与负类的数量</span></span><br></pre></td></tr></table></figure><pre><code>1    19680    1170Name: sentiment, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metrics.f1_score(y_true=y,y_pred=y_pred_all)</span><br><span class="line"><span class="comment"># f1_score 评价模型对于真个数据集</span></span><br></pre></td></tr></table></figure><pre><code>0.89346590909090906</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metrics.recall_score(y, y_pred_all)</span><br><span class="line"><span class="comment"># 检出率，也就是正类总样本检出的比例   真正/假阴+真正</span></span><br></pre></td></tr></table></figure><pre><code>0.95884146341463417</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metrics.precision_score(y, y_pred_all)</span><br><span class="line"><span class="comment">#  准确率，  检测出的来正类中真正类的比例  真正/假阳+真正</span></span><br></pre></td></tr></table></figure><pre><code>0.83643617021276595</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(metrics.classification_report(y, y_pred_all))</span><br><span class="line"><span class="comment"># 分类报告</span></span><br></pre></td></tr></table></figure><pre><code>             precision    recall  f1-score   support      0       0.91      0.68      0.78      1170      1       0.84      0.96      0.89      1968avg / total       0.86      0.86      0.85      3138</code></pre>]]></content>
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> naive bayes </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>meituan-data-basic-analysis</title>
      <link href="/2018/08/11/%E7%BE%8E%E5%9B%A2%E6%9F%90%E5%95%86%E5%AE%B6%E7%9A%84%E8%AF%84%E8%AE%BA%E9%94%80%E5%94%AE%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/2018/08/11/%E7%BE%8E%E5%9B%A2%E6%9F%90%E5%95%86%E5%AE%B6%E7%9A%84%E8%AF%84%E8%AE%BA%E9%94%80%E5%94%AE%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<h3 id="基于pandas-python的美团某商家的评论销售数据分析"><a href="#基于pandas-python的美团某商家的评论销售数据分析" class="headerlink" title="基于pandas python的美团某商家的评论销售数据分析"></a>基于pandas python的美团某商家的评论销售数据分析</h3><ul><li>爬虫获得美团某家烧烤店的订单（代码省略）</li><li>数据清洗</li><li>数据初步的统计</li><li>可视化</li><li>数据中的评论数据用于自然语言处理（待续）</li></ul><h4 id="导入相关库"><a href="#导入相关库" class="headerlink" title="导入相关库"></a>导入相关库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar,Pie</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span>  matplotlib.pyplot <span class="keyword">as</span>  plt</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><h4 id="数据清洗与简单统计"><a href="#数据清洗与简单统计" class="headerlink" title="数据清洗与简单统计"></a>数据清洗与简单统计</h4><ul><li>评论数据，其中包括一下几个字段</li><li>是否匿名，均价，评价（以去掉，后续会做一些关于这些评论的更为深入的分析），评价时间，交易截止时间，订单号，套餐，上传的图片链接，质量好坏，阅读量，回复量，评分，点赞数等。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df=pd.read_excel(<span class="string">"all_data_meituan.xlsx"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.drop(<span class="string">'comment'</span>,axis=<span class="number">1</span>).head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu679dm0udj20q104zmxj.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'avgPrice'</span>].value_counts()</span><br><span class="line"><span class="comment"># 同一家店的均价应该为同一个数值，所以这列数据没多大的意义</span></span><br></pre></td></tr></table></figure><pre><code>73    17400Name: avgPrice, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'anonymous'</span>].value_counts()</span><br><span class="line"><span class="comment"># 匿名评价与实名评价的比例大致在5:1左右</span></span><br></pre></td></tr></table></figure><pre><code>False    14402True      2998Name: anonymous, dtype: int64</code></pre><a id="more"></a><h4 id="时间格式的转化"><a href="#时间格式的转化" class="headerlink" title="时间格式的转化"></a>时间格式的转化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convertTime</span><span class="params">(x)</span>:</span></span><br><span class="line">    y=time.localtime(x/<span class="number">1000</span>)</span><br><span class="line">    z=time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>,y)</span><br><span class="line">    <span class="keyword">return</span> z</span><br><span class="line">df[<span class="string">"commentTime"</span>]=df[<span class="string">"commentTime"</span>].apply(convertTime)</span><br><span class="line">df[<span class="string">"commentTime"</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    2018-05-09 22:21:481    2018-06-01 19:41:312    2018-04-04 11:52:233    2018-05-01 17:12:224    2018-05-17 16:48:04Name: commentTime, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在excel可以用筛选器直接看到这列中的数据含有缺失值，或者在拿到数据的时候，使用df.info() 查看每列的数据信息情况</span></span><br><span class="line">df[<span class="string">'dealEndtime'</span>].isna().value_counts()</span><br><span class="line"><span class="comment"># 这列数据中含有177个缺失值，其余完整</span></span><br></pre></td></tr></table></figure><pre><code>False    17223True       177Name: dealEndtime, dtype: int64</code></pre><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu64b1fo14j21dk07kta0.jpg" alt=""></p><ul><li>按月统计</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'commentTime'</span>]=pd.to_datetime(df[<span class="string">'commentTime'</span>])</span><br><span class="line">df1 = df.set_index(<span class="string">'commentTime'</span>)</span><br><span class="line">df1.resample(<span class="string">'D'</span>).size().sort_values(ascending=<span class="keyword">False</span>).head(<span class="number">100</span>)</span><br><span class="line">df2=df1.resample(<span class="string">'M'</span>).size().to_period()</span><br><span class="line">df2=df2.reset_index()</span><br><span class="line"><span class="comment"># df2.columns</span></span><br><span class="line"><span class="comment"># from pyecharts import  Bar</span></span><br><span class="line">bar =Bar(<span class="string">"按月统计"</span>,width=<span class="number">1000</span>,height=<span class="number">800</span>)</span><br><span class="line">bar.add(<span class="string">"按月统计"</span>,df2[<span class="string">'commentTime'</span>],df2[<span class="number">0</span>],is_label_show=<span class="keyword">True</span>, is_datazoom_show=<span class="keyword">True</span>,is_toolbox_show=<span class="keyword">True</span>,is_more_utils=<span class="keyword">True</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu6argpgrzj20rs0b4mxm.jpg" alt=""></p><ul><li>按周统计<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'commentTime'</span>]=pd.to_datetime(df[<span class="string">'commentTime'</span>])</span><br><span class="line">df[<span class="string">'weekday'</span>] = df[<span class="string">'commentTime'</span>].dt.weekday</span><br><span class="line">df2= df.groupby([<span class="string">'weekday'</span>]).size()</span><br><span class="line"><span class="comment">#  周末吃外卖的还是教平时多了一些</span></span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Bar</span><br><span class="line">bar =Bar(<span class="string">"按周统计"</span>,width=<span class="number">750</span>,height=<span class="number">400</span>)</span><br><span class="line">weekday=[<span class="string">"一"</span>,<span class="string">"二"</span>,<span class="string">"三"</span>,<span class="string">"四"</span>,<span class="string">"五"</span>,<span class="string">"六"</span>,<span class="string">"日"</span>]</span><br><span class="line">bar.add(<span class="string">"按周统计"</span>,[<span class="string">'周&#123;&#125;'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> weekday],df2.values,is_label_show=<span class="keyword">True</span>, is_datazoom_show=<span class="keyword">False</span>,is_toolbox_show=<span class="keyword">True</span>,is_more_utils=<span class="keyword">True</span>,is_random=<span class="keyword">True</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure></li></ul><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1fu6as7lylzj20ku0b4q37.jpg" alt=""></p><ul><li>按天统计</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'commentTime'</span>]=pd.to_datetime(df[<span class="string">'commentTime'</span>])</span><br><span class="line">df[<span class="string">'day'</span>] = df[<span class="string">'commentTime'</span>].dt.day</span><br><span class="line">df2= df.groupby([<span class="string">'day'</span>]).size()</span><br><span class="line">df2</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Bar</span><br><span class="line">bar =Bar(<span class="string">"按天统计"</span>,width=<span class="number">1000</span>,height=<span class="number">400</span>)</span><br><span class="line">bar.add(<span class="string">"按天统计"</span>,[<span class="string">'&#123;&#125; 日'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> df2.index],df2.values,is_label_show=<span class="keyword">True</span>, is_datazoom_show=<span class="keyword">True</span>,is_toolbox_show=<span class="keyword">True</span>,is_more_utils=<span class="keyword">True</span>,is_random=<span class="keyword">True</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1fu6au38nk7j20rs0b43zb.jpg" alt=""></p><ul><li>按时统计</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'commentTime'</span>]=pd.to_datetime(df[<span class="string">'commentTime'</span>])</span><br><span class="line">df[<span class="string">'hour'</span>] = df[<span class="string">'commentTime'</span>].dt.hour</span><br><span class="line">df2= df.groupby([<span class="string">'hour'</span>]).size()</span><br><span class="line">df2</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Bar</span><br><span class="line">bar =Bar(<span class="string">"按时统计"</span>,width=<span class="number">1000</span>,height=<span class="number">600</span>)</span><br><span class="line">bar.add(<span class="string">"按时统计"</span>,[<span class="string">'&#123;&#125; h'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> df2.index],df2.values,is_label_show=<span class="keyword">True</span>, is_datazoom_show=<span class="keyword">True</span>,is_toolbox_show=<span class="keyword">True</span>,is_more_utils=<span class="keyword">True</span>,is_random=<span class="keyword">True</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1fu6asmrkzvj20rs0b474u.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理数据前需要先处理缺失值</span></span><br><span class="line"><span class="comment"># 订单结束时间清洗</span></span><br><span class="line">df[<span class="string">'dealEndtime'</span>].fillna(method=<span class="string">'ffill'</span>).apply(<span class="keyword">lambda</span> x:time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>,time.localtime(x))).head()</span><br></pre></td></tr></table></figure><pre><code>0    2018-06-30 14:00:001    2018-06-30 14:00:002    2018-06-30 14:00:003    2018-06-30 14:00:004    2018-06-30 14:00:00Name: dealEndtime, dtype: object</code></pre><h4 id="套餐的统计"><a href="#套餐的统计" class="headerlink" title="套餐的统计"></a>套餐的统计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'menu'</span>].dropna().astype(<span class="string">'category'</span>).value_counts()</span><br></pre></td></tr></table></figure><pre><code>2人午晚餐                       7640单人午晚餐                       3920学生专享午晚自助                    26384人午/晚自助                     1581单人下午自助烤肉                     6396人午/晚自助                      507周一至周五自助烤肉/周六日及节假日自助烤肉2选1     209单人午/晚自助                       67周一至周五自助烤肉，免费WiFi              22Name: menu, dtype: int64</code></pre><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu657vuie0j20rr0de3z2.jpg" alt=""></p><ul><li>阅读数与评分的协方差（相关性）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'readCnt'</span>].corr(df[<span class="string">'star'</span>])</span><br><span class="line"><span class="comment"># 评论阅读书与客户评价分数高低的相关性</span></span><br></pre></td></tr></table></figure><pre><code>0.05909293203205019</code></pre><ul><li>最受欢迎的套餐(2人午晚餐评价分布)，基本上几种在30,40,50,评价都还好，怪不得卖得好</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_most=df[(df[<span class="string">"menu"</span>]==<span class="string">"2人午晚餐"</span>)][<span class="string">'star'</span>].value_counts().reindex(range(<span class="number">10</span>,<span class="number">60</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure><pre><code>10     32920     53330    200240    270450    2072Name: star, dtype: int64</code></pre><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu66bowlaaj20km0aljrt.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"单人午晚餐"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>30    121540    120850    109320     29810     106Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 学生专享午晚自助 </span></span><br><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"学生专享午晚自助"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>40    95450    86330    52920    19110    101Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"4人午/晚自助"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>50    53630    43240    41410    13120     68Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"单人下午自助烤肉"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>30    20850    16940    14410     9820     20Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"6人午/晚自助"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>50    24540    14230    11210      8Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#周一至周五自助烤肉/周六日及节假日自助烤肉2选1</span></span><br><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"周一至周五自助烤肉/周六日及节假日自助烤肉2选1"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>50    8740    6630    4620    10Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"单人午/晚自助"</span>)][<span class="string">'star'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>50    3040    2730    10Name: star, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">"menu"</span>]==<span class="string">"周一至周五自助烤肉，免费WiFi"</span>)][<span class="string">'star'</span>].value_counts().reindex(range(<span class="number">10</span>,<span class="number">51</span>,<span class="number">10</span>)).fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>10     0.020     0.030     0.040     0.050    22.0Name: star, dtype: float64</code></pre><h4 id="套餐与评价汇总"><a href="#套餐与评价汇总" class="headerlink" title="套餐与评价汇总"></a>套餐与评价汇总</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># df.groupby(['menu','star']).size().to_excel("all_menu_star.xls") 可以直接导出到excel</span></span><br><span class="line">df.groupby([<span class="string">'menu'</span>,<span class="string">'star'</span>]).size()</span><br></pre></td></tr></table></figure><pre><code>menu                      star2人午晚餐                     10       329                          20       533                          30      2002                          40      2704                          50      20724人午/晚自助                   10       131                          20        68                          30       432                          40       414                          50       5366人午/晚自助                   10         8                          30       112                          40       142                          50       245单人下午自助烤肉                  10        98                          20        20                          30       208                          40       144                          50       169单人午/晚自助                   30        10                          40        27                          50        30单人午晚餐                     10       106                          20       298                          30      1215                          40      1208                          50      1093周一至周五自助烤肉/周六日及节假日自助烤肉2选1  20        10                          30        46                          40        66                          50        87周一至周五自助烤肉，免费WiFi          50        22学生专享午晚自助                  10       101                          20       191                          30       529                          40       954                          50       863dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby([<span class="string">'star'</span>,<span class="string">'menu'</span>,]).size()</span><br></pre></td></tr></table></figure><pre><code>star  menu                    10    2人午晚餐                        329      4人午/晚自助                      131      6人午/晚自助                        8      单人下午自助烤肉                      98      单人午晚餐                        106      学生专享午晚自助                     10120    2人午晚餐                        533      4人午/晚自助                       68      单人下午自助烤肉                      20      单人午晚餐                        298      周一至周五自助烤肉/周六日及节假日自助烤肉2选1      10      学生专享午晚自助                     19130    2人午晚餐                       2002      4人午/晚自助                      432      6人午/晚自助                      112      单人下午自助烤肉                     208      单人午/晚自助                       10      单人午晚餐                       1215      周一至周五自助烤肉/周六日及节假日自助烤肉2选1      46      学生专享午晚自助                     52940    2人午晚餐                       2704      4人午/晚自助                      414      6人午/晚自助                      142      单人下午自助烤肉                     144      单人午/晚自助                       27      单人午晚餐                       1208      周一至周五自助烤肉/周六日及节假日自助烤肉2选1      66      学生专享午晚自助                     95450    2人午晚餐                       2072      4人午/晚自助                      536      6人午/晚自助                      245      单人下午自助烤肉                     169      单人午/晚自助                       30      单人午晚餐                       1093      周一至周五自助烤肉/周六日及节假日自助烤肉2选1      87      周一至周五自助烤肉，免费WiFi              22      学生专享午晚自助                     863dtype: int64</code></pre><ul><li>评分最高的套餐分布</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby([<span class="string">'star'</span>,<span class="string">'menu'</span>,]).size()[<span class="number">50</span>]</span><br></pre></td></tr></table></figure><pre><code>menu2人午晚餐                       20724人午/晚自助                      5366人午/晚自助                      245单人下午自助烤肉                     169单人午/晚自助                       30单人午晚餐                       1093周一至周五自助烤肉/周六日及节假日自助烤肉2选1      87周一至周五自助烤肉，免费WiFi              22学生专享午晚自助                     863dtype: int64</code></pre><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu66hxb8tmj20kb0arjrp.jpg" alt=""></p><ul><li>用户id统计</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># userId</span></span><br><span class="line"><span class="comment"># 这家店铺有好多回头客，万万没想到</span></span><br><span class="line">df[df[<span class="string">'userId'</span>]!=<span class="number">0</span>][<span class="string">'userId'</span>].value_counts().head(<span class="number">40</span>)</span><br></pre></td></tr></table></figure><pre><code>266045270     64152775497     6080372612      60129840082     60336387962     6034216474      60617772217     6082682689      54287219504     49884729389     45...232697160     40141718492     40879430090     40696143486     4013257519      40983797146     40911947863     40993057629     40494215297     40Name: userId, dtype: int64</code></pre><ul><li>用户名统计,应该与用户id对应</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df[<span class="string">'userName'</span>]!=<span class="string">"匿名用户"</span>][<span class="string">'userName'</span>].value_counts().head(<span class="number">40</span>)</span><br></pre></td></tr></table></figure><pre><code>xuruiss1026         64黑发飘呀飘               60么么哒我是你聪叔            60jIx325233926        60siisgood            60vTF610712604        60始于初见的你              60yumengkou           54Daaaav              49梁子7543              45oev575457132        40oUI806055883        40joF498901567        40liE32679330         40...清晨cxh98             40cBj31240225         40天蛟Wing              40榴莲馅月饼               40leeman666888        40迅行天下                40滨海之恋33              40pHO437742850        40SzX539077433        40Name: userName, dtype: int64</code></pre><h4 id="评分与用户等级汇总"><a href="#评分与用户等级汇总" class="headerlink" title="评分与用户等级汇总"></a>评分与用户等级汇总</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby([<span class="string">'star'</span>,<span class="string">'userLevel'</span>,]).size()</span><br></pre></td></tr></table></figure><pre><code>star  userLevel10    0             187      1             139      2             164      3             193      4              80      5              1020    0             223      1              88      2             304      3             294      4             207      5              2130    0            1147      1             405      2            1057      3            1230      4             570      5             165      6              2040    0             870      1             432      2            1360      3            1751      4            1026      5             261      6              2550    0             698      1             386      2            1167      3            1670      4             802      5             318      6             130dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">df_level_star = df.groupby([<span class="string">'userLevel'</span>,<span class="string">'star'</span>]).size()</span><br><span class="line">attr = np.arange(<span class="number">10</span>,<span class="number">60</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br><span class="line">bar = Bar(<span class="string">"用户等级与评分"</span>,title_pos=<span class="string">"center"</span>)</span><br><span class="line">df_0 = df_level_star[<span class="number">0</span>].values</span><br><span class="line">df_1 = df_level_star[<span class="number">1</span>].values</span><br><span class="line">df_2 = df_level_star[<span class="number">2</span>].values</span><br><span class="line">df_3 = df_level_star[<span class="number">3</span>].values</span><br><span class="line">df_4 = df_level_star[<span class="number">4</span>].values</span><br><span class="line">df_5 = df_level_star[<span class="number">5</span>].values</span><br><span class="line"><span class="comment"># df_6 = df_level_star[6].values</span></span><br><span class="line">df_6 = df_level_star[<span class="number">6</span>].reindex(attr).fillna(<span class="number">0</span>).values</span><br><span class="line"></span><br><span class="line">bar.add(<span class="string">"level 0"</span>,attr,df_0,is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 1"</span>,attr,df_1,is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 2"</span>,attr,df_2,is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 3"</span>,attr,df_3,mark_line=[<span class="string">"average"</span>],mark_point=[<span class="string">'max'</span>,<span class="string">'min'</span>],is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 4"</span>,attr,df_4,is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 5"</span>,attr,df_5,is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 6"</span>,attr,df_6,is_label_show=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu66k2dzdgj20m80b4mxv.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">bar = Bar(<span class="string">"用户等级与评分"</span>,title_pos=<span class="string">"center"</span>,title_color=<span class="string">"red"</span>)</span><br><span class="line">attr = np.arange(<span class="number">10</span>,<span class="number">60</span>,<span class="number">10</span>)</span><br><span class="line">df_0 = df_level_star[<span class="number">0</span>].values</span><br><span class="line">df_1 = df_level_star[<span class="number">1</span>].values</span><br><span class="line">df_2 = df_level_star[<span class="number">2</span>].values</span><br><span class="line">df_3 = df_level_star[<span class="number">3</span>].values</span><br><span class="line">df_4 = df_level_star[<span class="number">4</span>].values</span><br><span class="line">df_5 = df_level_star[<span class="number">5</span>].values</span><br><span class="line"><span class="comment"># df_6 = df_level_star[6].values</span></span><br><span class="line">df_6 = df_level_star[<span class="number">6</span>].reindex(attr).fillna(<span class="number">0</span>).values</span><br><span class="line">bar.add(<span class="string">"level 0"</span>,attr,df_0,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 1"</span>,attr,df_1,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 2"</span>,attr,df_2,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 3"</span>,attr,df_3,is_stack=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 4"</span>,attr,df_4,is_stack=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 5"</span>,attr,df_5,is_stack=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar.add(<span class="string">"level 6"</span>,attr,df_6,is_stack=<span class="keyword">True</span>,legend_pos=<span class="string">'right'</span>,legend_orient=<span class="string">'vertical'</span>,label_text_size=<span class="number">12</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1fu66xjsuk6j20m80b4wet.jpg" alt=""></p><ul><li><p>用户等级与评价的相关性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'star'</span>].corr(df[<span class="string">'userLevel'</span>])</span><br></pre></td></tr></table></figure><p>  0.14389808871897794</p></li></ul><ul><li>点赞分布</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df_zan=df[<span class="string">'zanCnt'</span>].value_counts()</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br><span class="line">bar=Bar(<span class="string">"点赞统计"</span>)</span><br><span class="line">bar.add(<span class="string">"点赞分布"</span>,df_zan.index[<span class="number">1</span>:],df_zan.values[<span class="number">1</span>:],is_label_show=<span class="keyword">True</span>)</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu66vpau0lj20m80b43yp.jpg" alt=""></p><ul><li>数值型数据的统计</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu66ujghx0j211i084wfj.jpg" alt=""></p><ul><li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'userLevel'</span>].value_counts().reindex(range(<span class="number">7</span>))</span><br></pre></td></tr></table></figure><p>  0    3125<br>  1    1450<br>  2    4052<br>  3    5138<br>  4    2685<br>  5     775<br>  6     175<br>  Name: userLevel, dtype: int64</p></li><li><p>用户等级分布</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df_level=df[<span class="string">'userLevel'</span>].value_counts().reindex(range(<span class="number">7</span>))</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Pie</span><br><span class="line">pie=Pie(<span class="string">"用户等级分布"</span>,title_pos=<span class="string">"center"</span>,width=<span class="number">900</span>)</span><br><span class="line">pie.add(<span class="string">"levels distribution"</span>,[<span class="string">"level "</span>+str(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">7</span>)],df_level.values,is_random=<span class="keyword">True</span>,radidus=[<span class="number">30</span>,<span class="number">45</span>],legend_pos=<span class="string">'left'</span>,rosetype=<span class="string">'area'</span>,legend_orient=<span class="string">'vertical'</span>,is_label_show=<span class="keyword">True</span>,label_text_size=<span class="number">20</span>)</span><br><span class="line">pie</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu66mxp9crj20p00b4gmb.jpg" alt=""></p><ul><li>至此基本数据分析完成，后续会开始于其评论数据的挖掘</li></ul>]]></content>
      
      <categories>
          
          <category> visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> data visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>douban_top250_analysis</title>
      <link href="/2018/08/08/douban-top250-analysis/"/>
      <url>/2018/08/08/douban-top250-analysis/</url>
      <content type="html"><![CDATA[<h3 id="豆瓣电影top250数据分析"><a href="#豆瓣电影top250数据分析" class="headerlink" title="豆瓣电影top250数据分析"></a>豆瓣电影top250数据分析</h3><ul><li>数据来源（豆瓣电影top250）</li><li>爬虫代码比较简单</li><li>数据较为真实，可以进行初步的数据分析</li><li>可以将前面的几篇文章中的介绍的数据预处理的方法进行实践</li><li>最后用matplotlib与pyecharts两种可视化包进行部分数据展示</li><li>数据仍需深挖，有待加强 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先按照惯例导入python 数据分析的两个包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br></pre></td></tr></table></figure><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">names=[<span class="string">'num'</span>,<span class="string">'title'</span>,<span class="string">"director"</span>,<span class="string">"role"</span>,<span class="string">"init_year"</span>,<span class="string">"area"</span>,<span class="string">"genre"</span>,<span class="string">"rating_num"</span>,<span class="string">"comment_num"</span>,<span class="string">"comment"</span>,<span class="string">"url"</span>]</span><br><span class="line"><span class="comment">#"num#title#director#role#init_year#area#genre#rating_num#comment_num#comment#url"</span></span><br><span class="line">df_1 = pd.read_excel(<span class="string">"top250_f1.xls"</span>,index=<span class="keyword">None</span>,header=<span class="keyword">None</span>)</span><br><span class="line">df_1.columns=names</span><br><span class="line">df_1.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bfj69udj215f0hpn07.jpg" alt=""></p><ul><li>查看数据类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_1.dtypes</span><br></pre></td></tr></table></figure><pre><code>num              int64title           objectdirector        objectrole            objectinit_year       objectarea            objectgenre           objectrating_num     float64comment_num      int64comment         objecturl             objectdtype: object</code></pre><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">names1=[<span class="string">"num"</span>,<span class="string">"rank"</span>,<span class="string">"alt_title"</span>,<span class="string">"title"</span>,<span class="string">"pubdate"</span>,<span class="string">"language"</span>,<span class="string">"writer"</span>,<span class="string">"director"</span>,<span class="string">"cast"</span>,<span class="string">"movie_duration"</span>,<span class="string">"year"</span>,<span class="string">"movie_type"</span>,<span class="string">"tags"</span>,<span class="string">"image"</span>]</span><br><span class="line">df_2 = pd.read_excel(<span class="string">"top250_f2.xlsx"</span>,index=<span class="keyword">None</span>,header=<span class="keyword">None</span>)</span><br><span class="line">df_2.columns=names1</span><br><span class="line">df_2.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;RangeIndex: 250 entries, 0 to 249Data columns (total 14 columns):num               250 non-null int64rank              250 non-null float64alt_title         250 non-null objecttitle             250 non-null objectpubdate           250 non-null objectlanguage          250 non-null objectwriter            250 non-null objectdirector          250 non-null objectcast              250 non-null objectmovie_duration    250 non-null objectyear              250 non-null objectmovie_type        250 non-null objecttags              250 non-null objectimage             250 non-null objectdtypes: float64(1), int64(1), object(12)memory usage: 27.4+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_1_cut = df_1[[<span class="string">'num'</span>,<span class="string">'title'</span>,<span class="string">'init_year'</span>,<span class="string">'area'</span>,<span class="string">'genre'</span>,<span class="string">'rating_num'</span>,<span class="string">'comment_num'</span>]]</span><br><span class="line">df_2_cut = df_2[[<span class="string">'num'</span>,<span class="string">'language'</span>,<span class="string">'director'</span>,<span class="string">'cast'</span>,<span class="string">'movie_duration'</span>,<span class="string">'tags'</span>]]</span><br><span class="line">df = pd.merge(df_1_cut,df_2_cut,how = <span class="string">'outer'</span>,on = <span class="string">'num'</span>)   <span class="comment">#外连接，合并标准on = 'num'</span></span><br><span class="line"><span class="comment"># df.to_excel("all_data_movie.xls",index=False)         #查看前五条信息</span></span><br></pre></td></tr></table></figure><ul><li>查看重复数据 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看重复数据</span></span><br><span class="line">df.duplicated()</span><br><span class="line">df.duplicated().value_counts()</span><br></pre></td></tr></table></figure><pre><code>False    250dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.title.unique()</span><br></pre></td></tr></table></figure><pre><code>array([&apos;肖申克的救赎&apos;, &apos;霸王别姬&apos;, &apos;这个杀手不太冷&apos;, &apos;阿甘正传&apos;, &apos;美丽人生&apos;, &apos;泰坦尼克号&apos;, &apos;千与千寻&apos;,       &apos;辛德勒的名单&apos;, &apos;盗梦空间&apos;, &apos;机器人总动员&apos;, &apos;三傻大闹宝莱坞&apos;, &apos;忠犬八公的故事&apos;, &apos;海上钢琴师&apos;, &apos;放牛班的春天&apos;,       &apos;大话西游之大圣娶亲&apos;, &apos;楚门的世界&apos;, &apos;教父&apos;, &apos;龙猫&apos;, &apos;星际穿越&apos;, &apos;熔炉&apos;, &apos;触不可及&apos;, &apos;无间道&apos;,       &apos;乱世佳人&apos;, &apos;当幸福来敲门&apos;, &apos;怦然心动&apos;, &apos;天堂电影院&apos;, &apos;十二怒汉&apos;, &apos;鬼子来了&apos;, &apos;蝙蝠侠：黑暗骑士&apos;,       &apos;疯狂动物城&apos;, &apos;少年派的奇幻漂流&apos;, &apos;活着&apos;, &apos;搏击俱乐部&apos;, &apos;指环王3：王者无敌&apos;, &apos;天空之城&apos;,       &apos;大话西游之月光宝盒&apos;, &apos;飞屋环游记&apos;, &apos;罗马假日&apos;, &apos;控方证人&apos;, &apos;窃听风暴&apos;, &apos;两杆大烟枪&apos;, &apos;飞越疯人院&apos;,       &apos;闻香识女人&apos;, &apos;哈尔的移动城堡&apos;, &apos;辩护人&apos;, &apos;海豚湾&apos;, &apos;V字仇杀队&apos;, &apos;死亡诗社&apos;, &apos;摔跤吧！爸爸&apos;, &apos;教父2&apos;,       &apos;指环王2：双塔奇兵&apos;, &apos;美丽心灵&apos;, &apos;指环王1：魔戒再现&apos;, &apos;饮食男女&apos;, &apos;情书&apos;, &apos;美国往事&apos;, &apos;狮子王&apos;, &apos;素媛&apos;,       &apos;钢琴家&apos;, &apos;小鞋子&apos;, &apos;七宗罪&apos;, &apos;天使爱美丽&apos;, &apos;被嫌弃的松子的一生&apos;, &apos;致命魔术&apos;, &apos;本杰明·巴顿奇事&apos;,       &apos;音乐之声&apos;, &apos;西西里的美丽传说&apos;, &apos;勇敢的心&apos;, &apos;拯救大兵瑞恩&apos;, &apos;黑客帝国&apos;, &apos;低俗小说&apos;, &apos;剪刀手爱德华&apos;,       &apos;让子弹飞&apos;, &apos;看不见的客人&apos;, &apos;沉默的羔羊&apos;, &apos;蝴蝶效应&apos;, &apos;入殓师&apos;, &apos;大闹天宫&apos;, &apos;春光乍泄&apos;, &apos;末代皇帝&apos;,       &apos;心灵捕手&apos;, &apos;玛丽和马克思&apos;, &apos;阳光灿烂的日子&apos;, &apos;哈利·波特与魔法石&apos;, &apos;布达佩斯大饭店&apos;, &apos;幽灵公主&apos;, &apos;第六感&apos;,       &apos;禁闭岛&apos;, &apos;重庆森林&apos;, &apos;猫鼠游戏&apos;, &apos;狩猎&apos;, &apos;致命ID&apos;, &apos;大鱼&apos;, &apos;断背山&apos;, &apos;甜蜜蜜&apos;,       &apos;射雕英雄传之东成西就&apos;, &apos;告白&apos;, &apos;一一&apos;, &apos;加勒比海盗&apos;, &apos;穿条纹睡衣的男孩&apos;, &apos;阳光姐妹淘&apos;, &apos;摩登时代&apos;,       &apos;阿凡达&apos;, &apos;上帝之城&apos;, &apos;爱在黎明破晓前&apos;, &apos;消失的爱人&apos;, &apos;风之谷&apos;, &apos;爱在日落黄昏时&apos;, &apos;侧耳倾听&apos;, &apos;超脱&apos;,       &apos;倩女幽魂&apos;, &apos;恐怖直播&apos;, &apos;红辣椒&apos;, &apos;小森林 夏秋篇&apos;, &apos;喜剧之王&apos;, &apos;菊次郎的夏天&apos;, &apos;驯龙高手&apos;, &apos;幸福终点站&apos;,       &apos;萤火虫之墓&apos;, &apos;借东西的小人阿莉埃蒂&apos;, &apos;岁月神偷&apos;, &apos;神偷奶爸&apos;, &apos;七武士&apos;, &apos;杀人回忆&apos;, &apos;贫民窟的百万富翁&apos;,       &apos;电锯惊魂&apos;, &apos;喜宴&apos;, &apos;谍影重重3&apos;, &apos;真爱至上&apos;, &apos;怪兽电力公司&apos;, &apos;东邪西毒&apos;, &apos;记忆碎片&apos;, &apos;海洋&apos;,       &apos;黑天鹅&apos;, &apos;雨人&apos;, &apos;疯狂原始人&apos;, &apos;卢旺达饭店&apos;, &apos;小森林 冬春篇&apos;, &apos;英雄本色&apos;, &apos;哈利·波特与死亡圣器(下)&apos;,       &apos;燃情岁月&apos;, &apos;7号房的礼物&apos;, &apos;虎口脱险&apos;, &apos;心迷宫&apos;, &apos;萤火之森&apos;, &apos;傲慢与偏见&apos;, &apos;荒蛮故事&apos;, &apos;海边的曼彻斯特&apos;,       &apos;请以你的名字呼唤我&apos;, &apos;教父3&apos;, &apos;恋恋笔记本&apos;, &apos;完美的世界&apos;, &apos;纵横四海&apos;, &apos;花样年华&apos;, &apos;唐伯虎点秋香&apos;,       &apos;超能陆战队&apos;, &apos;玩具总动员3&apos;, &apos;蝙蝠侠：黑暗骑士崛起&apos;, &apos;时空恋旅人&apos;, &apos;魂断蓝桥&apos;, &apos;猜火车&apos;, &apos;穿越时空的少女&apos;,       &apos;雨中曲&apos;, &apos;二十二&apos;, &apos;达拉斯买家俱乐部&apos;, &apos;我是山姆&apos;, &apos;人工智能&apos;, &apos;冰川时代&apos;, &apos;浪潮&apos;, &apos;朗读者&apos;,       &apos;爆裂鼓手&apos;, &apos;香水&apos;, &apos;罗生门&apos;, &apos;未麻的部屋&apos;, &apos;阿飞正传&apos;, &apos;血战钢锯岭&apos;, &apos;一次别离&apos;, &apos;被解救的姜戈&apos;,       &apos;可可西里&apos;, &apos;追随&apos;, &apos;恐怖游轮&apos;, &apos;撞车&apos;, &apos;战争之王&apos;, &apos;头脑特工队&apos;, &apos;地球上的星星&apos;, &apos;房间&apos;, &apos;无人知晓&apos;,       &apos;梦之安魂曲&apos;, &apos;牯岭街少年杀人事件&apos;, &apos;魔女宅急便&apos;, &apos;谍影重重&apos;, &apos;谍影重重2&apos;, &apos;忠犬八公物语&apos;, &apos;模仿游戏&apos;,       &apos;你的名字。&apos;, &apos;惊魂记&apos;, &apos;青蛇&apos;, &apos;一个叫欧维的男人决定去死&apos;, &apos;再次出发之纽约遇见你&apos;, &apos;哪吒闹海&apos;, &apos;完美陌生人&apos;,       &apos;东京物语&apos;, &apos;小萝莉的猴神大叔&apos;, &apos;黑客帝国3：矩阵革命&apos;, &apos;源代码&apos;, &apos;新龙门客栈&apos;, &apos;终结者2：审判日&apos;,       &apos;末路狂花&apos;, &apos;碧海蓝天&apos;, &apos;秒速5厘米&apos;, &apos;绿里奇迹&apos;, &apos;这个男人来自地球&apos;, &apos;海盗电台&apos;, &apos;勇闯夺命岛&apos;,       &apos;城市之光&apos;, &apos;初恋这件小事&apos;, &apos;无耻混蛋&apos;, &apos;卡萨布兰卡&apos;, &apos;变脸&apos;, &apos;E.T. 外星人&apos;, &apos;爱在午夜降临前&apos;,       &apos;发条橙&apos;, &apos;步履不停&apos;, &apos;黄金三镖客&apos;, &apos;无敌破坏王&apos;, &apos;疯狂的石头&apos;, &apos;美国丽人&apos;, &apos;荒野生存&apos;, &apos;迁徙的鸟&apos;,       &apos;英国病人&apos;, &apos;海街日记&apos;, &apos;彗星来的那一夜&apos;, &apos;国王的演讲&apos;, &apos;非常嫌疑犯&apos;, &apos;血钻&apos;, &apos;燕尾蝶&apos;, &apos;聚焦&apos;,       &apos;勇士&apos;, &apos;叫我第一名&apos;, &apos;穆赫兰道&apos;, &apos;遗愿清单&apos;, &apos;枪火&apos;, &apos;上帝也疯狂&apos;, &apos;我爱你&apos;, &apos;黑鹰坠落&apos;, &apos;荒岛余生&apos;,       &apos;大卫·戈尔的一生&apos;, &apos;千钧一发&apos;, &apos;蓝色大门&apos;, &apos;2001太空漫游&apos;], dtype=object)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  数据格式的初步清洗</span></span><br><span class="line">df[<span class="string">'genre'</span>]=df[<span class="string">'genre'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"language"</span>]= df[<span class="string">'language'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"director"</span>]= df[<span class="string">'director'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"cast"</span>]= df[<span class="string">'cast'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"movie_duration"</span>]= df[<span class="string">'movie_duration'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line"><span class="comment"># df[["genre","language","director","cast","movie_duration"]]=df[["genre","language","director","cast","movie_duration"]].apply(lambda x: x.replace("['","").replace("']",""))</span></span><br></pre></td></tr></table></figure><ul><li>上映地区数据清理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 地区的数据清理</span></span><br><span class="line">area_split = df[<span class="string">'area'</span>].str.split(expand=<span class="keyword">True</span>)</span><br><span class="line">area_split.head()</span><br><span class="line">all_area = area_split.apply(pd.value_counts).fillna(<span class="number">0</span>)</span><br><span class="line">all_area.columns = [<span class="string">'area_1'</span>,<span class="string">'area_2'</span>,<span class="string">'area_3'</span>,<span class="string">'area_4'</span>,<span class="string">'area_5'</span>]</span><br><span class="line">all_area = all_area.astype(<span class="string">"int"</span>)</span><br><span class="line">all_area.dtypes</span><br></pre></td></tr></table></figure><pre><code>area_1    int32area_2    int32area_3    int32area_4    int32area_5    int32dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_area.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bioo61dj20gs07xwep.jpg" alt=""></p><ul><li>上映地区数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_area[<span class="string">'Col_sum'</span>] = all_area.apply(<span class="keyword">lambda</span> x: x.sum(), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_area.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bjtbssxj20k4080q38.jpg" alt=""></p><ul><li>电影类型数据清理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories = df[<span class="string">'genre'</span>].str.split(<span class="string">" "</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">categories = categories.apply(pd.value_counts).fillna(<span class="number">0</span>).astype(<span class="string">"int"</span>)</span><br><span class="line">categories.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2blloch5j20ak08ljrk.jpg" alt=""></p><ul><li>电影类型数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories[<span class="string">'count'</span>]= categories.apply(<span class="keyword">lambda</span> x:x.sum(),axis=<span class="number">1</span>)</span><br><span class="line">categories.sort_values(<span class="string">'count'</span>,ascending=<span class="keyword">False</span>)</span><br><span class="line">categories.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bm9sltij20cd07wglu.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于language处理</span></span><br><span class="line">df[<span class="string">'language'</span>].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><pre><code>0                         英语1                      汉语普通话2           英语&apos;, &apos;意大利语&apos;, &apos;法语3                         英语4           意大利语&apos;, &apos;德语&apos;, &apos;英语5     英语&apos;, &apos;意大利语&apos;, &apos;德语&apos;, &apos;俄语6                         日语7    英语&apos;, &apos;希伯来语&apos;, &apos;德语&apos;, &apos;波兰语8             英语&apos;, &apos;日语&apos;, &apos;法语9                         英语Name: language, dtype: object</code></pre><ul><li>电影语言的清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">language_all = df[<span class="string">'language'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">" "</span>).str.split(<span class="string">" "</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">language_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bn4unt0j20nh087wey.jpg" alt=""></p><ul><li>电影语言的数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">language_all = language_all.apply(pd.value_counts).fillna(<span class="number">0</span>).astype(<span class="string">"int"</span>)</span><br><span class="line">language_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bnhy7huj20ep07waaa.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">language_all[<span class="string">'count'</span>]= language_all.apply(<span class="keyword">lambda</span> x:x.sum(),axis=<span class="number">1</span>)</span><br><span class="line">language_all.sort_values(<span class="string">'count'</span>,ascending=<span class="keyword">False</span>)</span><br><span class="line">language_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bo69lnoj20hh086mxg.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.director.head()</span><br></pre></td></tr></table></figure><pre><code>0    弗兰克·德拉邦特 Frank Darabont1             陈凯歌 Kaige Chen2           吕克·贝松 Luc Besson3            Robert Zemeckis4    罗伯托·贝尼尼 Roberto BenigniName: director, dtype: object</code></pre><ul><li>导演的数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">director_all = df[<span class="string">'director'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">"~"</span>).str.split(<span class="string">"~"</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">director_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2cz4eekyj20ey08274r.jpg" alt=""></p><ul><li>电影演员的数据清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  演员</span></span><br><span class="line">df[<span class="string">'cast'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    蒂姆·罗宾斯 Tim Robbins&apos;, &apos;摩根·弗里曼 Morgan Freeman&apos;, ...1    张国荣 Leslie Cheung&apos;, &apos;张丰毅 Fengyi Zhang&apos;, &apos;巩俐 Li...2    让·雷诺 Jean Reno&apos;, &apos;娜塔莉·波特曼 Natalie Portman&apos;, &apos;加...3    Tom Hanks&apos;, &apos;Robin Wright Penn&apos;, &apos;Gary Sinise&apos;...4    罗伯托·贝尼尼 Roberto Benigni&apos;, &apos;尼可莱塔·布拉斯基 Nicoletta...Name: cast, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cast_all = df[<span class="string">'cast'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">"~"</span>).str.split(<span class="string">"~"</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">cast_all.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bp8s3wtj215g08fmyy.jpg" alt=""></p><ul><li>电影演员的数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">main_dr= list(director_all[<span class="number">0</span>])</span><br><span class="line">second_dr= list(director_all[<span class="number">1</span>])</span><br><span class="line">thrid_dr= list(director_all[<span class="number">2</span>])</span><br><span class="line">directors=pd.Series(main_dr+second_dr+thrid_dr)</span><br><span class="line">directors.value_counts().head()</span><br></pre></td></tr></table></figure><pre><code>宫崎骏 Hayao Miyazaki            7克里斯托弗·诺兰 Christopher Nolan    7王家卫 Kar Wai Wong              5史蒂文·斯皮尔伯格 Steven Spielberg    5大卫·芬奇 David Fincher           4dtype: int64</code></pre><ul><li>电影发行年份清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'init_year'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    19941    19932    19943    19944    1997Name: init_year, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">year_= df[<span class="string">'init_year'</span>].str.split(<span class="string">'/'</span>).apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>].strip()).replace(regex=&#123;<span class="string">'\(中国大陆\)'</span>:<span class="string">''</span>&#125;)</span><br><span class="line">year_split = pd.to_datetime(year_).dt.year</span><br><span class="line">year_split.head()</span><br></pre></td></tr></table></figure><pre><code>0    19941    19932    19943    19944    1997Name: init_year, dtype: int64</code></pre><ul><li>电影观影时长的清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'movie_duration'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0                       142分钟1                      171 分钟2    110分钟(剧场版)&apos;, &apos;133分钟(国际版)3                      142 分钟4         116分钟&apos;, &apos;125分钟(加长版)Name: movie_duration, dtype: object</code></pre><ul><li>电影观影时长的整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 观影时长，多次上映取的第一个时长</span></span><br><span class="line">movie_duration_split = df[<span class="string">'movie_duration'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">"~"</span>).str.split(<span class="string">"~"</span>,expand=<span class="keyword">True</span>).fillna(<span class="number">0</span>)</span><br><span class="line">movie_duration_split =movie_duration_split.replace(regex=&#123;<span class="string">'分钟.*'</span>: <span class="string">''</span>&#125;)</span><br><span class="line">df[<span class="string">'movie_duration'</span>]=movie_duration_split[<span class="number">0</span>].astype(<span class="string">"int"</span>)</span><br><span class="line">df[<span class="string">'movie_duration'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    1421    1712    1103    1424    116Name: movie_duration, dtype: int32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标签 tags</span></span><br><span class="line"><span class="comment"># 查看第一部电影的的tag</span></span><br><span class="line"><span class="comment"># pd.DataFrame(eval(df['tags'][0]))</span></span><br><span class="line">df[<span class="string">'tags'</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>&quot;[{&apos;count&apos;: 220591, &apos;name&apos;: &apos;经典&apos;}, {&apos;count&apos;: 191014, &apos;name&apos;: &apos;励志&apos;}, {&apos;count&apos;: 173587, &apos;name&apos;: &apos;信念&apos;}, {&apos;count&apos;: 159939, &apos;name&apos;: &apos;自由&apos;}, {&apos;count&apos;: 115024, &apos;name&apos;: &apos;人性&apos;}, {&apos;count&apos;: 111430, &apos;name&apos;: &apos;美国&apos;}, {&apos;count&apos;: 93721, &apos;name&apos;: &apos;人生&apos;}, {&apos;count&apos;: 72602, &apos;name&apos;: &apos;剧情&apos;}]&quot;</code></pre><ul><li>电影标签的清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_tags = [ pd.DataFrame(eval(i)) <span class="keyword">for</span> i <span class="keyword">in</span> df[<span class="string">"tags"</span>]]</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">all_tags=[list(itertools.chain.from_iterable(zip(df_[<span class="string">'name'</span>],df_[<span class="string">'count'</span>]))) <span class="keyword">for</span> df_ <span class="keyword">in</span> all_tags]</span><br><span class="line">all_tags_df=pd.DataFrame(all_tags)</span><br><span class="line">all_tags_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bqdhgjfj213p07wdhi.jpg" alt=""></p><h4 id="数据可视化部分"><a href="#数据可视化部分" class="headerlink" title="数据可视化部分"></a>数据可视化部分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据分析与可视化部分 matplotlib 与 pyecharts</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">"font.family"</span>]=[<span class="string">"simsunb"</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">'font.size'</span>] =<span class="number">15</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line">plt.style.use(<span class="string">'seaborn-whitegrid'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(df[<span class="string">'rating_num'</span>],df[<span class="string">'num'</span>])</span><br><span class="line">plt.xlabel(<span class="string">"reating_num"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"ranking"</span>)</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.hist(df[<span class="string">'rating_num'</span>],bins=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">"rating_num"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2brdjbpqj20vy0dhwgd.jpg" alt="影评人数"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line">plt.style.use(<span class="string">'seaborn-whitegrid'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(df[<span class="string">'movie_duration'</span>],df[<span class="string">'num'</span>])</span><br><span class="line">plt.xlabel(<span class="string">"movie_duration"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"ranking"</span>)</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.hist(df[<span class="string">'movie_duration'</span>],bins=<span class="number">15</span>)</span><br><span class="line">plt.xlabel(<span class="string">"movie_duration"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bs32a65j20vx0dkjts.jpg" alt="观影时长"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 观影时长与 电影排名之间的相关性，从常识来判断，基本没有啥关系，因为好的电影不一定时间长，时间长的不一定是好电影</span></span><br><span class="line">df[<span class="string">'num'</span>].corr(df[<span class="string">'movie_duration'</span>])</span><br></pre></td></tr></table></figure><pre><code>-0.19979596696001942</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'init_year'</span>]=year_split</span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line">plt.style.use(<span class="string">'seaborn-whitegrid'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(df[<span class="string">'init_year'</span>],df[<span class="string">'num'</span>])</span><br><span class="line">plt.xlabel(<span class="string">"init_year"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"ranking"</span>)</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.hist(df[<span class="string">'init_year'</span>],bins=<span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">"init_year"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bsnsesdj20vm0dimzk.jpg" alt="发行年份"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'num'</span>].corr(df[<span class="string">'init_year'</span>])  </span><br><span class="line"><span class="comment"># 从结果来看，更没有什么相关性</span></span><br></pre></td></tr></table></figure><pre><code>0.041157240822869007</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import matplotlib.font_manager as fm</span></span><br><span class="line"><span class="comment"># fpath = 'C:\\Windows\\Fonts\\simsunb.ttf'</span></span><br><span class="line"><span class="comment"># prop=fm.FontProperties(fname=fpath)</span></span><br><span class="line"><span class="comment"># print(prop)</span></span><br><span class="line">matplotlib.rcParams[<span class="string">"font.family"</span>]=[<span class="string">"SimHei"</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">24</span>,<span class="number">6</span>))</span><br><span class="line">all_area_new = all_area[<span class="string">'Col_sum'</span>].sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">plt.bar(list(all_area_new.index),list(all_area_new))</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)  <span class="comment">#坐标轴刻度倾斜45°</span></span><br><span class="line">plt.legend(labels=[<span class="string">"count"</span>],loc=<span class="string">'upper center'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bt24rgpj20zc0aiwfj.jpg" alt="地域"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">language_all[<span class="string">'count'</span>].sort_values(ascending=<span class="keyword">False</span>).head()</span><br></pre></td></tr></table></figure><pre><code>英语       170法语        40日语        40汉语普通话     34德语        24Name: count, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">language_all[<span class="string">'count'</span>].sort_values(ascending=<span class="keyword">False</span>).plot(kind=<span class="string">'bar'</span>,figsize=(<span class="number">22</span>,<span class="number">6</span>))</span><br><span class="line">plt.legend(labels=[<span class="string">"language_count"</span>],loc=<span class="string">'upper center'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2buk6ozqj20z50c1di1.jpg" alt="语言"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories[<span class="string">"count"</span>].sort_values(ascending=<span class="keyword">False</span>).plot(kind=<span class="string">'bar'</span>,figsize=(<span class="number">22</span>,<span class="number">6</span>))</span><br><span class="line">plt.legend(labels=[<span class="string">"category_count"</span>],loc=<span class="string">'upper center'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2buzrrafj20z50awmy2.jpg" alt="类型"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_tag_name = all_tags_df.loc[:,[<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">10</span>,<span class="number">12</span>,<span class="number">14</span>]].values.flatten()</span><br><span class="line">all_tag_name = pd.Series(all_tag_name).value_counts()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> WordCloud</span><br><span class="line">wordcloud = WordCloud(width=<span class="number">1000</span>,height=<span class="number">600</span>)</span><br><span class="line">wordcloud.add(<span class="string">""</span>,list(all_tag_name.index),list(all_tag_name.values),word_size_range=[<span class="number">20</span>,<span class="number">100</span>])</span><br><span class="line">wordcloud</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bxo1kl8j20tq0i2tib.jpg" alt="pyeacharts"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line">font = <span class="string">r'C:\Windows\Fonts\simfang.ttf'</span></span><br><span class="line">wordcloud = WordCloud(font_path=font,max_font_size = <span class="number">35</span>).generate(str(list(all_tag_name.index)))</span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line">plt.imshow(wordcloud)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bz2yq4oj20hj08qteq.jpg" alt="wordcloud"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Bar</span><br><span class="line">mybar= Bar(<span class="string">"电影类型分析"</span>)</span><br><span class="line">cate=categories[<span class="string">'count'</span>].sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">mybar.add(<span class="string">"电影类型"</span>,cate.index,cate.values,mark_line=[<span class="string">'max'</span>],mark_point=[<span class="string">'average'</span>])</span><br><span class="line">mybar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bzw7b0hj20rv0dgjry.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Pie</span><br><span class="line">Top30_rating_num=df[[<span class="string">'rating_num'</span>,<span class="string">'title'</span>]].sort_values([<span class="string">'rating_num'</span>],ascending=<span class="keyword">False</span>).head(<span class="number">30</span>)[<span class="string">'rating_num'</span>].value_counts()</span><br><span class="line">Top30_rating_num</span><br><span class="line">pie = Pie(<span class="string">'排名前30电影评分占比'</span>,title_pos = <span class="string">'center'</span>)</span><br><span class="line">pie.add(<span class="string">''</span>,list(Top30_rating_num.index),Top30_rating_num.values,is_label_show = <span class="keyword">True</span>,legend_orient = <span class="string">'vertical'</span>,legend_pos = <span class="string">'right'</span>)</span><br><span class="line">pie</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2c120o8uj20sh0d6wfc.jpg" alt=""></p>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pandas data processing</title>
      <link href="/2018/08/02/data-processing-pandas/"/>
      <url>/2018/08/02/data-processing-pandas/</url>
      <content type="html"><![CDATA[<h3 id="category-type-data-in-pandas"><a href="#category-type-data-in-pandas" class="headerlink" title="category type data in pandas"></a>category type data in pandas</h3><ul><li>实际应用pandas过程中，经常会用到category数据类型，通常以text的形式显示，包括颜色（红，绿，蓝），尺寸的大小（大，中，小），还有地理信息等（国家，省份），这些数据的处理经常会有各种各样的问题，pandas以及scikit-learn两个包可以将category数据转化为合适的数值型格式，这篇主要介绍通过这两个包处理category类型的数据转化为数值类型，也就是encoding的过程。</li><li>数据来源<a href="http://mlr.cs.umass.edu/ml/index.html" target="_blank" rel="noopener">UCI Machine Learning Repository</a>，这个数据集中包含了很多的category类型的数据，可以从链接汇总查看数据的代表的含义。</li><li>下面开始导入需要用到的包</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 规定一下数据列的各个名称，</span></span><br><span class="line">headers = [<span class="string">"symboling"</span>, <span class="string">"normalized_losses"</span>, <span class="string">"make"</span>, <span class="string">"fuel_type"</span>, <span class="string">"aspiration"</span>,</span><br><span class="line">           <span class="string">"num_doors"</span>, <span class="string">"body_style"</span>, <span class="string">"drive_wheels"</span>, <span class="string">"engine_location"</span>,</span><br><span class="line">           <span class="string">"wheel_base"</span>, <span class="string">"length"</span>, <span class="string">"width"</span>, <span class="string">"height"</span>, <span class="string">"curb_weight"</span>,</span><br><span class="line">           <span class="string">"engine_type"</span>, <span class="string">"num_cylinders"</span>, <span class="string">"engine_size"</span>, <span class="string">"fuel_system"</span>,</span><br><span class="line">           <span class="string">"bore"</span>, <span class="string">"stroke"</span>, <span class="string">"compression_ratio"</span>, <span class="string">"horsepower"</span>, <span class="string">"peak_rpm"</span>,</span><br><span class="line">           <span class="string">"city_mpg"</span>, <span class="string">"highway_mpg"</span>, <span class="string">"price"</span>]</span><br><span class="line"><span class="comment"># 从pandas导入csv文件，将?标记为NaN缺失值</span></span><br><span class="line">df=pd.read_csv(<span class="string">"http://mlr.cs.umass.edu/ml/machine-learning-databases/autos/imports-85.data"</span>,header=<span class="keyword">None</span>,names=headers,na_values=<span class="string">"?"</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf3plqefj215n0ci75u.jpg" alt=""></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>symboling              int64normalized_losses    float64make                  objectfuel_type             objectaspiration            objectnum_doors             objectbody_style            objectdrive_wheels          objectengine_location       objectwheel_base           float64length               float64width                float64height               float64curb_weight            int64engine_type           objectnum_cylinders         objectengine_size            int64fuel_system           objectbore                 float64stroke               float64compression_ratio    float64horsepower           float64peak_rpm             float64city_mpg               int64highway_mpg            int64price                float64dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果只关注category 类型的数据，其实根本没有必要拿到这些全部数据，只需要将object类型的数据取出，然后进行后续分析即可</span></span><br><span class="line">obj_df = df.select_dtypes(include=[<span class="string">'object'</span>]).copy()</span><br><span class="line">obj_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf4zyk7fj215q0aomyh.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  在进行下一步处理的之前，需要将数据进行缺失值的处理，对列进行处理axis=1</span></span><br><span class="line">obj_df[obj_df.isnull().any(axis=<span class="number">1</span>)]</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf5ra63gj215k04emxn.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理缺失值的方式有很多种，根据项目的不同或者填补缺失值或者去掉该样本。本文中的数据缺失用该列的众数来补充。</span></span><br><span class="line">obj_df.num_doors.value_counts()</span><br></pre></td></tr></table></figure><pre><code>four    114two      89Name: num_doors, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj_df=obj_df.fillna(&#123;<span class="string">"num_doors"</span>:<span class="string">"four"</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="在处理完缺失值之后，有以下几种方式进行category数据转化encoding"><a href="#在处理完缺失值之后，有以下几种方式进行category数据转化encoding" class="headerlink" title="在处理完缺失值之后，有以下几种方式进行category数据转化encoding"></a>在处理完缺失值之后，有以下几种方式进行category数据转化encoding</h3><ul><li>Find and Replace</li><li>label encoding</li><li>One Hot encoding </li><li>Custom Binary encoding</li><li>sklearn</li><li>advanced Approaches</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  pandas里面的replace文档非常丰富，笔者在使用该功能时候，深感其参数众多，深感提供的功能也非常的强大</span></span><br><span class="line"><span class="comment"># 本文中使用replace的功能，创建map的字典，针对需要数据清理的列进行清理更加方便，例如：</span></span><br><span class="line">cleanup_nums= &#123;</span><br><span class="line">    <span class="string">"num_doors"</span>:&#123;<span class="string">"four"</span>:<span class="number">4</span>,<span class="string">"two"</span>:<span class="number">2</span>&#125;,</span><br><span class="line">    <span class="string">"num_cylinders"</span>:&#123;</span><br><span class="line">        <span class="string">"four"</span>:<span class="number">4</span>,<span class="string">"six"</span>:<span class="number">6</span>,<span class="string">"five"</span>:<span class="number">5</span>,<span class="string">"eight"</span>:<span class="number">8</span>,<span class="string">"two"</span>:<span class="number">2</span>,<span class="string">"twelve"</span>:<span class="number">12</span>,<span class="string">"three"</span>:<span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">obj_df.replace(cleanup_nums,inplace=<span class="keyword">True</span>)</span><br><span class="line">obj_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf702rzrj215k0anabc.jpg" alt=""></p><h4 id="label-encoding-是将一组无规则的，没有大小比较的数据转化为数字"><a href="#label-encoding-是将一组无规则的，没有大小比较的数据转化为数字" class="headerlink" title="label encoding 是将一组无规则的，没有大小比较的数据转化为数字"></a>label encoding 是将一组无规则的，没有大小比较的数据转化为数字</h4><ul><li>比如body_style 字段中含有多个数据值，可以使用该方法将其转化</li><li>convertible &gt; 0</li><li>hardtop  &gt; 1</li><li>hatchback  &gt; 2</li><li>sedan &gt; 3</li><li>wagon &gt; 4</li></ul><h4 id="这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样"><a href="#这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样" class="headerlink" title="这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样"></a>这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过pandas里面的 category数据类型，可以很方便的或者该编码</span></span><br><span class="line">obj_df[<span class="string">"body_style"</span>]=obj_df[<span class="string">"body_style"</span>].astype(<span class="string">"category"</span>)</span><br><span class="line">obj_df.dtypes</span><br></pre></td></tr></table></figure><pre><code>make                 objectfuel_type            objectaspiration           objectnum_doors             int64body_style         categorydrive_wheels         objectengine_location      objectengine_type          objectnum_cylinders         int64fuel_system          objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们可以通过赋值新的列，保存其对应的code</span></span><br><span class="line"><span class="comment"># 通过这种方法可以舒服的数据，便于以后的数据分析以及整理</span></span><br><span class="line">obj_df[<span class="string">"body_style_code"</span>] = obj_df[<span class="string">"body_style"</span>].cat.codes</span><br><span class="line">obj_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvfh4tpzuj213p0au3zi.jpg" alt=""></p><h4 id="one-hot-encoding"><a href="#one-hot-encoding" class="headerlink" title="one hot encoding"></a>one hot encoding</h4><ul><li>label encoding 因为将wagon转化为4，而convertible变成了0，这里面是不是会有大大小的比较，可能会造成误解，然后利用one hot encoding这种方式<br>是将特征转化为0或者1，这样会增加数据的列的数量，同时也减少了label encoding造成的衡量数据大小的误解。</li><li>pandas中提供了get_dummies 方法可以将需要转化的列的值转化为0,1,两种编码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新生成DataFrame包含了新生成的三列数据,</span></span><br><span class="line"><span class="comment"># drive_wheels_4wd </span></span><br><span class="line"><span class="comment"># drive_wheels_fwd</span></span><br><span class="line"><span class="comment"># drive_wheels_rwd</span></span><br><span class="line">pd.get_dummies(obj_df,columns=[<span class="string">"drive_wheels"</span>]).head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf9zuskxj20z90axq3j.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法之所以强大，是因为可以同时处理多个category的列，同时选择prefix前缀分别对应好</span></span><br><span class="line"><span class="comment"># 产生的新的DataFrame所有数据都包含</span></span><br><span class="line">pd.get_dummies(obj_df, columns=[<span class="string">"body_style"</span>, <span class="string">"drive_wheels"</span>], prefix=[<span class="string">"body"</span>, <span class="string">"drive"</span>]).head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvfbg1lg1j210n0aymxn.jpg" alt=""></p><h4 id="自定义0-1-encoding"><a href="#自定义0-1-encoding" class="headerlink" title="自定义0,1 encoding"></a>自定义0,1 encoding</h4><ul><li>有的时候回根据业务需要，可能会结合label encoding以及not hot 两种方式进行二值化。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj_df[<span class="string">"engine_type"</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>ohc      148ohcf      15ohcv      13dohc      12l         12rotor      4dohcv      1Name: engine_type, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有的时候为了区分出 engine_type是否是och技术的，可以使用二值化，将该列进行处理</span></span><br><span class="line"><span class="comment"># 这也突出了领域知识是如何以最有效的方式解决问题</span></span><br><span class="line">obj_df[<span class="string">"engine_type_code"</span>] = np.where(obj_df[<span class="string">"engine_type"</span>].str.contains(<span class="string">"ohc"</span>),<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">obj_df[[<span class="string">"make"</span>,<span class="string">"engine_type"</span>,<span class="string">"engine_type_code"</span>]].head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvfe3f1ybj20ky07w74l.jpg" alt=""></p><h3 id="scikit-learn中的数据转化"><a href="#scikit-learn中的数据转化" class="headerlink" title="scikit-learn中的数据转化"></a>scikit-learn中的数据转化</h3><ul><li>sklearn.processing模块提供了很多方便的数据转化以及缺失值处理方式。可以直接从该模块导入</li><li>Imputer</li><li>LabelEncoder，</li><li>LabelBinarizer，0,1归一化(最大最小标准化)，</li><li>Normalizer正则化（L1，L2）一般用的不多，</li><li>StandardScale 标准化</li><li>max_mixScale（最大最小标准化max_mix），</li><li>非线性转换包括，生成多项式特征(PolynomialFeatures),将每个特征缩放在同样的范围或分布情况下</li><li><a href="http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" target="_blank" rel="noopener">sklearn processing 模块官网文档链接</a></li><li><a href="http://contrib.scikit-learn.org/categorical-encoding/" target="_blank" rel="noopener">category_encoders包官方文档</a></li></ul><h4 id="至此，数据预处理以及category转化大致讲完了。"><a href="#至此，数据预处理以及category转化大致讲完了。" class="headerlink" title="至此，数据预处理以及category转化大致讲完了。"></a>至此，数据预处理以及category转化大致讲完了。</h4>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pandas datatype transform</title>
      <link href="/2018/08/02/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96/"/>
      <url>/2018/08/02/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96/</url>
      <content type="html"><![CDATA[<h3 id="数据处理过程的数据类型"><a href="#数据处理过程的数据类型" class="headerlink" title="数据处理过程的数据类型"></a>数据处理过程的数据类型</h3><ul><li>当利用pandas进行数据处理的时候，经常会遇到数据类型的问题，当拿到数据的时候，首先需要确定拿到的是正确类型的数据，一般通过数据类型的转化，这篇文章就介绍pandas里面的数据类型（data types也就是常用的dtyps），以及pandas与numpy之间的数据对应关系。</li><li><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fto9860xy9j20sl0bfgrk.jpg" alt=""></li><li>主要介绍object，int64，float64，datetime64，bool等几种类型，category与timedelta两种类型会单独的在其他文章中进行介绍。当然本文中也会涉及简单的介绍。</li></ul><h4 id="数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter-notebook进行一个数据类型的介绍。"><a href="#数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter-notebook进行一个数据类型的介绍。" class="headerlink" title="数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter notebook进行一个数据类型的介绍。"></a>数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter notebook进行一个数据类型的介绍。</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####按照惯例导入两个常用的数据处理的包，numpy与pandas</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 从csv文件读取数据，数据表格中只有5行，里面包含了float，string，int三种数据python类型，也就是分别对应的pandas的float64，object，int64</span></span><br><span class="line"><span class="comment"># csv文件中共有六列，第一列是表头，其余是数据。</span></span><br><span class="line">df = pd.read_csv(<span class="string">"sales_data_types.csv"</span>)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftunyo12lpj20uu0cp3zy.jpg" alt=""></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>Customer Number    float64Customer Name       object2016                object2017                objectPercent Growth      objectJan Units           objectMonth                int64Day                  int64Year                 int64Active              objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假如想得到2016年与2017年的数据总和，可以尝试,但并不是我们需要的答案，因为这两列中的数据类型是object，执行该操作之后，得到是一个更加长的字符串，</span></span><br><span class="line"><span class="comment"># 当然我们可以通过df.info() 来获得关于数据框的更多的详细信息，</span></span><br><span class="line">df[<span class="string">'2016'</span>]+df[<span class="string">'2017'</span>]</span><br></pre></td></tr></table></figure><pre><code>0      $125,000.00 $162,500.00 1    $920,000.00 $1,012,000.00 2        $50,000.00 $62,500.00 3      $350,000.00 $490,000.00 4        $15,000.00 $12,750.00 dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br><span class="line"><span class="comment"># Customer Number 列是float64，然而应该是int64</span></span><br><span class="line"><span class="comment"># 2016 2017两列的数据是object，并不是float64或者int64格式</span></span><br><span class="line"><span class="comment"># Percent以及Jan Units 也是objects而不是数字格式</span></span><br><span class="line"><span class="comment"># Month，Day以及Year应该转化为datetime64[ns]格式</span></span><br><span class="line"><span class="comment"># Active 列应该是布尔值</span></span><br><span class="line"><span class="comment"># 如果不做数据清洗，很难进行下一步的数据分析，为了进行数据格式的转化，pandas里面有三种比较常用的方法</span></span><br><span class="line"><span class="comment"># 1. astype()强制转化数据类型</span></span><br><span class="line"><span class="comment"># 2. 通过创建常用的函数进行数据转化</span></span><br><span class="line"><span class="comment"># 3. pandas提供的to_nueric()以及to_datetime()</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;RangeIndex: 5 entries, 0 to 4Data columns (total 10 columns):Customer Number    5 non-null float64Customer Name      5 non-null object2016               5 non-null object2017               5 non-null objectPercent Growth     5 non-null objectJan Units          5 non-null objectMonth              5 non-null int64Day                5 non-null int64Year               5 non-null int64Active             5 non-null objectdtypes: float64(1), int64(3), object(6)memory usage: 480.0+ bytes</code></pre><h3 id="首先介绍最常用的astype"><a href="#首先介绍最常用的astype" class="headerlink" title="首先介绍最常用的astype()"></a>首先介绍最常用的astype()</h3><h4 id="比如可以通过astype-将第一列的数据转化为整数int类型"><a href="#比如可以通过astype-将第一列的数据转化为整数int类型" class="headerlink" title="比如可以通过astype()将第一列的数据转化为整数int类型"></a>比如可以通过astype()将第一列的数据转化为整数int类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'Customer Number'</span>].astype(<span class="string">"int"</span>)</span><br><span class="line"><span class="comment">#  这样的操作并没有改变原始的数据框，而只是返回的一个拷贝</span></span><br></pre></td></tr></table></figure><pre><code>0     100021    5522782     234773     249004    651029Name: Customer Number, dtype: int32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 想要真正的改变数据框，通常需要通过赋值来进行，比如</span></span><br><span class="line">df[<span class="string">"Customer Number"</span>] = df[<span class="string">"Customer Number"</span>].astype(<span class="string">"int"</span>)</span><br><span class="line">print(<span class="string">"--------"</span>*<span class="number">10</span>)</span><br><span class="line">print(df.dtypes)</span><br></pre></td></tr></table></figure><pre><code>   Customer Number     Customer Name          2016            2017  \0            10002  Quest Industries  $125,000.00     $162,500.00    1           552278    Smith Plumbing  $920,000.00   $1,012,000.00    2            23477   ACME Industrial   $50,000.00      $62,500.00    3            24900        Brekke LTD  $350,000.00     $490,000.00    4           651029         Harbor Co   $15,000.00      $12,750.00      Percent Growth Jan Units  Month  Day  Year Active  0         30.00%       500      1   10  2015      Y  1         10.00%       700      6   15  2014      Y  2         25.00%       125      3   29  2016      Y  3          4.00%        75     10   27  2015      Y  4        -15.00%    Closed      2    2  2014      N  --------------------------------------------------------------------------------Customer Number     int32Customer Name      object2016               object2017               objectPercent Growth     objectJan Units          objectMonth               int64Day                 int64Year                int64Active             objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过赋值在原始的数据框基础上进行了数据转化，可以重新看一下我们新生成的数据框</span></span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftunzqcjudj20us0c9gn5.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后像2016,2017 Percent Growth，Jan Units 这几列带有特殊符号的object是不能直接通过astype("flaot)方法进行转化的，</span></span><br><span class="line"><span class="comment"># 这与python中的字符串转化为浮点数，都要求原始的字符都只能含有数字本身，不能含有其他的特殊字符</span></span><br><span class="line"><span class="comment"># 我们可以试着将将Active列转化为布尔值，看一下到底会发生什么,五个结果全是True，说明并没有起到什么作用</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#df["Active"].astype("bool")</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'2016'</span>].astype(<span class="string">'float'</span>)</span><br></pre></td></tr></table></figure><pre><code>---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)&lt;ipython-input-145-47cc9d68cd65&gt; in &lt;module&gt;()----&gt; 1 df[&apos;2016&apos;].astype(&apos;float&apos;)C:\Anaconda3\lib\site-packages\pandas\core\generic.py in astype(self, dtype, copy, raise_on_error, **kwargs)   3052         # else, only a single dtype is given   3053         new_data = self._data.astype(dtype=dtype, copy=copy,-&gt; 3054                                      raise_on_error=raise_on_error, **kwargs)   3055         return self._constructor(new_data).__finalize__(self)   3056 C:\Anaconda3\lib\site-packages\pandas\core\internals.py in astype(self, dtype, **kwargs)   3187    3188     def astype(self, dtype, **kwargs):-&gt; 3189         return self.apply(&apos;astype&apos;, dtype=dtype, **kwargs)   3190    3191     def convert(self, **kwargs):C:\Anaconda3\lib\site-packages\pandas\core\internals.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)   3054    3055             kwargs[&apos;mgr&apos;] = self-&gt; 3056             applied = getattr(b, f)(**kwargs)   3057             result_blocks = _extend_blocks(applied, result_blocks)   3058 C:\Anaconda3\lib\site-packages\pandas\core\internals.py in astype(self, dtype, copy, raise_on_error, values, **kwargs)    459                **kwargs):    460         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,--&gt; 461                             values=values, **kwargs)    462     463     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,C:\Anaconda3\lib\site-packages\pandas\core\internals.py in _astype(self, dtype, copy, raise_on_error, values, klass, mgr, **kwargs)    502     503                 # _astype_nansafe works fine with 1-d only--&gt; 504                 values = _astype_nansafe(values.ravel(), dtype, copy=True)    505                 values = values.reshape(self.shape)    506 C:\Anaconda3\lib\site-packages\pandas\types\cast.py in _astype_nansafe(arr, dtype, copy)    535     536     if copy:--&gt; 537         return arr.astype(dtype)    538     return arr.view(dtype)    539 ValueError: could not convert string to float: &apos;$15,000.00 &apos;</code></pre><h4 id="以上的问题说明了一些问题"><a href="#以上的问题说明了一些问题" class="headerlink" title="以上的问题说明了一些问题"></a>以上的问题说明了一些问题</h4><ul><li>如果数据是纯净的数据，可以转化为数字</li><li>astype基本也就是两种用作，数字转化为单纯字符串，单纯数字的字符串转化为数字，含有其他的非数字的字符串是不能通过astype进行转化的。</li><li>需要引入其他的方法进行转化，也就有了下面的自定义函数方法</li></ul><h3 id="通过自定义函数清理数据"><a href="#通过自定义函数清理数据" class="headerlink" title="通过自定义函数清理数据"></a>通过自定义函数清理数据</h3><ul><li>通过下面的函数可以将货币进行转化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_currency</span><span class="params">(var)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    convert the string number to a float</span></span><br><span class="line"><span class="string">    _ 去除$</span></span><br><span class="line"><span class="string">    - 去除逗号，</span></span><br><span class="line"><span class="string">    - 转化为浮点数类型</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    new_value = var.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)</span><br><span class="line">    <span class="keyword">return</span> float(new_value)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过replace函数将$以及逗号去掉，然后字符串转化为浮点数，让pandas选择pandas认为合适的特定类型，float或者int，该例子中将数据转化为了float64</span></span><br><span class="line"><span class="comment"># 通过pandas中的apply函数将2016列中的数据全部转化</span></span><br><span class="line">df[<span class="string">"2016"</span>].apply(convert_currency)</span><br></pre></td></tr></table></figure><pre><code>0    125000.01    920000.02     50000.03    350000.04     15000.0Name: 2016, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当然可以通过lambda 函数将这个比较简单的函数一行带过</span></span><br><span class="line">df[<span class="string">"2016"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)).astype(<span class="string">"float64"</span>)</span><br></pre></td></tr></table></figure><pre><code>0    125000.01    920000.02     50000.03    350000.04     15000.0Name: 2016, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#同样可以利用lambda表达式将PercentGrowth进行数据清理</span></span><br><span class="line">df[<span class="string">"Percent Growth"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">"%"</span>,<span class="string">""</span>)).astype(<span class="string">"float"</span>)/<span class="number">100</span></span><br></pre></td></tr></table></figure><pre><code>0    0.301    0.102    0.253    0.044   -0.15Name: Percent Growth, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同样可以通过自定义函数进行解决，结果同上</span></span><br><span class="line"><span class="comment"># 最后一个自定义函数是利用np.where() function 将Active 列转化为布尔值。</span></span><br><span class="line">df[<span class="string">"Active"</span>] = np.where(df[<span class="string">"Active"</span>] == <span class="string">"Y"</span>, <span class="keyword">True</span>, <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">"Active"</span>]</span><br></pre></td></tr></table></figure><pre><code>0     True1     True2     True3     True4    FalseName: Active, dtype: bool</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时可查看一下数据格式</span></span><br><span class="line">df[<span class="string">"2016"</span>]=df[<span class="string">"2016"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)).astype(<span class="string">"float64"</span>)</span><br><span class="line">df[<span class="string">"2017"</span>]=df[<span class="string">"2017"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)).astype(<span class="string">"float64"</span>)</span><br><span class="line">df[<span class="string">"Percent Growth"</span>]=df[<span class="string">"Percent Growth"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">"%"</span>,<span class="string">""</span>)).astype(<span class="string">"float"</span>)/<span class="number">100</span></span><br><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>Customer Number      int32Customer Name       object2016               float642017               float64Percent Growth     float64Jan Units           objectMonth                int64Day                  int64Year                 int64Active                booldtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次查看DataFrame</span></span><br><span class="line"><span class="comment"># 此时只有Jan Units中格式需要转化，以及年月日的合并，可以利用pandas中自带的几个函数进行处理</span></span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftuo1ogfioj20vd0bw3zt.jpg" alt=""></p><h3 id="利用pandas中函数进行处理"><a href="#利用pandas中函数进行处理" class="headerlink" title="利用pandas中函数进行处理"></a>利用pandas中函数进行处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pandas中pd.to_numeric()处理Jan Units中的数据</span></span><br><span class="line">pd.to_numeric(df[<span class="string">"Jan Units"</span>],errors=<span class="string">'coerce'</span>).fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>0    500.01    700.02    125.03     75.04      0.0Name: Jan Units, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最后利用pd.to_datatime()将年月日进行合并</span></span><br><span class="line">pd.to_datetime(df[[<span class="string">'Month'</span>, <span class="string">'Day'</span>, <span class="string">'Year'</span>]])</span><br></pre></td></tr></table></figure><pre><code>0   2015-01-101   2014-06-152   2016-03-293   2015-10-274   2014-02-02dtype: datetime64[ns]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 做到这里不要忘记重新赋值，否则原始数据并没有变化</span></span><br><span class="line">df[<span class="string">"Jan Units"</span>] = pd.to_numeric(df[<span class="string">"Jan Units"</span>],errors=<span class="string">'coerce'</span>)</span><br><span class="line">df[<span class="string">"Start_date"</span>] = pd.to_datetime(df[[<span class="string">'Month'</span>, <span class="string">'Day'</span>, <span class="string">'Year'</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftuo34c4tlj214308m75j.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>Customer Number             int32Customer Name              object2016                      float642017                      float64Percent Growth            float64Jan Units                 float64Month                       int64Day                         int64Year                        int64Active                       boolStart_date         datetime64[ns]dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将这些转化整合在一起</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_percent</span><span class="params">(val)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Convert the percentage string to an actual floating point percent</span></span><br><span class="line"><span class="string">    - Remove %</span></span><br><span class="line"><span class="string">    - Divide by 100 to make decimal</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    new_val = val.replace(<span class="string">'%'</span>, <span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> float(new_val) / <span class="number">100</span></span><br><span class="line"></span><br><span class="line">df_2 = pd.read_csv(<span class="string">"sales_data_types.csv"</span>,dtype=&#123;<span class="string">"Customer_Number"</span>:<span class="string">"int"</span>&#125;,converters=&#123;</span><br><span class="line">    <span class="string">"2016"</span>:convert_currency,</span><br><span class="line">    <span class="string">"2017"</span>:convert_currency,</span><br><span class="line">    <span class="string">"Percent Growth"</span>:convert_percent,</span><br><span class="line">    <span class="string">"Jan Units"</span>:<span class="keyword">lambda</span> x:pd.to_numeric(x,errors=<span class="string">"coerce"</span>),</span><br><span class="line">    <span class="string">"Active"</span>:<span class="keyword">lambda</span> x: np.where(x==<span class="string">"Y"</span>,<span class="keyword">True</span>,<span class="keyword">False</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_2.dtypes</span><br><span class="line"><span class="comment">#</span></span><br></pre></td></tr></table></figure><pre><code>Customer Number      int64Customer Name       object2016               float642017               float64Percent Growth      objectJan Units          float64Month                int64Day                  int64Year                 int64Active              booldtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_2</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftuosn84wxj20lq04y74n.jpg" alt=""></p><h3 id="至此，pandas里面数据类型目前还有timedelta以及category两个-之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas-0-16-之后添加的，之后还会根据需要进行整理pandas的常用方法。"><a href="#至此，pandas里面数据类型目前还有timedelta以及category两个-之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas-0-16-之后添加的，之后还会根据需要进行整理pandas的常用方法。" class="headerlink" title="至此，pandas里面数据类型目前还有timedelta以及category两个,之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas 0.16 之后添加的，之后还会根据需要进行整理pandas的常用方法。"></a>至此，pandas里面数据类型目前还有timedelta以及category两个,之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas 0.16 之后添加的，之后还会根据需要进行整理pandas的常用方法。</h3>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logistic regression</title>
      <link href="/2018/07/16/logistic-regression/"/>
      <url>/2018/07/16/logistic-regression/</url>
      <content type="html"><![CDATA[<h2 id="第三章-使用sklearn-实现机学习的分类算法"><a href="#第三章-使用sklearn-实现机学习的分类算法" class="headerlink" title="第三章 使用sklearn 实现机学习的分类算法"></a>第三章 使用sklearn 实现机学习的分类算法</h2><h3 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h3><ul><li>分类器的性能与计算能力和预测性能很大程度上取决于用于模型训练的数据</li><li>训练机器学习算法的五个步骤：<ol><li>特征的选择</li><li>确定评价性能的标准</li><li>选择分类器及其优化算法</li><li><em>对模型性能的评估</em></li><li><strong>算法的调优</strong></li></ol></li></ul><a id="more"></a><h3 id="sklearn初步使用"><a href="#sklearn初步使用" class="headerlink" title="sklearn初步使用"></a>sklearn初步使用</h3><ul><li>3.1 sklearn中包括的processing 模块中的标准化类，StandardScaler对特征进行标准化处理<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.processing <span class="keyword">import</span> StandardSacler</span><br><span class="line">sc = StandardScaler() <span class="comment">#实例化</span></span><br><span class="line">sc.fit(X_train)</span><br><span class="line">sc.transform(X_train)</span><br><span class="line"><span class="comment"># - 以上两句可以并写成一句sc.fit_transform(X_trian)</span></span><br><span class="line"><span class="comment"># - 我们使用相同的放缩参数分别对训练和测试数据集以保证他们的值是彼此相当的。**但是在使用fit_transform 只能对训练集使用，而测试机则只使用fit即可。**</span></span><br><span class="line"><span class="comment"># - sklearn中的metrics类中包含了很多的评估参数，其中accuracy_score,</span></span><br><span class="line"><span class="comment"># - 中accuracy_score(y_test,y_pred)，也就是那y_test与预测值相比较，得出正确率</span></span><br><span class="line">y_pred = model.predict(X_test-std)</span><br></pre></td></tr></table></figure></li></ul><h3 id="过拟合现象"><a href="#过拟合现象" class="headerlink" title="过拟合现象"></a>过拟合现象</h3><p>过拟合现象出现有两个原因：</p><ul><li>训练集与测试集特征分布不一致（黑天鹅和白天鹅）</li><li>模型训练的太过复杂，而样本量不足。<br>同时针对两个原因而出现的解决方法:</li><li>收集多样化的样本</li><li>简化模型</li><li>交叉检验<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftbixvvcy7j30tz0alab2.jpg" alt="模型拟合"></li></ul><h3 id="逻辑斯谛回归"><a href="#逻辑斯谛回归" class="headerlink" title="逻辑斯谛回归"></a>逻辑斯谛回归</h3><p>感知机的一个最大缺点是：在样本不是完全线性可分的情况下，它永远不会收敛。<br>分类算中的另一个简单高效的方法：logistics regression（分类模型）</p><ul><li>很多情况下，我们会将逻辑回归的输出映射到二元分类问题的解决方案，需要确保逻辑回归的输出始终落在在0-1之间，此时S型函数的输出值正好满足了这个条件，其中：<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftbjqo8f7rj30ai021gld.jpg" alt=""></li></ul><h3 id="几率比（odd-ratio）"><a href="#几率比（odd-ratio）" class="headerlink" title="几率比（odd ratio）"></a>几率比（odd ratio）</h3><p>特定的事件的发生的几率，用数学公式表示为：$\frac{p}{1-p} $，其中p为正事件的概率，不一定是有利的事件，而是我们将要预测的事件。以一个患者患有某种疾病的概率，我们可以将正事件的类标标记为y=1。<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftbjl34vj9j30in06b74o.jpg" alt="如图"></p><ul><li>也就是样本特征与权重的线性组合，其计算公式：<br>  z = w·x + b</li><li>预测得到的概率可以通过一个量化器（单位阶跃函数）简单的转化为二元输出</li><li>如果y＞0.5 则判断该样本类别为1，如y＜0.5，则判定该样本是其他类别。</li><li>对应上面的展开式，如果z≥0，则判断类别是1，否则是其他。</li><li>阈值也就是0.5</li></ul><h3 id="通过逻辑斯谛回归模型的代价函数获得权重"><a href="#通过逻辑斯谛回归模型的代价函数获得权重" class="headerlink" title="通过逻辑斯谛回归模型的代价函数获得权重"></a>通过逻辑斯谛回归模型的代价函数获得权重</h3><ul><li>判定某个样本属于类别1或者0 的条件概率如下：<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftbko85i86j30ed03dmxk.jpg" alt=""></li><li>逻辑回回归的代价函数是最小二乘损失函数<br><img src="https://s1.ax1x.com/2018/07/16/PQBB5D.png" alt="PQBB5D.png"></li><li>为了推导出逻辑斯蒂回归的代价函数，需要先定义一个极大似然函数L,<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc1tr86pvj30be01pdfn.jpg" alt=""></li><li>用极大似然估计来根据给定的训练集估计出参数w,对上式两边取对数，化简为<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc1ycsz6hj30dg0123yd.jpg" alt=""><br>求极大似然函数的最大值等价于求-l(w)的最小值，即：<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc2jimakjj30e101kwec.jpg" alt=""></li></ul><h3 id="利用梯度下降法求参数"><a href="#利用梯度下降法求参数" class="headerlink" title="利用梯度下降法求参数"></a>利用梯度下降法求参数</h3><ul><li>在开始梯度下降之前，sigmoid function有一个很好的性质，<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftc2zhxk86j307101nt8h.jpg" alt=""><br>梯度的负方向就是代价函数下降最快的方向，借助泰勒展开，可以得到（函数可微，可导）<br><img src="http://wx3.sinaimg.cn/mw690/0060lm7Tly1ftc33bmu45j306q00wa9u.jpg" alt=""><br>其中，f’(x) 和δ为向量，那么这两者的内积就等于<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftc36jdvpzj308g018mwy.jpg" alt=""><br>当θ=π时，也就是在δ与f’(x)的方向相反时，取得最小值， 也就是下降的最快的方向了<br>这里也就是: f(x+δ) - f(x) = - ||δ||·||f’(x)||<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftc3wrla2qj307j01f742.jpg" alt=""><br>也就是<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc3yrla04j308101gq2q.jpg" alt=""></li><li>其中，wj表示第j个特征的权重，η为学习率，用来控制步长。</li><li>对损失函数<em>J</em>(w))中的w的第j个权重求偏导，<img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc42cfb1aj30gp0533yr.jpg" alt=""><br>所以，在使用梯度下降法更新权重时，只要根据公式<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftc4m2t1e8j307z015dfn.jpg" alt=""><br>当样本量极大的时候，每次更新权重需要耗费大量的算力，这时可以采取随机梯度下降法，这时，每次迭代的时候需要将样本重新打乱，然后用下面的式子更新权重<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc4pl81xyj30av01aglg.jpg" alt=""></li></ul><p>参考文献:</p><ul><li>Raschka S. Python Machine Learning[M]. Packt Publishing, 2015</li><li>周志华. 机器学习 : = Machine learning[M]. 清华大学出版社, 2016.</li></ul>]]></content>
      
      <categories>
          
          <category> regression </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> logistic regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title> general regression models </title>
      <link href="/2018/07/11/general-regression-models/"/>
      <url>/2018/07/11/general-regression-models/</url>
      <content type="html"><![CDATA[<h3 id="1-1-1-Ordinary-Least-Squares"><a href="#1-1-1-Ordinary-Least-Squares" class="headerlink" title="1.1.1. Ordinary Least Squares"></a>1.1.1. Ordinary Least Squares</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg = linear_model.LinearRegression()</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure><a id="more"></a><pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.coef_</span><br></pre></td></tr></table></figure><pre><code>array([0.5, 0.5])</code></pre><p>最小二乘法的代价函数表述为：<br><img src="http://scikit-learn.org/stable/_images/math/e8e92a5482d9327d939e7a17946a8a1b98006018.png" alt=""></p><h3 id="1-1-2-Ridge-Regression"><a href="#1-1-2-Ridge-Regression" class="headerlink" title="1.1.2 Ridge Regression"></a>1.1.2 Ridge Regression</h3><h4 id="岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和"><a href="#岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和" class="headerlink" title="岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和"></a>岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和</h4><ul><li>现行回归含有惩罚项的代价函数表述为：<br><img src="http://scikit-learn.org/stable/_images/math/48dbdad39c89539c714a825c0c0d5524eb526851.png" alt=""></li><li>正则化的背后的概念是引入额外的信息（偏差）来对极端参数的权重做出惩罚，此处的正则化则是引入的L2正则化。</li><li>代价函数的参数α的变化导致权重稀疏的变化，岭回归即L2正则化（L2收缩），也<strong>叫权重衰减</strong>：<br><img src="http://scikit-learn.org/stable/_images/sphx_glr_plot_ridge_path_0011.png" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg= linear_model.Ridge(alpha=<span class="number">0.5</span>)</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,   normalize=False, random_state=None, solver=&apos;auto&apos;, tol=0.001)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.intercept_</span><br></pre></td></tr></table></figure><pre><code>0.1363636363636364</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.coef_</span><br></pre></td></tr></table></figure><pre><code>array([0.34545455, 0.34545455])</code></pre><h4 id="1-1-2-1-Setting-the-regularization-parameter-generalized-Cross-Validation-通过交叉验证获得回归效果最恰当的惩罚项的参数"><a href="#1-1-2-1-Setting-the-regularization-parameter-generalized-Cross-Validation-通过交叉验证获得回归效果最恰当的惩罚项的参数" class="headerlink" title="1.1.2.1 Setting the regularization parameter: generalized Cross-Validation 通过交叉验证获得回归效果最恰当的惩罚项的参数"></a>1.1.2.1 Setting the regularization parameter: generalized Cross-Validation 通过交叉验证获得回归效果最恰当的惩罚项的参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg=linear_model.RidgeCV(alphas=[<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>])</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>RidgeCV(alphas=[0.1, 1.0, 10.0], cv=None, fit_intercept=True, gcv_mode=None,    normalize=False, scoring=None, store_cv_values=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.alpha_</span><br></pre></td></tr></table></figure><pre><code>0.1</code></pre><h4 id="1-1-3-Lasso-权重稀疏）"><a href="#1-1-3-Lasso-权重稀疏）" class="headerlink" title="1.1.3 Lasso(权重稀疏）"></a>1.1.3 Lasso(权重稀疏）</h4><ul><li>L1正则化可生成稀疏的特征向量，且大多数的权值为0，当高维的数据集中包含许多不想管的特征，尤其是在不相关的特征数量大于样本数量是，权重的稀疏化可以发挥特征选择的作用。</li><li>损失函数可以表示为：<br><img src="http://scikit-learn.org/stable/_images/math/07c30d8004d4406105b2547be4f3050048531656.png" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg= linear_model.Lasso(alpha=<span class="number">0.1</span>)</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]],[<span class="number">0</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,   normalize=False, positive=False, precompute=False, random_state=None,   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">reg.predict([[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># 如果是一维数组的话，需要在外面再加一层中括号，或者</span></span><br></pre></td></tr></table></figure><pre><code>array([0.8])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg</span><br></pre></td></tr></table></figure><pre><code>Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,   normalize=False, positive=False, precompute=False, random_state=None,   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.coef_</span><br></pre></td></tr></table></figure><pre><code>array([0.6, 0. ])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.intercept_</span><br></pre></td></tr></table></figure><pre><code>0.2</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> regression </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Bagging和Boosting的概念与区别</title>
      <link href="/2018/06/11/Hello-hexo/"/>
      <url>/2018/06/11/Hello-hexo/</url>
      <content type="html"><![CDATA[<h2 id="Bagging和Boosting的概念与区别"><a href="#Bagging和Boosting的概念与区别" class="headerlink" title="Bagging和Boosting的概念与区别"></a>Bagging和Boosting的概念与区别</h2><h3 id="随机森林属于集成学习-ensemble-learning-中的bagging算法，在集成算法中主要分为bagging算法与boosting算法"><a href="#随机森林属于集成学习-ensemble-learning-中的bagging算法，在集成算法中主要分为bagging算法与boosting算法" class="headerlink" title="随机森林属于集成学习(ensemble learning)中的bagging算法，在集成算法中主要分为bagging算法与boosting算法"></a>随机森林属于集成学习(ensemble learning)中的bagging算法，在集成算法中主要分为bagging算法与boosting算法</h3><hr><h4 id="Bagging算法-套袋法，bootstrap-aggregating"><a href="#Bagging算法-套袋法，bootstrap-aggregating" class="headerlink" title="Bagging算法(套袋法，bootstrap aggregating)"></a>Bagging算法(套袋法，bootstrap aggregating)</h4><ul><li>bagging的算法过程如下：</li><li>从原始样本集中使用Bootstraping 方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集（k个训练集之间相互独立，元素可以有重复）。</li><li>对于n个训练集，我们训练k个模型，（这个模型可根据具体的情况而定，可以是决策树，knn等）</li><li>对于分类问题：由投票表决产生的分类结果；对于回归问题，由k个模型预测结果的均值作为最后预测的结果（所有模型的重要性相同）。</li></ul><a id="more"></a><h4 id="Boosting（提升法）"><a href="#Boosting（提升法）" class="headerlink" title="Boosting（提升法）"></a>Boosting（提升法）</h4><ul><li>boosting的算法过程如下： </li><li>对于训练集中的每个样本建立权值wi，表示对每个样本的权重， 其关键在与对于被错误分类的样本权重会在下一轮的分类中获得更大的权重（错误分类的样本的权重增加）。</li><li>同时加大分类 误差概率小的弱分类器的权值，使其在表决中起到更大的作用，减小分类误差率较大弱分类器的权值，使其在表决中起到较小的作用。每一次迭代都得到一个弱分类器，需要使用某种策略将其组合，最为最终模型，(adaboost给每个迭代之后的弱分类器一个权值，将其线性组合作为最终的分类器,误差小的分类器权值越大。)</li></ul><h4 id="Bagging和Boosting-的主要区别"><a href="#Bagging和Boosting-的主要区别" class="headerlink" title="Bagging和Boosting 的主要区别"></a>Bagging和Boosting 的主要区别</h4><ul><li>样本选择上: Bagging采取Bootstraping的是随机有放回的取样，Boosting的每一轮训练的样本是固定的，改变的是每个样的权重。</li><li>样本权重上：<strong>Bagging采取的是均匀取样，且每个样本的权重相同</strong>，Boosting根据错误率调整样本权重，错误率越大的样本权重会变大</li><li>预测函数上：<strong>Bagging所以的预测函数权值相同</strong>，Boosting中误差越小的预测函数其权值越大。</li><li>并行计算: Bagging 的各个预测函数可以并行生成;Boosting的各个预测函数必须按照顺序迭代生成.</li></ul><h4 id="将决策树与以上框架组合成新的算法"><a href="#将决策树与以上框架组合成新的算法" class="headerlink" title="将决策树与以上框架组合成新的算法"></a>将决策树与以上框架组合成新的算法</h4><ul><li>Bagging + 决策树 = 随机森林</li><li>AdaBoost + 决策树 = 提升树</li><li>gradient + 决策树 = （梯度提升树）GDBT </li></ul><h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><ul><li>常用的决策树有ID3， C4.5 ,CART三种. 三种算法模型构架相似，只是采用了不同的指标</li></ul><h4 id="首先看ID3算法"><a href="#首先看ID3算法" class="headerlink" title="首先看ID3算法"></a>首先看ID3算法</h4><ul><li>基于奥卡姆剃刀原理，即用尽量较少的东西做更多的事。ID3算法即iterative Dichotomiser3，迭代二叉树三代，越是小型的决策树优于较大的决策树。</li><li>核心思想是以信息增益来度量属性的选择，选择分裂后信息增益最大的属性进行分类。</li><li>信息增益是属性选择中一个重要指标，它定义为一个属性能够为分类系统带来的多少信息，带来的信息越多，该属性就越重要，而信息量，就是熵。</li><li>熵的定义是信息量的期望值，熵越大，一个变量的不确定性越大，它带来的信息量就越大，计算信息熵的公式为：<img src="https://github.com/KeKe-Li/tutorial/raw/master/assets/images/176.jpg" alt="">，其中，p为出现c分类时的概率。</li><li>如何计算一个属性的信息增益？</li></ul>]]></content>
      
      <categories>
          
          <category> ensemble method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> boosting </tag>
            
            <tag> 集成算法 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
