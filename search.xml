<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>doubanan_top250_analysis</title>
      <link href="/2018/08/08/douban-top250-analysis/"/>
      <url>/2018/08/08/douban-top250-analysis/</url>
      <content type="html"><![CDATA[<h3 id="豆瓣电影top250数据分析"><a href="#豆瓣电影top250数据分析" class="headerlink" title="豆瓣电影top250数据分析"></a>豆瓣电影top250数据分析</h3><ul><li>数据来源（豆瓣电影top250）</li><li>爬虫代码比较简单</li><li>数据较为真实，可以进行初步的数据分析</li><li>可以将前面的几篇文章中的介绍的数据预处理的方法进行实践</li><li>最后用matplotlib与pyecharts两种可视化包进行部分数据展示</li><li>数据仍需深挖，有待加强</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先按照惯例导入python 数据分析的两个包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br></pre></td></tr></table></figure><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">names=[<span class="string">'num'</span>,<span class="string">'title'</span>,<span class="string">"director"</span>,<span class="string">"role"</span>,<span class="string">"init_year"</span>,<span class="string">"area"</span>,<span class="string">"genre"</span>,<span class="string">"rating_num"</span>,<span class="string">"comment_num"</span>,<span class="string">"comment"</span>,<span class="string">"url"</span>]</span><br><span class="line"><span class="comment">#"num#title#director#role#init_year#area#genre#rating_num#comment_num#comment#url"</span></span><br><span class="line">df_1 = pd.read_excel(<span class="string">"top250_f1.xls"</span>,index=<span class="keyword">None</span>,header=<span class="keyword">None</span>)</span><br><span class="line">df_1.columns=names</span><br><span class="line">df_1.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bfj69udj215f0hpn07.jpg" alt=""></p><ul><li>查看数据类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_1.dtypes</span><br></pre></td></tr></table></figure><pre><code>num              int64title           objectdirector        objectrole            objectinit_year       objectarea            objectgenre           objectrating_num     float64comment_num      int64comment         objecturl             objectdtype: object</code></pre><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">names1=[<span class="string">"num"</span>,<span class="string">"rank"</span>,<span class="string">"alt_title"</span>,<span class="string">"title"</span>,<span class="string">"pubdate"</span>,<span class="string">"language"</span>,<span class="string">"writer"</span>,<span class="string">"director"</span>,<span class="string">"cast"</span>,<span class="string">"movie_duration"</span>,<span class="string">"year"</span>,<span class="string">"movie_type"</span>,<span class="string">"tags"</span>,<span class="string">"image"</span>]</span><br><span class="line">df_2 = pd.read_excel(<span class="string">"top250_f2.xlsx"</span>,index=<span class="keyword">None</span>,header=<span class="keyword">None</span>)</span><br><span class="line">df_2.columns=names1</span><br><span class="line">df_2.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;RangeIndex: 250 entries, 0 to 249Data columns (total 14 columns):num               250 non-null int64rank              250 non-null float64alt_title         250 non-null objecttitle             250 non-null objectpubdate           250 non-null objectlanguage          250 non-null objectwriter            250 non-null objectdirector          250 non-null objectcast              250 non-null objectmovie_duration    250 non-null objectyear              250 non-null objectmovie_type        250 non-null objecttags              250 non-null objectimage             250 non-null objectdtypes: float64(1), int64(1), object(12)memory usage: 27.4+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_1_cut = df_1[[<span class="string">'num'</span>,<span class="string">'title'</span>,<span class="string">'init_year'</span>,<span class="string">'area'</span>,<span class="string">'genre'</span>,<span class="string">'rating_num'</span>,<span class="string">'comment_num'</span>]]</span><br><span class="line">df_2_cut = df_2[[<span class="string">'num'</span>,<span class="string">'language'</span>,<span class="string">'director'</span>,<span class="string">'cast'</span>,<span class="string">'movie_duration'</span>,<span class="string">'tags'</span>]]</span><br><span class="line">df = pd.merge(df_1_cut,df_2_cut,how = <span class="string">'outer'</span>,on = <span class="string">'num'</span>)   <span class="comment">#外连接，合并标准on = 'num'</span></span><br><span class="line"><span class="comment"># df.to_excel("all_data_movie.xls",index=False)         #查看前五条信息</span></span><br></pre></td></tr></table></figure><ul><li>查看重复数据 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看重复数据</span></span><br><span class="line">df.duplicated()</span><br><span class="line">df.duplicated().value_counts()</span><br></pre></td></tr></table></figure><pre><code>False    250dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.title.unique()</span><br></pre></td></tr></table></figure><pre><code>array([&apos;肖申克的救赎&apos;, &apos;霸王别姬&apos;, &apos;这个杀手不太冷&apos;, &apos;阿甘正传&apos;, &apos;美丽人生&apos;, &apos;泰坦尼克号&apos;, &apos;千与千寻&apos;,       &apos;辛德勒的名单&apos;, &apos;盗梦空间&apos;, &apos;机器人总动员&apos;, &apos;三傻大闹宝莱坞&apos;, &apos;忠犬八公的故事&apos;, &apos;海上钢琴师&apos;, &apos;放牛班的春天&apos;,       &apos;大话西游之大圣娶亲&apos;, &apos;楚门的世界&apos;, &apos;教父&apos;, &apos;龙猫&apos;, &apos;星际穿越&apos;, &apos;熔炉&apos;, &apos;触不可及&apos;, &apos;无间道&apos;,       &apos;乱世佳人&apos;, &apos;当幸福来敲门&apos;, &apos;怦然心动&apos;, &apos;天堂电影院&apos;, &apos;十二怒汉&apos;, &apos;鬼子来了&apos;, &apos;蝙蝠侠：黑暗骑士&apos;,       &apos;疯狂动物城&apos;, &apos;少年派的奇幻漂流&apos;, &apos;活着&apos;, &apos;搏击俱乐部&apos;, &apos;指环王3：王者无敌&apos;, &apos;天空之城&apos;,       &apos;大话西游之月光宝盒&apos;, &apos;飞屋环游记&apos;, &apos;罗马假日&apos;, &apos;控方证人&apos;, &apos;窃听风暴&apos;, &apos;两杆大烟枪&apos;, &apos;飞越疯人院&apos;,       &apos;闻香识女人&apos;, &apos;哈尔的移动城堡&apos;, &apos;辩护人&apos;, &apos;海豚湾&apos;, &apos;V字仇杀队&apos;, &apos;死亡诗社&apos;, &apos;摔跤吧！爸爸&apos;, &apos;教父2&apos;,       &apos;指环王2：双塔奇兵&apos;, &apos;美丽心灵&apos;, &apos;指环王1：魔戒再现&apos;, &apos;饮食男女&apos;, &apos;情书&apos;, &apos;美国往事&apos;, &apos;狮子王&apos;, &apos;素媛&apos;,       &apos;钢琴家&apos;, &apos;小鞋子&apos;, &apos;七宗罪&apos;, &apos;天使爱美丽&apos;, &apos;被嫌弃的松子的一生&apos;, &apos;致命魔术&apos;, &apos;本杰明·巴顿奇事&apos;,       &apos;音乐之声&apos;, &apos;西西里的美丽传说&apos;, &apos;勇敢的心&apos;, &apos;拯救大兵瑞恩&apos;, &apos;黑客帝国&apos;, &apos;低俗小说&apos;, &apos;剪刀手爱德华&apos;,       &apos;让子弹飞&apos;, &apos;看不见的客人&apos;, &apos;沉默的羔羊&apos;, &apos;蝴蝶效应&apos;, &apos;入殓师&apos;, &apos;大闹天宫&apos;, &apos;春光乍泄&apos;, &apos;末代皇帝&apos;,       &apos;心灵捕手&apos;, &apos;玛丽和马克思&apos;, &apos;阳光灿烂的日子&apos;, &apos;哈利·波特与魔法石&apos;, &apos;布达佩斯大饭店&apos;, &apos;幽灵公主&apos;, &apos;第六感&apos;,       &apos;禁闭岛&apos;, &apos;重庆森林&apos;, &apos;猫鼠游戏&apos;, &apos;狩猎&apos;, &apos;致命ID&apos;, &apos;大鱼&apos;, &apos;断背山&apos;, &apos;甜蜜蜜&apos;,       &apos;射雕英雄传之东成西就&apos;, &apos;告白&apos;, &apos;一一&apos;, &apos;加勒比海盗&apos;, &apos;穿条纹睡衣的男孩&apos;, &apos;阳光姐妹淘&apos;, &apos;摩登时代&apos;,       &apos;阿凡达&apos;, &apos;上帝之城&apos;, &apos;爱在黎明破晓前&apos;, &apos;消失的爱人&apos;, &apos;风之谷&apos;, &apos;爱在日落黄昏时&apos;, &apos;侧耳倾听&apos;, &apos;超脱&apos;,       &apos;倩女幽魂&apos;, &apos;恐怖直播&apos;, &apos;红辣椒&apos;, &apos;小森林 夏秋篇&apos;, &apos;喜剧之王&apos;, &apos;菊次郎的夏天&apos;, &apos;驯龙高手&apos;, &apos;幸福终点站&apos;,       &apos;萤火虫之墓&apos;, &apos;借东西的小人阿莉埃蒂&apos;, &apos;岁月神偷&apos;, &apos;神偷奶爸&apos;, &apos;七武士&apos;, &apos;杀人回忆&apos;, &apos;贫民窟的百万富翁&apos;,       &apos;电锯惊魂&apos;, &apos;喜宴&apos;, &apos;谍影重重3&apos;, &apos;真爱至上&apos;, &apos;怪兽电力公司&apos;, &apos;东邪西毒&apos;, &apos;记忆碎片&apos;, &apos;海洋&apos;,       &apos;黑天鹅&apos;, &apos;雨人&apos;, &apos;疯狂原始人&apos;, &apos;卢旺达饭店&apos;, &apos;小森林 冬春篇&apos;, &apos;英雄本色&apos;, &apos;哈利·波特与死亡圣器(下)&apos;,       &apos;燃情岁月&apos;, &apos;7号房的礼物&apos;, &apos;虎口脱险&apos;, &apos;心迷宫&apos;, &apos;萤火之森&apos;, &apos;傲慢与偏见&apos;, &apos;荒蛮故事&apos;, &apos;海边的曼彻斯特&apos;,       &apos;请以你的名字呼唤我&apos;, &apos;教父3&apos;, &apos;恋恋笔记本&apos;, &apos;完美的世界&apos;, &apos;纵横四海&apos;, &apos;花样年华&apos;, &apos;唐伯虎点秋香&apos;,       &apos;超能陆战队&apos;, &apos;玩具总动员3&apos;, &apos;蝙蝠侠：黑暗骑士崛起&apos;, &apos;时空恋旅人&apos;, &apos;魂断蓝桥&apos;, &apos;猜火车&apos;, &apos;穿越时空的少女&apos;,       &apos;雨中曲&apos;, &apos;二十二&apos;, &apos;达拉斯买家俱乐部&apos;, &apos;我是山姆&apos;, &apos;人工智能&apos;, &apos;冰川时代&apos;, &apos;浪潮&apos;, &apos;朗读者&apos;,       &apos;爆裂鼓手&apos;, &apos;香水&apos;, &apos;罗生门&apos;, &apos;未麻的部屋&apos;, &apos;阿飞正传&apos;, &apos;血战钢锯岭&apos;, &apos;一次别离&apos;, &apos;被解救的姜戈&apos;,       &apos;可可西里&apos;, &apos;追随&apos;, &apos;恐怖游轮&apos;, &apos;撞车&apos;, &apos;战争之王&apos;, &apos;头脑特工队&apos;, &apos;地球上的星星&apos;, &apos;房间&apos;, &apos;无人知晓&apos;,       &apos;梦之安魂曲&apos;, &apos;牯岭街少年杀人事件&apos;, &apos;魔女宅急便&apos;, &apos;谍影重重&apos;, &apos;谍影重重2&apos;, &apos;忠犬八公物语&apos;, &apos;模仿游戏&apos;,       &apos;你的名字。&apos;, &apos;惊魂记&apos;, &apos;青蛇&apos;, &apos;一个叫欧维的男人决定去死&apos;, &apos;再次出发之纽约遇见你&apos;, &apos;哪吒闹海&apos;, &apos;完美陌生人&apos;,       &apos;东京物语&apos;, &apos;小萝莉的猴神大叔&apos;, &apos;黑客帝国3：矩阵革命&apos;, &apos;源代码&apos;, &apos;新龙门客栈&apos;, &apos;终结者2：审判日&apos;,       &apos;末路狂花&apos;, &apos;碧海蓝天&apos;, &apos;秒速5厘米&apos;, &apos;绿里奇迹&apos;, &apos;这个男人来自地球&apos;, &apos;海盗电台&apos;, &apos;勇闯夺命岛&apos;,       &apos;城市之光&apos;, &apos;初恋这件小事&apos;, &apos;无耻混蛋&apos;, &apos;卡萨布兰卡&apos;, &apos;变脸&apos;, &apos;E.T. 外星人&apos;, &apos;爱在午夜降临前&apos;,       &apos;发条橙&apos;, &apos;步履不停&apos;, &apos;黄金三镖客&apos;, &apos;无敌破坏王&apos;, &apos;疯狂的石头&apos;, &apos;美国丽人&apos;, &apos;荒野生存&apos;, &apos;迁徙的鸟&apos;,       &apos;英国病人&apos;, &apos;海街日记&apos;, &apos;彗星来的那一夜&apos;, &apos;国王的演讲&apos;, &apos;非常嫌疑犯&apos;, &apos;血钻&apos;, &apos;燕尾蝶&apos;, &apos;聚焦&apos;,       &apos;勇士&apos;, &apos;叫我第一名&apos;, &apos;穆赫兰道&apos;, &apos;遗愿清单&apos;, &apos;枪火&apos;, &apos;上帝也疯狂&apos;, &apos;我爱你&apos;, &apos;黑鹰坠落&apos;, &apos;荒岛余生&apos;,       &apos;大卫·戈尔的一生&apos;, &apos;千钧一发&apos;, &apos;蓝色大门&apos;, &apos;2001太空漫游&apos;], dtype=object)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  数据格式的初步清洗</span></span><br><span class="line">df[<span class="string">'genre'</span>]=df[<span class="string">'genre'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"language"</span>]= df[<span class="string">'language'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"director"</span>]= df[<span class="string">'director'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"cast"</span>]= df[<span class="string">'cast'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line">df[<span class="string">"movie_duration"</span>]= df[<span class="string">'movie_duration'</span>].str[<span class="number">2</span>:<span class="number">-2</span>]</span><br><span class="line"><span class="comment"># df[["genre","language","director","cast","movie_duration"]]=df[["genre","language","director","cast","movie_duration"]].apply(lambda x: x.replace("['","").replace("']",""))</span></span><br></pre></td></tr></table></figure><ul><li>上映地区数据清理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 地区的数据清理</span></span><br><span class="line">area_split = df[<span class="string">'area'</span>].str.split(expand=<span class="keyword">True</span>)</span><br><span class="line">area_split.head()</span><br><span class="line">all_area = area_split.apply(pd.value_counts).fillna(<span class="number">0</span>)</span><br><span class="line">all_area.columns = [<span class="string">'area_1'</span>,<span class="string">'area_2'</span>,<span class="string">'area_3'</span>,<span class="string">'area_4'</span>,<span class="string">'area_5'</span>]</span><br><span class="line">all_area = all_area.astype(<span class="string">"int"</span>)</span><br><span class="line">all_area.dtypes</span><br></pre></td></tr></table></figure><pre><code>area_1    int32area_2    int32area_3    int32area_4    int32area_5    int32dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_area.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bioo61dj20gs07xwep.jpg" alt=""></p><ul><li>上映地区数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_area[<span class="string">'Col_sum'</span>] = all_area.apply(<span class="keyword">lambda</span> x: x.sum(), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_area.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bjtbssxj20k4080q38.jpg" alt=""></p><ul><li>电影类型数据清理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories = df[<span class="string">'genre'</span>].str.split(<span class="string">" "</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">categories = categories.apply(pd.value_counts).fillna(<span class="number">0</span>).astype(<span class="string">"int"</span>)</span><br><span class="line">categories.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2blloch5j20ak08ljrk.jpg" alt=""></p><ul><li>电影类型数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories[<span class="string">'count'</span>]= categories.apply(<span class="keyword">lambda</span> x:x.sum(),axis=<span class="number">1</span>)</span><br><span class="line">categories.sort_values(<span class="string">'count'</span>,ascending=<span class="keyword">False</span>)</span><br><span class="line">categories.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bm9sltij20cd07wglu.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于language处理</span></span><br><span class="line">df[<span class="string">'language'</span>].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><pre><code>0                         英语1                      汉语普通话2           英语&apos;, &apos;意大利语&apos;, &apos;法语3                         英语4           意大利语&apos;, &apos;德语&apos;, &apos;英语5     英语&apos;, &apos;意大利语&apos;, &apos;德语&apos;, &apos;俄语6                         日语7    英语&apos;, &apos;希伯来语&apos;, &apos;德语&apos;, &apos;波兰语8             英语&apos;, &apos;日语&apos;, &apos;法语9                         英语Name: language, dtype: object</code></pre><ul><li>电影语言的清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">language_all = df[<span class="string">'language'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">" "</span>).str.split(<span class="string">" "</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">language_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bn4unt0j20nh087wey.jpg" alt=""></p><ul><li>电影语言的数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">language_all = language_all.apply(pd.value_counts).fillna(<span class="number">0</span>).astype(<span class="string">"int"</span>)</span><br><span class="line">language_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bnhy7huj20ep07waaa.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">language_all[<span class="string">'count'</span>]= language_all.apply(<span class="keyword">lambda</span> x:x.sum(),axis=<span class="number">1</span>)</span><br><span class="line">language_all.sort_values(<span class="string">'count'</span>,ascending=<span class="keyword">False</span>)</span><br><span class="line">language_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bo69lnoj20hh086mxg.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.director.head()</span><br></pre></td></tr></table></figure><pre><code>0    弗兰克·德拉邦特 Frank Darabont1             陈凯歌 Kaige Chen2           吕克·贝松 Luc Besson3            Robert Zemeckis4    罗伯托·贝尼尼 Roberto BenigniName: director, dtype: object</code></pre><ul><li>导演的数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">director_all = df[<span class="string">'director'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">"~"</span>).str.split(<span class="string">"~"</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">director_all.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2cz4eekyj20ey08274r.jpg" alt=""></p><ul><li>电影演员的数据清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  演员</span></span><br><span class="line">df[<span class="string">'cast'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    蒂姆·罗宾斯 Tim Robbins&apos;, &apos;摩根·弗里曼 Morgan Freeman&apos;, ...1    张国荣 Leslie Cheung&apos;, &apos;张丰毅 Fengyi Zhang&apos;, &apos;巩俐 Li...2    让·雷诺 Jean Reno&apos;, &apos;娜塔莉·波特曼 Natalie Portman&apos;, &apos;加...3    Tom Hanks&apos;, &apos;Robin Wright Penn&apos;, &apos;Gary Sinise&apos;...4    罗伯托·贝尼尼 Roberto Benigni&apos;, &apos;尼可莱塔·布拉斯基 Nicoletta...Name: cast, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cast_all = df[<span class="string">'cast'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">"~"</span>).str.split(<span class="string">"~"</span>,expand=<span class="keyword">True</span>)</span><br><span class="line">cast_all.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bp8s3wtj215g08fmyy.jpg" alt=""></p><ul><li>电影演员的数据整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">main_dr= list(director_all[<span class="number">0</span>])</span><br><span class="line">second_dr= list(director_all[<span class="number">1</span>])</span><br><span class="line">thrid_dr= list(director_all[<span class="number">2</span>])</span><br><span class="line">directors=pd.Series(main_dr+second_dr+thrid_dr)</span><br><span class="line">directors.value_counts().head()</span><br></pre></td></tr></table></figure><pre><code>宫崎骏 Hayao Miyazaki            7克里斯托弗·诺兰 Christopher Nolan    7王家卫 Kar Wai Wong              5史蒂文·斯皮尔伯格 Steven Spielberg    5大卫·芬奇 David Fincher           4dtype: int64</code></pre><ul><li>电影发行年份清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'init_year'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    19941    19932    19943    19944    1997Name: init_year, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">year_= df[<span class="string">'init_year'</span>].str.split(<span class="string">'/'</span>).apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>].strip()).replace(regex=&#123;<span class="string">'\(中国大陆\)'</span>:<span class="string">''</span>&#125;)</span><br><span class="line">year_split = pd.to_datetime(year_).dt.year</span><br><span class="line">year_split.head()</span><br></pre></td></tr></table></figure><pre><code>0    19941    19932    19943    19944    1997Name: init_year, dtype: int64</code></pre><ul><li>电影观影时长的清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'movie_duration'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0                       142分钟1                      171 分钟2    110分钟(剧场版)&apos;, &apos;133分钟(国际版)3                      142 分钟4         116分钟&apos;, &apos;125分钟(加长版)Name: movie_duration, dtype: object</code></pre><ul><li>电影观影时长的整理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 观影时长，多次上映取的第一个时长</span></span><br><span class="line">movie_duration_split = df[<span class="string">'movie_duration'</span>].str.replace(<span class="string">"\', \'"</span>,<span class="string">"~"</span>).str.split(<span class="string">"~"</span>,expand=<span class="keyword">True</span>).fillna(<span class="number">0</span>)</span><br><span class="line">movie_duration_split =movie_duration_split.replace(regex=&#123;<span class="string">'分钟.*'</span>: <span class="string">''</span>&#125;)</span><br><span class="line">df[<span class="string">'movie_duration'</span>]=movie_duration_split[<span class="number">0</span>].astype(<span class="string">"int"</span>)</span><br><span class="line">df[<span class="string">'movie_duration'</span>].head()</span><br></pre></td></tr></table></figure><pre><code>0    1421    1712    1103    1424    116Name: movie_duration, dtype: int32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标签 tags</span></span><br><span class="line"><span class="comment"># 查看第一部电影的的tag</span></span><br><span class="line"><span class="comment"># pd.DataFrame(eval(df['tags'][0]))</span></span><br><span class="line">df[<span class="string">'tags'</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>&quot;[{&apos;count&apos;: 220591, &apos;name&apos;: &apos;经典&apos;}, {&apos;count&apos;: 191014, &apos;name&apos;: &apos;励志&apos;}, {&apos;count&apos;: 173587, &apos;name&apos;: &apos;信念&apos;}, {&apos;count&apos;: 159939, &apos;name&apos;: &apos;自由&apos;}, {&apos;count&apos;: 115024, &apos;name&apos;: &apos;人性&apos;}, {&apos;count&apos;: 111430, &apos;name&apos;: &apos;美国&apos;}, {&apos;count&apos;: 93721, &apos;name&apos;: &apos;人生&apos;}, {&apos;count&apos;: 72602, &apos;name&apos;: &apos;剧情&apos;}]&quot;</code></pre><ul><li>电影标签的清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_tags = [ pd.DataFrame(eval(i)) <span class="keyword">for</span> i <span class="keyword">in</span> df[<span class="string">"tags"</span>]]</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">all_tags=[list(itertools.chain.from_iterable(zip(df_[<span class="string">'name'</span>],df_[<span class="string">'count'</span>]))) <span class="keyword">for</span> df_ <span class="keyword">in</span> all_tags]</span><br><span class="line">all_tags_df=pd.DataFrame(all_tags)</span><br><span class="line">all_tags_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bqdhgjfj213p07wdhi.jpg" alt=""></p><h4 id="数据可视化部分"><a href="#数据可视化部分" class="headerlink" title="数据可视化部分"></a>数据可视化部分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据分析与可视化部分 matplotlib 与 pyecharts</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">"font.family"</span>]=[<span class="string">"simsunb"</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">'font.size'</span>] =<span class="number">15</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line">plt.style.use(<span class="string">'seaborn-whitegrid'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(df[<span class="string">'rating_num'</span>],df[<span class="string">'num'</span>])</span><br><span class="line">plt.xlabel(<span class="string">"reating_num"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"ranking"</span>)</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.hist(df[<span class="string">'rating_num'</span>],bins=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">"rating_num"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2brdjbpqj20vy0dhwgd.jpg" alt="影评人数"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line">plt.style.use(<span class="string">'seaborn-whitegrid'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(df[<span class="string">'movie_duration'</span>],df[<span class="string">'num'</span>])</span><br><span class="line">plt.xlabel(<span class="string">"movie_duration"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"ranking"</span>)</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.hist(df[<span class="string">'movie_duration'</span>],bins=<span class="number">15</span>)</span><br><span class="line">plt.xlabel(<span class="string">"movie_duration"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bs32a65j20vx0dkjts.jpg" alt="观影时长"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 观影时长与 电影排名之间的相关性，从常识来判断，基本没有啥关系，因为好的电影不一定时间长，时间长的不一定是好电影</span></span><br><span class="line">df[<span class="string">'num'</span>].corr(df[<span class="string">'movie_duration'</span>])</span><br></pre></td></tr></table></figure><pre><code>-0.19979596696001942</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'init_year'</span>]=year_split</span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line">plt.style.use(<span class="string">'seaborn-whitegrid'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(df[<span class="string">'init_year'</span>],df[<span class="string">'num'</span>])</span><br><span class="line">plt.xlabel(<span class="string">"init_year"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"ranking"</span>)</span><br><span class="line">plt.gca().invert_yaxis()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.hist(df[<span class="string">'init_year'</span>],bins=<span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">"init_year"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bsnsesdj20vm0dimzk.jpg" alt="发行年份"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'num'</span>].corr(df[<span class="string">'init_year'</span>])  </span><br><span class="line"><span class="comment"># 从结果来看，更没有什么相关性</span></span><br></pre></td></tr></table></figure><pre><code>0.041157240822869007</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import matplotlib.font_manager as fm</span></span><br><span class="line"><span class="comment"># fpath = 'C:\\Windows\\Fonts\\simsunb.ttf'</span></span><br><span class="line"><span class="comment"># prop=fm.FontProperties(fname=fpath)</span></span><br><span class="line"><span class="comment"># print(prop)</span></span><br><span class="line">matplotlib.rcParams[<span class="string">"font.family"</span>]=[<span class="string">"SimHei"</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">24</span>,<span class="number">6</span>))</span><br><span class="line">all_area_new = all_area[<span class="string">'Col_sum'</span>].sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">plt.bar(list(all_area_new.index),list(all_area_new))</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)  <span class="comment">#坐标轴刻度倾斜45°</span></span><br><span class="line">plt.legend(labels=[<span class="string">"count"</span>],loc=<span class="string">'upper center'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bt24rgpj20zc0aiwfj.jpg" alt="地域"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">language_all[<span class="string">'count'</span>].sort_values(ascending=<span class="keyword">False</span>).head()</span><br></pre></td></tr></table></figure><pre><code>英语       170法语        40日语        40汉语普通话     34德语        24Name: count, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">language_all[<span class="string">'count'</span>].sort_values(ascending=<span class="keyword">False</span>).plot(kind=<span class="string">'bar'</span>,figsize=(<span class="number">22</span>,<span class="number">6</span>))</span><br><span class="line">plt.legend(labels=[<span class="string">"language_count"</span>],loc=<span class="string">'upper center'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2buk6ozqj20z50c1di1.jpg" alt="语言"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories[<span class="string">"count"</span>].sort_values(ascending=<span class="keyword">False</span>).plot(kind=<span class="string">'bar'</span>,figsize=(<span class="number">22</span>,<span class="number">6</span>))</span><br><span class="line">plt.legend(labels=[<span class="string">"category_count"</span>],loc=<span class="string">'upper center'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2buzrrafj20z50awmy2.jpg" alt="类型"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_tag_name = all_tags_df.loc[:,[<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">10</span>,<span class="number">12</span>,<span class="number">14</span>]].values.flatten()</span><br><span class="line">all_tag_name = pd.Series(all_tag_name).value_counts()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> WordCloud</span><br><span class="line">wordcloud = WordCloud(width=<span class="number">1000</span>,height=<span class="number">600</span>)</span><br><span class="line">wordcloud.add(<span class="string">""</span>,list(all_tag_name.index),list(all_tag_name.values),word_size_range=[<span class="number">20</span>,<span class="number">100</span>])</span><br><span class="line">wordcloud</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bxo1kl8j20tq0i2tib.jpg" alt="pyeacharts"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line">font = <span class="string">r'C:\Windows\Fonts\simfang.ttf'</span></span><br><span class="line">wordcloud = WordCloud(font_path=font,max_font_size = <span class="number">35</span>).generate(str(list(all_tag_name.index)))</span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line">plt.imshow(wordcloud)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bz2yq4oj20hj08qteq.jpg" alt="wordcloud"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Bar</span><br><span class="line">mybar= Bar(<span class="string">"电影类型分析"</span>)</span><br><span class="line">cate=categories[<span class="string">'count'</span>].sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">mybar.add(<span class="string">"电影类型"</span>,cate.index,cate.values,mark_line=[<span class="string">'max'</span>],mark_point=[<span class="string">'average'</span>])</span><br><span class="line">mybar</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2bzw7b0hj20rv0dgjry.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span>  Pie</span><br><span class="line">Top30_rating_num=df[[<span class="string">'rating_num'</span>,<span class="string">'title'</span>]].sort_values([<span class="string">'rating_num'</span>],ascending=<span class="keyword">False</span>).head(<span class="number">30</span>)[<span class="string">'rating_num'</span>].value_counts()</span><br><span class="line">Top30_rating_num</span><br><span class="line">pie = Pie(<span class="string">'排名前30电影评分占比'</span>,title_pos = <span class="string">'center'</span>)</span><br><span class="line">pie.add(<span class="string">''</span>,list(Top30_rating_num.index),Top30_rating_num.values,is_label_show = <span class="keyword">True</span>,legend_orient = <span class="string">'vertical'</span>,legend_pos = <span class="string">'right'</span>)</span><br><span class="line">pie</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fu2c120o8uj20sh0d6wfc.jpg" alt=""></p>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>pandas data processing</title>
      <link href="/2018/08/02/data-processing-pandas/"/>
      <url>/2018/08/02/data-processing-pandas/</url>
      <content type="html"><![CDATA[<h3 id="category-type-data-in-pandas"><a href="#category-type-data-in-pandas" class="headerlink" title="category type data in pandas"></a>category type data in pandas</h3><ul><li>实际应用pandas过程中，经常会用到category数据类型，通常以text的形式显示，包括颜色（红，绿，蓝），尺寸的大小（大，中，小），还有地理信息等（国家，省份），这些数据的处理经常会有各种各样的问题，pandas以及scikit-learn两个包可以将category数据转化为合适的数值型格式，这篇主要介绍通过这两个包处理category类型的数据转化为数值类型，也就是encoding的过程。</li><li>数据来源<a href="http://mlr.cs.umass.edu/ml/index.html" target="_blank" rel="noopener">UCI Machine Learning Repository</a>，这个数据集中包含了很多的category类型的数据，可以从链接汇总查看数据的代表的含义。</li><li>下面开始导入需要用到的包</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 规定一下数据列的各个名称，</span></span><br><span class="line">headers = [<span class="string">"symboling"</span>, <span class="string">"normalized_losses"</span>, <span class="string">"make"</span>, <span class="string">"fuel_type"</span>, <span class="string">"aspiration"</span>,</span><br><span class="line">           <span class="string">"num_doors"</span>, <span class="string">"body_style"</span>, <span class="string">"drive_wheels"</span>, <span class="string">"engine_location"</span>,</span><br><span class="line">           <span class="string">"wheel_base"</span>, <span class="string">"length"</span>, <span class="string">"width"</span>, <span class="string">"height"</span>, <span class="string">"curb_weight"</span>,</span><br><span class="line">           <span class="string">"engine_type"</span>, <span class="string">"num_cylinders"</span>, <span class="string">"engine_size"</span>, <span class="string">"fuel_system"</span>,</span><br><span class="line">           <span class="string">"bore"</span>, <span class="string">"stroke"</span>, <span class="string">"compression_ratio"</span>, <span class="string">"horsepower"</span>, <span class="string">"peak_rpm"</span>,</span><br><span class="line">           <span class="string">"city_mpg"</span>, <span class="string">"highway_mpg"</span>, <span class="string">"price"</span>]</span><br><span class="line"><span class="comment"># 从pandas导入csv文件，将?标记为NaN缺失值</span></span><br><span class="line">df=pd.read_csv(<span class="string">"http://mlr.cs.umass.edu/ml/machine-learning-databases/autos/imports-85.data"</span>,header=<span class="keyword">None</span>,names=headers,na_values=<span class="string">"?"</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf3plqefj215n0ci75u.jpg" alt=""></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>symboling              int64normalized_losses    float64make                  objectfuel_type             objectaspiration            objectnum_doors             objectbody_style            objectdrive_wheels          objectengine_location       objectwheel_base           float64length               float64width                float64height               float64curb_weight            int64engine_type           objectnum_cylinders         objectengine_size            int64fuel_system           objectbore                 float64stroke               float64compression_ratio    float64horsepower           float64peak_rpm             float64city_mpg               int64highway_mpg            int64price                float64dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果只关注category 类型的数据，其实根本没有必要拿到这些全部数据，只需要将object类型的数据取出，然后进行后续分析即可</span></span><br><span class="line">obj_df = df.select_dtypes(include=[<span class="string">'object'</span>]).copy()</span><br><span class="line">obj_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf4zyk7fj215q0aomyh.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  在进行下一步处理的之前，需要将数据进行缺失值的处理，对列进行处理axis=1</span></span><br><span class="line">obj_df[obj_df.isnull().any(axis=<span class="number">1</span>)]</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf5ra63gj215k04emxn.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理缺失值的方式有很多种，根据项目的不同或者填补缺失值或者去掉该样本。本文中的数据缺失用该列的众数来补充。</span></span><br><span class="line">obj_df.num_doors.value_counts()</span><br></pre></td></tr></table></figure><pre><code>four    114two      89Name: num_doors, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj_df=obj_df.fillna(&#123;<span class="string">"num_doors"</span>:<span class="string">"four"</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="在处理完缺失值之后，有以下几种方式进行category数据转化encoding"><a href="#在处理完缺失值之后，有以下几种方式进行category数据转化encoding" class="headerlink" title="在处理完缺失值之后，有以下几种方式进行category数据转化encoding"></a>在处理完缺失值之后，有以下几种方式进行category数据转化encoding</h3><ul><li>Find and Replace</li><li>label encoding</li><li>One Hot encoding </li><li>Custom Binary encoding</li><li>sklearn</li><li>advanced Approaches</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  pandas里面的replace文档非常丰富，笔者在使用该功能时候，深感其参数众多，深感提供的功能也非常的强大</span></span><br><span class="line"><span class="comment"># 本文中使用replace的功能，创建map的字典，针对需要数据清理的列进行清理更加方便，例如：</span></span><br><span class="line">cleanup_nums= &#123;</span><br><span class="line">    <span class="string">"num_doors"</span>:&#123;<span class="string">"four"</span>:<span class="number">4</span>,<span class="string">"two"</span>:<span class="number">2</span>&#125;,</span><br><span class="line">    <span class="string">"num_cylinders"</span>:&#123;</span><br><span class="line">        <span class="string">"four"</span>:<span class="number">4</span>,<span class="string">"six"</span>:<span class="number">6</span>,<span class="string">"five"</span>:<span class="number">5</span>,<span class="string">"eight"</span>:<span class="number">8</span>,<span class="string">"two"</span>:<span class="number">2</span>,<span class="string">"twelve"</span>:<span class="number">12</span>,<span class="string">"three"</span>:<span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">obj_df.replace(cleanup_nums,inplace=<span class="keyword">True</span>)</span><br><span class="line">obj_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf702rzrj215k0anabc.jpg" alt=""></p><h4 id="label-encoding-是将一组无规则的，没有大小比较的数据转化为数字"><a href="#label-encoding-是将一组无规则的，没有大小比较的数据转化为数字" class="headerlink" title="label encoding 是将一组无规则的，没有大小比较的数据转化为数字"></a>label encoding 是将一组无规则的，没有大小比较的数据转化为数字</h4><ul><li>比如body_style 字段中含有多个数据值，可以使用该方法将其转化</li><li>convertible &gt; 0</li><li>hardtop  &gt; 1</li><li>hatchback  &gt; 2</li><li>sedan &gt; 3</li><li>wagon &gt; 4</li></ul><h4 id="这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样"><a href="#这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样" class="headerlink" title="这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样"></a>这种方式就像是密码编码一样，这，个比喻很有意思，就像之前看电影，记得一句台词，他们俩亲密的像做贼一样</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过pandas里面的 category数据类型，可以很方便的或者该编码</span></span><br><span class="line">obj_df[<span class="string">"body_style"</span>]=obj_df[<span class="string">"body_style"</span>].astype(<span class="string">"category"</span>)</span><br><span class="line">obj_df.dtypes</span><br></pre></td></tr></table></figure><pre><code>make                 objectfuel_type            objectaspiration           objectnum_doors             int64body_style         categorydrive_wheels         objectengine_location      objectengine_type          objectnum_cylinders         int64fuel_system          objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们可以通过赋值新的列，保存其对应的code</span></span><br><span class="line"><span class="comment"># 通过这种方法可以舒服的数据，便于以后的数据分析以及整理</span></span><br><span class="line">obj_df[<span class="string">"body_style_code"</span>] = obj_df[<span class="string">"body_style"</span>].cat.codes</span><br><span class="line">obj_df.head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvfh4tpzuj213p0au3zi.jpg" alt=""></p><h4 id="one-hot-encoding"><a href="#one-hot-encoding" class="headerlink" title="one hot encoding"></a>one hot encoding</h4><ul><li>label encoding 因为将wagon转化为4，而convertible变成了0，这里面是不是会有大大小的比较，可能会造成误解，然后利用one hot encoding这种方式<br>是将特征转化为0或者1，这样会增加数据的列的数量，同时也减少了label encoding造成的衡量数据大小的误解。</li><li>pandas中提供了get_dummies 方法可以将需要转化的列的值转化为0,1,两种编码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新生成DataFrame包含了新生成的三列数据,</span></span><br><span class="line"><span class="comment"># drive_wheels_4wd </span></span><br><span class="line"><span class="comment"># drive_wheels_fwd</span></span><br><span class="line"><span class="comment"># drive_wheels_rwd</span></span><br><span class="line">pd.get_dummies(obj_df,columns=[<span class="string">"drive_wheels"</span>]).head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvf9zuskxj20z90axq3j.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法之所以强大，是因为可以同时处理多个category的列，同时选择prefix前缀分别对应好</span></span><br><span class="line"><span class="comment"># 产生的新的DataFrame所有数据都包含</span></span><br><span class="line">pd.get_dummies(obj_df, columns=[<span class="string">"body_style"</span>, <span class="string">"drive_wheels"</span>], prefix=[<span class="string">"body"</span>, <span class="string">"drive"</span>]).head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvfbg1lg1j210n0aymxn.jpg" alt=""></p><h4 id="自定义0-1-encoding"><a href="#自定义0-1-encoding" class="headerlink" title="自定义0,1 encoding"></a>自定义0,1 encoding</h4><ul><li>有的时候回根据业务需要，可能会结合label encoding以及not hot 两种方式进行二值化。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj_df[<span class="string">"engine_type"</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>ohc      148ohcf      15ohcv      13dohc      12l         12rotor      4dohcv      1Name: engine_type, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有的时候为了区分出 engine_type是否是och技术的，可以使用二值化，将该列进行处理</span></span><br><span class="line"><span class="comment"># 这也突出了领域知识是如何以最有效的方式解决问题</span></span><br><span class="line">obj_df[<span class="string">"engine_type_code"</span>] = np.where(obj_df[<span class="string">"engine_type"</span>].str.contains(<span class="string">"ohc"</span>),<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">obj_df[[<span class="string">"make"</span>,<span class="string">"engine_type"</span>,<span class="string">"engine_type_code"</span>]].head()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1ftvfe3f1ybj20ky07w74l.jpg" alt=""></p><h3 id="scikit-learn中的数据转化"><a href="#scikit-learn中的数据转化" class="headerlink" title="scikit-learn中的数据转化"></a>scikit-learn中的数据转化</h3><ul><li>sklearn.processing模块提供了很多方便的数据转化以及缺失值处理方式。可以直接从该模块导入</li><li>Imputer</li><li>LabelEncoder，</li><li>LabelBinarizer，0,1归一化(最大最小标准化)，</li><li>Normalizer正则化（L1，L2）一般用的不多，</li><li>StandardScale 标准化</li><li>max_mixScale（最大最小标准化max_mix），</li><li>非线性转换包括，生成多项式特征(PolynomialFeatures),将每个特征缩放在同样的范围或分布情况下</li><li><a href="http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" target="_blank" rel="noopener">sklearn processing 模块官网文档链接</a></li><li><a href="http://contrib.scikit-learn.org/categorical-encoding/" target="_blank" rel="noopener">category_encoders包官方文档</a></li></ul><h4 id="至此，数据预处理以及category转化大致讲完了。"><a href="#至此，数据预处理以及category转化大致讲完了。" class="headerlink" title="至此，数据预处理以及category转化大致讲完了。"></a>至此，数据预处理以及category转化大致讲完了。</h4>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数据类型转化</title>
      <link href="/2018/08/02/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96/"/>
      <url>/2018/08/02/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96/</url>
      <content type="html"><![CDATA[<h3 id="数据处理过程的数据类型"><a href="#数据处理过程的数据类型" class="headerlink" title="数据处理过程的数据类型"></a>数据处理过程的数据类型</h3><ul><li>当利用pandas进行数据处理的时候，经常会遇到数据类型的问题，当拿到数据的时候，首先需要确定拿到的是正确类型的数据，一般通过数据类型的转化，这篇文章就介绍pandas里面的数据类型（data types也就是常用的dtyps），以及pandas与numpy之间的数据对应关系。</li><li><img src="http://ww1.sinaimg.cn/large/9ebd4c2bgy1fto9860xy9j20sl0bfgrk.jpg" alt=""></li><li>主要介绍object，int64，float64，datetime64，bool等几种类型，category与timedelta两种类型会单独的在其他文章中进行介绍。当然本文中也会涉及简单的介绍。</li></ul><h4 id="数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter-notebook进行一个数据类型的介绍。"><a href="#数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter-notebook进行一个数据类型的介绍。" class="headerlink" title="数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter notebook进行一个数据类型的介绍。"></a>数据类型的问题一般都是出了问题之后才会发现的，所以有了一些经验之后就会拿到数据之后，就直接看数据类型，是否与自己想要处理的数据格式一致，这样可以从一开始避免一些尴尬的问题出现。那么我们以一个简单的例子，利用jupyter notebook进行一个数据类型的介绍。</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####按照惯例导入两个常用的数据处理的包，numpy与pandas</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 从csv文件读取数据，数据表格中只有5行，里面包含了float，string，int三种数据python类型，也就是分别对应的pandas的float64，object，int64</span></span><br><span class="line"><span class="comment"># csv文件中共有六列，第一列是表头，其余是数据。</span></span><br><span class="line">df = pd.read_csv(<span class="string">"sales_data_types.csv"</span>)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftunyo12lpj20uu0cp3zy.jpg" alt=""></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>Customer Number    float64Customer Name       object2016                object2017                objectPercent Growth      objectJan Units           objectMonth                int64Day                  int64Year                 int64Active              objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假如想得到2016年与2017年的数据总和，可以尝试,但并不是我们需要的答案，因为这两列中的数据类型是object，执行该操作之后，得到是一个更加长的字符串，</span></span><br><span class="line"><span class="comment"># 当然我们可以通过df.info() 来获得关于数据框的更多的详细信息，</span></span><br><span class="line">df[<span class="string">'2016'</span>]+df[<span class="string">'2017'</span>]</span><br></pre></td></tr></table></figure><pre><code>0      $125,000.00 $162,500.00 1    $920,000.00 $1,012,000.00 2        $50,000.00 $62,500.00 3      $350,000.00 $490,000.00 4        $15,000.00 $12,750.00 dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br><span class="line"><span class="comment"># Customer Number 列是float64，然而应该是int64</span></span><br><span class="line"><span class="comment"># 2016 2017两列的数据是object，并不是float64或者int64格式</span></span><br><span class="line"><span class="comment"># Percent以及Jan Units 也是objects而不是数字格式</span></span><br><span class="line"><span class="comment"># Month，Day以及Year应该转化为datetime64[ns]格式</span></span><br><span class="line"><span class="comment"># Active 列应该是布尔值</span></span><br><span class="line"><span class="comment"># 如果不做数据清洗，很难进行下一步的数据分析，为了进行数据格式的转化，pandas里面有三种比较常用的方法</span></span><br><span class="line"><span class="comment"># 1. astype()强制转化数据类型</span></span><br><span class="line"><span class="comment"># 2. 通过创建常用的函数进行数据转化</span></span><br><span class="line"><span class="comment"># 3. pandas提供的to_nueric()以及to_datetime()</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;RangeIndex: 5 entries, 0 to 4Data columns (total 10 columns):Customer Number    5 non-null float64Customer Name      5 non-null object2016               5 non-null object2017               5 non-null objectPercent Growth     5 non-null objectJan Units          5 non-null objectMonth              5 non-null int64Day                5 non-null int64Year               5 non-null int64Active             5 non-null objectdtypes: float64(1), int64(3), object(6)memory usage: 480.0+ bytes</code></pre><h3 id="首先介绍最常用的astype"><a href="#首先介绍最常用的astype" class="headerlink" title="首先介绍最常用的astype()"></a>首先介绍最常用的astype()</h3><h4 id="比如可以通过astype-将第一列的数据转化为整数int类型"><a href="#比如可以通过astype-将第一列的数据转化为整数int类型" class="headerlink" title="比如可以通过astype()将第一列的数据转化为整数int类型"></a>比如可以通过astype()将第一列的数据转化为整数int类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'Customer Number'</span>].astype(<span class="string">"int"</span>)</span><br><span class="line"><span class="comment">#  这样的操作并没有改变原始的数据框，而只是返回的一个拷贝</span></span><br></pre></td></tr></table></figure><pre><code>0     100021    5522782     234773     249004    651029Name: Customer Number, dtype: int32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 想要真正的改变数据框，通常需要通过赋值来进行，比如</span></span><br><span class="line">df[<span class="string">"Customer Number"</span>] = df[<span class="string">"Customer Number"</span>].astype(<span class="string">"int"</span>)</span><br><span class="line">print(<span class="string">"--------"</span>*<span class="number">10</span>)</span><br><span class="line">print(df.dtypes)</span><br></pre></td></tr></table></figure><pre><code>   Customer Number     Customer Name          2016            2017  \0            10002  Quest Industries  $125,000.00     $162,500.00    1           552278    Smith Plumbing  $920,000.00   $1,012,000.00    2            23477   ACME Industrial   $50,000.00      $62,500.00    3            24900        Brekke LTD  $350,000.00     $490,000.00    4           651029         Harbor Co   $15,000.00      $12,750.00      Percent Growth Jan Units  Month  Day  Year Active  0         30.00%       500      1   10  2015      Y  1         10.00%       700      6   15  2014      Y  2         25.00%       125      3   29  2016      Y  3          4.00%        75     10   27  2015      Y  4        -15.00%    Closed      2    2  2014      N  --------------------------------------------------------------------------------Customer Number     int32Customer Name      object2016               object2017               objectPercent Growth     objectJan Units          objectMonth               int64Day                 int64Year                int64Active             objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过赋值在原始的数据框基础上进行了数据转化，可以重新看一下我们新生成的数据框</span></span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftunzqcjudj20us0c9gn5.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后像2016,2017 Percent Growth，Jan Units 这几列带有特殊符号的object是不能直接通过astype("flaot)方法进行转化的，</span></span><br><span class="line"><span class="comment"># 这与python中的字符串转化为浮点数，都要求原始的字符都只能含有数字本身，不能含有其他的特殊字符</span></span><br><span class="line"><span class="comment"># 我们可以试着将将Active列转化为布尔值，看一下到底会发生什么,五个结果全是True，说明并没有起到什么作用</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#df["Active"].astype("bool")</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'2016'</span>].astype(<span class="string">'float'</span>)</span><br></pre></td></tr></table></figure><pre><code>---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)&lt;ipython-input-145-47cc9d68cd65&gt; in &lt;module&gt;()----&gt; 1 df[&apos;2016&apos;].astype(&apos;float&apos;)C:\Anaconda3\lib\site-packages\pandas\core\generic.py in astype(self, dtype, copy, raise_on_error, **kwargs)   3052         # else, only a single dtype is given   3053         new_data = self._data.astype(dtype=dtype, copy=copy,-&gt; 3054                                      raise_on_error=raise_on_error, **kwargs)   3055         return self._constructor(new_data).__finalize__(self)   3056 C:\Anaconda3\lib\site-packages\pandas\core\internals.py in astype(self, dtype, **kwargs)   3187    3188     def astype(self, dtype, **kwargs):-&gt; 3189         return self.apply(&apos;astype&apos;, dtype=dtype, **kwargs)   3190    3191     def convert(self, **kwargs):C:\Anaconda3\lib\site-packages\pandas\core\internals.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)   3054    3055             kwargs[&apos;mgr&apos;] = self-&gt; 3056             applied = getattr(b, f)(**kwargs)   3057             result_blocks = _extend_blocks(applied, result_blocks)   3058 C:\Anaconda3\lib\site-packages\pandas\core\internals.py in astype(self, dtype, copy, raise_on_error, values, **kwargs)    459                **kwargs):    460         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,--&gt; 461                             values=values, **kwargs)    462     463     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,C:\Anaconda3\lib\site-packages\pandas\core\internals.py in _astype(self, dtype, copy, raise_on_error, values, klass, mgr, **kwargs)    502     503                 # _astype_nansafe works fine with 1-d only--&gt; 504                 values = _astype_nansafe(values.ravel(), dtype, copy=True)    505                 values = values.reshape(self.shape)    506 C:\Anaconda3\lib\site-packages\pandas\types\cast.py in _astype_nansafe(arr, dtype, copy)    535     536     if copy:--&gt; 537         return arr.astype(dtype)    538     return arr.view(dtype)    539 ValueError: could not convert string to float: &apos;$15,000.00 &apos;</code></pre><h4 id="以上的问题说明了一些问题"><a href="#以上的问题说明了一些问题" class="headerlink" title="以上的问题说明了一些问题"></a>以上的问题说明了一些问题</h4><ul><li>如果数据是纯净的数据，可以转化为数字</li><li>astype基本也就是两种用作，数字转化为单纯字符串，单纯数字的字符串转化为数字，含有其他的非数字的字符串是不能通过astype进行转化的。</li><li>需要引入其他的方法进行转化，也就有了下面的自定义函数方法</li></ul><h3 id="通过自定义函数清理数据"><a href="#通过自定义函数清理数据" class="headerlink" title="通过自定义函数清理数据"></a>通过自定义函数清理数据</h3><ul><li>通过下面的函数可以将货币进行转化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_currency</span><span class="params">(var)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    convert the string number to a float</span></span><br><span class="line"><span class="string">    _ 去除$</span></span><br><span class="line"><span class="string">    - 去除逗号，</span></span><br><span class="line"><span class="string">    - 转化为浮点数类型</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    new_value = var.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)</span><br><span class="line">    <span class="keyword">return</span> float(new_value)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过replace函数将$以及逗号去掉，然后字符串转化为浮点数，让pandas选择pandas认为合适的特定类型，float或者int，该例子中将数据转化为了float64</span></span><br><span class="line"><span class="comment"># 通过pandas中的apply函数将2016列中的数据全部转化</span></span><br><span class="line">df[<span class="string">"2016"</span>].apply(convert_currency)</span><br></pre></td></tr></table></figure><pre><code>0    125000.01    920000.02     50000.03    350000.04     15000.0Name: 2016, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当然可以通过lambda 函数将这个比较简单的函数一行带过</span></span><br><span class="line">df[<span class="string">"2016"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)).astype(<span class="string">"float64"</span>)</span><br></pre></td></tr></table></figure><pre><code>0    125000.01    920000.02     50000.03    350000.04     15000.0Name: 2016, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#同样可以利用lambda表达式将PercentGrowth进行数据清理</span></span><br><span class="line">df[<span class="string">"Percent Growth"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">"%"</span>,<span class="string">""</span>)).astype(<span class="string">"float"</span>)/<span class="number">100</span></span><br></pre></td></tr></table></figure><pre><code>0    0.301    0.102    0.253    0.044   -0.15Name: Percent Growth, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同样可以通过自定义函数进行解决，结果同上</span></span><br><span class="line"><span class="comment"># 最后一个自定义函数是利用np.where() function 将Active 列转化为布尔值。</span></span><br><span class="line">df[<span class="string">"Active"</span>] = np.where(df[<span class="string">"Active"</span>] == <span class="string">"Y"</span>, <span class="keyword">True</span>, <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">"Active"</span>]</span><br></pre></td></tr></table></figure><pre><code>0     True1     True2     True3     True4    FalseName: Active, dtype: bool</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时可查看一下数据格式</span></span><br><span class="line">df[<span class="string">"2016"</span>]=df[<span class="string">"2016"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)).astype(<span class="string">"float64"</span>)</span><br><span class="line">df[<span class="string">"2017"</span>]=df[<span class="string">"2017"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">","</span>,<span class="string">""</span>).replace(<span class="string">"$"</span>,<span class="string">""</span>)).astype(<span class="string">"float64"</span>)</span><br><span class="line">df[<span class="string">"Percent Growth"</span>]=df[<span class="string">"Percent Growth"</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">"%"</span>,<span class="string">""</span>)).astype(<span class="string">"float"</span>)/<span class="number">100</span></span><br><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>Customer Number      int32Customer Name       object2016               float642017               float64Percent Growth     float64Jan Units           objectMonth                int64Day                  int64Year                 int64Active                booldtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次查看DataFrame</span></span><br><span class="line"><span class="comment"># 此时只有Jan Units中格式需要转化，以及年月日的合并，可以利用pandas中自带的几个函数进行处理</span></span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftuo1ogfioj20vd0bw3zt.jpg" alt=""></p><h3 id="利用pandas中函数进行处理"><a href="#利用pandas中函数进行处理" class="headerlink" title="利用pandas中函数进行处理"></a>利用pandas中函数进行处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pandas中pd.to_numeric()处理Jan Units中的数据</span></span><br><span class="line">pd.to_numeric(df[<span class="string">"Jan Units"</span>],errors=<span class="string">'coerce'</span>).fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>0    500.01    700.02    125.03     75.04      0.0Name: Jan Units, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最后利用pd.to_datatime()将年月日进行合并</span></span><br><span class="line">pd.to_datetime(df[[<span class="string">'Month'</span>, <span class="string">'Day'</span>, <span class="string">'Year'</span>]])</span><br></pre></td></tr></table></figure><pre><code>0   2015-01-101   2014-06-152   2016-03-293   2015-10-274   2014-02-02dtype: datetime64[ns]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 做到这里不要忘记重新赋值，否则原始数据并没有变化</span></span><br><span class="line">df[<span class="string">"Jan Units"</span>] = pd.to_numeric(df[<span class="string">"Jan Units"</span>],errors=<span class="string">'coerce'</span>)</span><br><span class="line">df[<span class="string">"Start_date"</span>] = pd.to_datetime(df[[<span class="string">'Month'</span>, <span class="string">'Day'</span>, <span class="string">'Year'</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftuo34c4tlj214308m75j.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes</span><br></pre></td></tr></table></figure><pre><code>Customer Number             int32Customer Name              object2016                      float642017                      float64Percent Growth            float64Jan Units                 float64Month                       int64Day                         int64Year                        int64Active                       boolStart_date         datetime64[ns]dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将这些转化整合在一起</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_percent</span><span class="params">(val)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Convert the percentage string to an actual floating point percent</span></span><br><span class="line"><span class="string">    - Remove %</span></span><br><span class="line"><span class="string">    - Divide by 100 to make decimal</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    new_val = val.replace(<span class="string">'%'</span>, <span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> float(new_val) / <span class="number">100</span></span><br><span class="line"></span><br><span class="line">df_2 = pd.read_csv(<span class="string">"sales_data_types.csv"</span>,dtype=&#123;<span class="string">"Customer_Number"</span>:<span class="string">"int"</span>&#125;,converters=&#123;</span><br><span class="line">    <span class="string">"2016"</span>:convert_currency,</span><br><span class="line">    <span class="string">"2017"</span>:convert_currency,</span><br><span class="line">    <span class="string">"Percent Growth"</span>:convert_percent,</span><br><span class="line">    <span class="string">"Jan Units"</span>:<span class="keyword">lambda</span> x:pd.to_numeric(x,errors=<span class="string">"coerce"</span>),</span><br><span class="line">    <span class="string">"Active"</span>:<span class="keyword">lambda</span> x: np.where(x==<span class="string">"Y"</span>,<span class="keyword">True</span>,<span class="keyword">False</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_2.dtypes</span><br><span class="line"><span class="comment">#</span></span><br></pre></td></tr></table></figure><pre><code>Customer Number      int64Customer Name       object2016               float642017               float64Percent Growth      objectJan Units          float64Month                int64Day                  int64Year                 int64Active              booldtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_2</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/9ebd4c2bly1ftuosn84wxj20lq04y74n.jpg" alt=""></p><h3 id="至此，pandas里面数据类型目前还有timedelta以及category两个-之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas-0-16-之后添加的，之后还会根据需要进行整理pandas的常用方法。"><a href="#至此，pandas里面数据类型目前还有timedelta以及category两个-之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas-0-16-之后添加的，之后还会根据需要进行整理pandas的常用方法。" class="headerlink" title="至此，pandas里面数据类型目前还有timedelta以及category两个,之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas 0.16 之后添加的，之后还会根据需要进行整理pandas的常用方法。"></a>至此，pandas里面数据类型目前还有timedelta以及category两个,之后会着重介绍category类型，这是类型是参考了R中的category设计的，在pandas 0.16 之后添加的，之后还会根据需要进行整理pandas的常用方法。</h3>]]></content>
      
      <categories>
          
          <category> pandas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data processing </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logistic regression</title>
      <link href="/2018/07/16/logistic-regression/"/>
      <url>/2018/07/16/logistic-regression/</url>
      <content type="html"><![CDATA[<h2 id="第三章-使用sklearn-实现机学习的分类算法"><a href="#第三章-使用sklearn-实现机学习的分类算法" class="headerlink" title="第三章 使用sklearn 实现机学习的分类算法"></a>第三章 使用sklearn 实现机学习的分类算法</h2><h3 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h3><ul><li>分类器的性能与计算能力和预测性能很大程度上取决于用于模型训练的数据</li><li>训练机器学习算法的五个步骤：<ol><li>特征的选择</li><li>确定评价性能的标准</li><li>选择分类器及其优化算法</li><li><em>对模型性能的评估</em></li><li><strong>算法的调优</strong></li></ol></li></ul><a id="more"></a><h3 id="sklearn初步使用"><a href="#sklearn初步使用" class="headerlink" title="sklearn初步使用"></a>sklearn初步使用</h3><ul><li>3.1 sklearn中包括的processing 模块中的标准化类，StandardScaler对特征进行标准化处理<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.processing <span class="keyword">import</span> StandardSacler</span><br><span class="line">sc = StandardScaler() <span class="comment">#实例化</span></span><br><span class="line">sc.fit(X_train)</span><br><span class="line">sc.transform(X_train)</span><br><span class="line"><span class="comment"># - 以上两句可以并写成一句sc.fit_transform(X_trian)</span></span><br><span class="line"><span class="comment"># - 我们使用相同的放缩参数分别对训练和测试数据集以保证他们的值是彼此相当的。**但是在使用fit_transform 只能对训练集使用，而测试机则只使用fit即可。**</span></span><br><span class="line"><span class="comment"># - sklearn中的metrics类中包含了很多的评估参数，其中accuracy_score,</span></span><br><span class="line"><span class="comment"># - 中accuracy_score(y_test,y_pred)，也就是那y_test与预测值相比较，得出正确率</span></span><br><span class="line">y_pred = model.predict(X_test-std)</span><br></pre></td></tr></table></figure></li></ul><h3 id="过拟合现象"><a href="#过拟合现象" class="headerlink" title="过拟合现象"></a>过拟合现象</h3><p>过拟合现象出现有两个原因：</p><ul><li>训练集与测试集特征分布不一致（黑天鹅和白天鹅）</li><li>模型训练的太过复杂，而样本量不足。<br>同时针对两个原因而出现的解决方法:</li><li>收集多样化的样本</li><li>简化模型</li><li>交叉检验<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftbixvvcy7j30tz0alab2.jpg" alt="模型拟合"></li></ul><h3 id="逻辑斯谛回归"><a href="#逻辑斯谛回归" class="headerlink" title="逻辑斯谛回归"></a>逻辑斯谛回归</h3><p>感知机的一个最大缺点是：在样本不是完全线性可分的情况下，它永远不会收敛。<br>分类算中的另一个简单高效的方法：logistics regression（分类模型）</p><ul><li>很多情况下，我们会将逻辑回归的输出映射到二元分类问题的解决方案，需要确保逻辑回归的输出始终落在在0-1之间，此时S型函数的输出值正好满足了这个条件，其中：<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftbjqo8f7rj30ai021gld.jpg" alt=""></li></ul><h3 id="几率比（odd-ratio）"><a href="#几率比（odd-ratio）" class="headerlink" title="几率比（odd ratio）"></a>几率比（odd ratio）</h3><p>特定的事件的发生的几率，用数学公式表示为：$\frac{p}{1-p} $，其中p为正事件的概率，不一定是有利的事件，而是我们将要预测的事件。以一个患者患有某种疾病的概率，我们可以将正事件的类标标记为y=1。<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftbjl34vj9j30in06b74o.jpg" alt="如图"></p><ul><li>也就是样本特征与权重的线性组合，其计算公式：<br>  z = w·x + b</li><li>预测得到的概率可以通过一个量化器（单位阶跃函数）简单的转化为二元输出</li><li>如果y＞0.5 则判断该样本类别为1，如y＜0.5，则判定该样本是其他类别。</li><li>对应上面的展开式，如果z≥0，则判断类别是1，否则是其他。</li><li>阈值也就是0.5</li></ul><h3 id="通过逻辑斯谛回归模型的代价函数获得权重"><a href="#通过逻辑斯谛回归模型的代价函数获得权重" class="headerlink" title="通过逻辑斯谛回归模型的代价函数获得权重"></a>通过逻辑斯谛回归模型的代价函数获得权重</h3><ul><li>判定某个样本属于类别1或者0 的条件概率如下：<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftbko85i86j30ed03dmxk.jpg" alt=""></li><li>逻辑回回归的代价函数是最小二乘损失函数<br><img src="https://s1.ax1x.com/2018/07/16/PQBB5D.png" alt="PQBB5D.png"></li><li>为了推导出逻辑斯蒂回归的代价函数，需要先定义一个极大似然函数L,<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc1tr86pvj30be01pdfn.jpg" alt=""></li><li>用极大似然估计来根据给定的训练集估计出参数w,对上式两边取对数，化简为<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc1ycsz6hj30dg0123yd.jpg" alt=""><br>求极大似然函数的最大值等价于求-l(w)的最小值，即：<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc2jimakjj30e101kwec.jpg" alt=""></li></ul><h3 id="利用梯度下降法求参数"><a href="#利用梯度下降法求参数" class="headerlink" title="利用梯度下降法求参数"></a>利用梯度下降法求参数</h3><ul><li>在开始梯度下降之前，sigmoid function有一个很好的性质，<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftc2zhxk86j307101nt8h.jpg" alt=""><br>梯度的负方向就是代价函数下降最快的方向，借助泰勒展开，可以得到（函数可微，可导）<br><img src="http://wx3.sinaimg.cn/mw690/0060lm7Tly1ftc33bmu45j306q00wa9u.jpg" alt=""><br>其中，f’(x) 和δ为向量，那么这两者的内积就等于<br><img src="http://wx4.sinaimg.cn/mw690/0060lm7Tly1ftc36jdvpzj308g018mwy.jpg" alt=""><br>当θ=π时，也就是在δ与f’(x)的方向相反时，取得最小值， 也就是下降的最快的方向了<br>这里也就是: f(x+δ) - f(x) = - ||δ||·||f’(x)||<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftc3wrla2qj307j01f742.jpg" alt=""><br>也就是<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc3yrla04j308101gq2q.jpg" alt=""></li><li>其中，wj表示第j个特征的权重，η为学习率，用来控制步长。</li><li>对损失函数<em>J</em>(w))中的w的第j个权重求偏导，<img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc42cfb1aj30gp0533yr.jpg" alt=""><br>所以，在使用梯度下降法更新权重时，只要根据公式<br><img src="http://wx1.sinaimg.cn/mw690/0060lm7Tly1ftc4m2t1e8j307z015dfn.jpg" alt=""><br>当样本量极大的时候，每次更新权重需要耗费大量的算力，这时可以采取随机梯度下降法，这时，每次迭代的时候需要将样本重新打乱，然后用下面的式子更新权重<br><img src="http://wx2.sinaimg.cn/mw690/0060lm7Tly1ftc4pl81xyj30av01aglg.jpg" alt=""></li></ul><p>参考文献:</p><ul><li>Raschka S. Python Machine Learning[M]. Packt Publishing, 2015</li><li>周志华. 机器学习 : = Machine learning[M]. 清华大学出版社, 2016.</li></ul>]]></content>
      
      <categories>
          
          <category> regression </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logistic regression </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title> general regression models </title>
      <link href="/2018/07/11/general-regression-models/"/>
      <url>/2018/07/11/general-regression-models/</url>
      <content type="html"><![CDATA[<h3 id="1-1-1-Ordinary-Least-Squares"><a href="#1-1-1-Ordinary-Least-Squares" class="headerlink" title="1.1.1. Ordinary Least Squares"></a>1.1.1. Ordinary Least Squares</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg = linear_model.LinearRegression()</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure><a id="more"></a><pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.coef_</span><br></pre></td></tr></table></figure><pre><code>array([0.5, 0.5])</code></pre><p>最小二乘法的代价函数表述为：<br><img src="http://scikit-learn.org/stable/_images/math/e8e92a5482d9327d939e7a17946a8a1b98006018.png" alt=""></p><h3 id="1-1-2-Ridge-Regression"><a href="#1-1-2-Ridge-Regression" class="headerlink" title="1.1.2 Ridge Regression"></a>1.1.2 Ridge Regression</h3><h4 id="岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和"><a href="#岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和" class="headerlink" title="岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和"></a>岭回归通过对最小二乘法的系数做出惩罚以解决部分的问题，最小化了惩罚的残差平方和</h4><ul><li>现行回归含有惩罚项的代价函数表述为：<br><img src="http://scikit-learn.org/stable/_images/math/48dbdad39c89539c714a825c0c0d5524eb526851.png" alt=""></li><li>正则化的背后的概念是引入额外的信息（偏差）来对极端参数的权重做出惩罚，此处的正则化则是引入的L2正则化。</li><li>代价函数的参数α的变化导致权重稀疏的变化，岭回归即L2正则化（L2收缩），也<strong>叫权重衰减</strong>：<br><img src="http://scikit-learn.org/stable/_images/sphx_glr_plot_ridge_path_0011.png" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg= linear_model.Ridge(alpha=<span class="number">0.5</span>)</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,   normalize=False, random_state=None, solver=&apos;auto&apos;, tol=0.001)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.intercept_</span><br></pre></td></tr></table></figure><pre><code>0.1363636363636364</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.coef_</span><br></pre></td></tr></table></figure><pre><code>array([0.34545455, 0.34545455])</code></pre><h4 id="1-1-2-1-Setting-the-regularization-parameter-generalized-Cross-Validation-通过交叉验证获得回归效果最恰当的惩罚项的参数"><a href="#1-1-2-1-Setting-the-regularization-parameter-generalized-Cross-Validation-通过交叉验证获得回归效果最恰当的惩罚项的参数" class="headerlink" title="1.1.2.1 Setting the regularization parameter: generalized Cross-Validation 通过交叉验证获得回归效果最恰当的惩罚项的参数"></a>1.1.2.1 Setting the regularization parameter: generalized Cross-Validation 通过交叉验证获得回归效果最恰当的惩罚项的参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg=linear_model.RidgeCV(alphas=[<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>])</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>RidgeCV(alphas=[0.1, 1.0, 10.0], cv=None, fit_intercept=True, gcv_mode=None,    normalize=False, scoring=None, store_cv_values=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.alpha_</span><br></pre></td></tr></table></figure><pre><code>0.1</code></pre><h4 id="1-1-3-Lasso-权重稀疏）"><a href="#1-1-3-Lasso-权重稀疏）" class="headerlink" title="1.1.3 Lasso(权重稀疏）"></a>1.1.3 Lasso(权重稀疏）</h4><ul><li>L1正则化可生成稀疏的特征向量，且大多数的权值为0，当高维的数据集中包含许多不想管的特征，尤其是在不相关的特征数量大于样本数量是，权重的稀疏化可以发挥特征选择的作用。</li><li>损失函数可以表示为：<br><img src="http://scikit-learn.org/stable/_images/math/07c30d8004d4406105b2547be4f3050048531656.png" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg= linear_model.Lasso(alpha=<span class="number">0.1</span>)</span><br><span class="line">reg.fit([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]],[<span class="number">0</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,   normalize=False, positive=False, precompute=False, random_state=None,   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">reg.predict([[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># 如果是一维数组的话，需要在外面再加一层中括号，或者</span></span><br></pre></td></tr></table></figure><pre><code>array([0.8])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg</span><br></pre></td></tr></table></figure><pre><code>Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,   normalize=False, positive=False, precompute=False, random_state=None,   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.coef_</span><br></pre></td></tr></table></figure><pre><code>array([0.6, 0. ])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.intercept_</span><br></pre></td></tr></table></figure><pre><code>0.2</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> regression </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Bagging和Boosting的概念与区别</title>
      <link href="/2018/06/11/Hello-hexo/"/>
      <url>/2018/06/11/Hello-hexo/</url>
      <content type="html"><![CDATA[<h2 id="Bagging和Boosting的概念与区别"><a href="#Bagging和Boosting的概念与区别" class="headerlink" title="Bagging和Boosting的概念与区别"></a>Bagging和Boosting的概念与区别</h2><h3 id="随机森林属于集成学习-ensemble-learning-中的bagging算法，在集成算法中主要分为bagging算法与boosting算法"><a href="#随机森林属于集成学习-ensemble-learning-中的bagging算法，在集成算法中主要分为bagging算法与boosting算法" class="headerlink" title="随机森林属于集成学习(ensemble learning)中的bagging算法，在集成算法中主要分为bagging算法与boosting算法"></a>随机森林属于集成学习(ensemble learning)中的bagging算法，在集成算法中主要分为bagging算法与boosting算法</h3><hr><h4 id="Bagging算法-套袋法，bootstrap-aggregating"><a href="#Bagging算法-套袋法，bootstrap-aggregating" class="headerlink" title="Bagging算法(套袋法，bootstrap aggregating)"></a>Bagging算法(套袋法，bootstrap aggregating)</h4><ul><li>bagging的算法过程如下：</li><li>从原始样本集中使用Bootstraping 方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集（k个训练集之间相互独立，元素可以有重复）。</li><li>对于n个训练集，我们训练k个模型，（这个模型可根据具体的情况而定，可以是决策树，knn等）</li><li>对于分类问题：由投票表决产生的分类结果；对于回归问题，由k个模型预测结果的均值作为最后预测的结果（所有模型的重要性相同）。</li></ul><a id="more"></a><h4 id="Boosting（提升法）"><a href="#Boosting（提升法）" class="headerlink" title="Boosting（提升法）"></a>Boosting（提升法）</h4><ul><li>boosting的算法过程如下： </li><li>对于训练集中的每个样本建立权值wi，表示对每个样本的权重， 其关键在与对于被错误分类的样本权重会在下一轮的分类中获得更大的权重（错误分类的样本的权重增加）。</li><li>同时加大分类 误差概率小的弱分类器的权值，使其在表决中起到更大的作用，减小分类误差率较大弱分类器的权值，使其在表决中起到较小的作用。每一次迭代都得到一个弱分类器，需要使用某种策略将其组合，最为最终模型，(adaboost给每个迭代之后的弱分类器一个权值，将其线性组合作为最终的分类器,误差小的分类器权值越大。)</li></ul><h4 id="Bagging和Boosting-的主要区别"><a href="#Bagging和Boosting-的主要区别" class="headerlink" title="Bagging和Boosting 的主要区别"></a>Bagging和Boosting 的主要区别</h4><ul><li>样本选择上: Bagging采取Bootstraping的是随机有放回的取样，Boosting的每一轮训练的样本是固定的，改变的是每个样的权重。</li><li>样本权重上：<strong>Bagging采取的是均匀取样，且每个样本的权重相同</strong>，Boosting根据错误率调整样本权重，错误率越大的样本权重会变大</li><li>预测函数上：<strong>Bagging所以的预测函数权值相同</strong>，Boosting中误差越小的预测函数其权值越大。</li><li>并行计算: Bagging 的各个预测函数可以并行生成;Boosting的各个预测函数必须按照顺序迭代生成.</li></ul><h4 id="将决策树与以上框架组合成新的算法"><a href="#将决策树与以上框架组合成新的算法" class="headerlink" title="将决策树与以上框架组合成新的算法"></a>将决策树与以上框架组合成新的算法</h4><ul><li>Bagging + 决策树 = 随机森林</li><li>AdaBoost + 决策树 = 提升树</li><li>gradient + 决策树 = （梯度提升树）GDBT </li></ul><h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><ul><li>常用的决策树有ID3， C4.5 ,CART三种. 三种算法模型构架相似，只是采用了不同的指标</li></ul><h4 id="首先看ID3算法"><a href="#首先看ID3算法" class="headerlink" title="首先看ID3算法"></a>首先看ID3算法</h4><ul><li>基于奥卡姆剃刀原理，即用尽量较少的东西做更多的事。ID3算法即iterative Dichotomiser3，迭代二叉树三代，越是小型的决策树优于较大的决策树。</li><li>核心思想是以信息增益来度量属性的选择，选择分裂后信息增益最大的属性进行分类。</li><li>信息增益是属性选择中一个重要指标，它定义为一个属性能够为分类系统带来的多少信息，带来的信息越多，该属性就越重要，而信息量，就是熵。</li><li>熵的定义是信息量的期望值，熵越大，一个变量的不确定性越大，它带来的信息量就越大，计算信息熵的公式为：<img src="https://github.com/KeKe-Li/tutorial/raw/master/assets/images/176.jpg" alt="">，其中，p为出现c分类时的概率。</li><li>如何计算一个属性的信息增益？</li></ul>]]></content>
      
      <categories>
          
          <category> ensemble method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> boosting </tag>
            
            <tag> 集成算法 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
